{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras import initializers, regularizers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str0 = \"ts_L60_Z12_A500_DX50_bias5_N10000\"\n",
    "\n",
    "fnamex = \"DATA/x_\"+str0+\".csv\"\n",
    "fnamey = \"DATA/y_\"+str0+\".csv\"\n",
    "\n",
    "x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "N = len(x)\n",
    "print(N)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_std =  scaler.fit_transform(x.T).T\n",
    "\n",
    "plt.plot(x_std[0], label = '0')\n",
    "plt.plot(x_std[1], label = '1')\n",
    "plt.plot(x_std[2], label = '2')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "N_categ = 3\n",
    "y = np.zeros((N,N_categ))\n",
    "\n",
    "for n in range(N):\n",
    "    y[n][categ[n]] = 1.\n",
    "    \n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_train = 0.8\n",
    "N_train = int(N*perc_train)\n",
    "N_val = N-N_train\n",
    "\n",
    "x_train = x_std[:N_train]\n",
    "y_train = y[:N_train]\n",
    "x_val = x_std[N_train:]\n",
    "y_val = y[N_train:]\n",
    "\n",
    "\n",
    "L = len(x[0])\n",
    "print(N, N_train, N_val, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],L,1) #1 - channel (RGB:3)\n",
    "                                                # L = sample size\n",
    "x_val = x_val.reshape(x_val.shape[0],L,1)\n",
    "\n",
    "input_shape = (L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "reg = regularizers.l2(0.01) #Lasso\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "#kernel_size = 11... similar to 12 as before\n",
    "model.add(Conv1D( filters = 5, kernel_size = 11, kernel_regularizer = reg, \n",
    "                 kernel_initializer = ini, \n",
    "                 activation = \"relu\", \n",
    "                 input_shape = input_shape                \n",
    "                ))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(filters = 5, kernel_size = 7, \n",
    "                 activation = \"relu\", \n",
    "                ))\n",
    "model.add(MaxPooling1D(2)) #optional\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, \n",
    "              optimizer = \"adam\", \n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "# model.save_weights(\"Original_Weights_CNN1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Working!\n",
    "The NN has as input larger and larger numbers. We shall manipulate the data at the beginning for example reshuffling them as they have average 0 and remove their standard deviation (set it to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = 250, epochs = 250, \n",
    "                 validation_data = (x_val, y_val), \n",
    "                verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(categ[N_train:],np.argmax(model.predict(x_val), axis=1),  normalize = 'true')\n",
    "\n",
    "\n",
    "#Better visualization of confusion matrices\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize = (15, 8))\n",
    "ax1.matshow(c_matrix, cmap = plt.cm.YlGn, alpha = 0.5)\n",
    "ax1.set_xticks(np.arange(3))\n",
    "ax1.set_yticks(np.arange(3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax1.text(x=j, y=i, s=round(c_matrix[i, j],2), ha=\"center\", va=\"center\")\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.set_xlabel('predicted label')\n",
    "ax1.set_ylabel('true label')\n",
    "ax1.set_title('CNN')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Discrimination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = np.linspace(50,500,10)\n",
    "res = []\n",
    "\n",
    "for A in As[-3:]:\n",
    "    str0 = f\"ts_L60_Z12_A{A}_DX50_bias5_N10000\"\n",
    "    fnamex = \"DATA/x_\" + str0 + \".csv\"\n",
    "    fnamey = \"DATA/y_\" + str0 + \".csv\"\n",
    "    \n",
    "    x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_std =  scaler.fit_transform(x.T).T\n",
    "    categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "    N_categ = 3\n",
    "    y = np.zeros((N,N_categ))\n",
    "\n",
    "    for n in range(N):\n",
    "        y[n][categ[n]] = 1.\n",
    "\n",
    "    perc_train = 0.8\n",
    "    N_train = int(N*perc_train)\n",
    "    N_val = N-N_train\n",
    "\n",
    "    x_train = x_std[:N_train]\n",
    "    y_train = y[:N_train]\n",
    "    x_val = x_std[N_train:]\n",
    "    y_val = y[N_train:]\n",
    "\n",
    "\n",
    "    L = len(x[0])\n",
    "    x_train = x_train.reshape(x_train.shape[0],L,1) #1 - channel (RGB:3)\n",
    "                                                   # L = sample size\n",
    "    x_val = x_val.reshape(x_val.shape[0],L,1)\n",
    "\n",
    "    input_shape = (L,1)\n",
    "    \n",
    "#     model.load_weights(\"Original_Weights_CNN1.h5\")\n",
    "    hist = model.fit(x_train, y_train, batch_size = 250, epochs = 50, \n",
    "                 validation_data = (x_val, y_val), \n",
    "                verbose = 2, shuffle = True)\n",
    "    res.append(pd.DataFrame(hist))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
