{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import initializers, regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPGheArt - Week 2 exercise\n",
    "\n",
    "### Lorenzo Buriola - 2021860\n",
    "### Filippo Conforto - 2021856\n",
    "### Lorenzo Domenichetti - 2011653\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(fit1, label_fit1 = '', fit_compare = None, label_fit_compare = '',  compare = False ):\n",
    "    '''\n",
    "    Simple function to plot the history of train and validation accuracy\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "\n",
    "    # summarize history for loss\n",
    "    ax1.plot(fit1.history['loss'], label = (label_fit1 + \" Train Loss\"), color = '#648FFF', lw = 2.5)\n",
    "    ax1.plot(fit1.history['val_loss'], label = (label_fit1 + \" Validation Loss\"), color = '#FE6100', lw = 2.5)\n",
    "    \n",
    "    if compare: ax1.plot(fit_compare.history['val_loss'], label = label_fit_compare+ ' Validation Loss', color  = '#DC267F', lw = 2.5)\n",
    "\n",
    "\n",
    "    ax1.legend(loc = 'best')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Model Loss')\n",
    "    ax1.grid(ls = '--')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    ax2.plot(fit1.history['accuracy'], label = (label_fit1 + ' Train Accuracy'), color =  '#648FFF', lw = 2.5)\n",
    "    ax2.plot(fit1.history['val_accuracy'], label = (label_fit1 + ' Validation Accuracy'), color = '#FE6100', lw = 2.5)\n",
    "    if compare: ax2.plot(fit_compare.history['val_accuracy'], label = label_fit_compare+ ' Validation Accuracy', color  = '#DC267F', lw = 2.5)\n",
    "\n",
    "    ax2.legend(loc = 'best')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Model Accuracy')\n",
    "    ax2.grid(ls = '--')\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN(reg = regularizers.l2, PoolType = keras.layers.MaxPooling1D, PoolSize = 3, \n",
    "               learn_rate= 0.001, fil = [4], k_size = [10],\n",
    "               dout_rate = 0.2, dense = [10]):\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = fil[0], kernel_size = k_size[0],\n",
    "                        kernel_regularizer = reg(learn_rate),\n",
    "                        kernel_initializer=ini,\n",
    "                        activation = \"relu\",\n",
    "                        input_shape = input_shape\n",
    "                        ))\n",
    "    model.add(PoolType(PoolSize))\n",
    "\n",
    "    for i in range(1,len(fil)):\n",
    "        model.add(Conv1D(filters = fil[i], kernel_size = k_size[i],\n",
    "                        activation = \"relu\",\n",
    "                        ))\n",
    "        model.add(PoolType(PoolSize))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    for i in range(len(dense)):\n",
    "        model.add(Dense(dense[i],activation=\"relu\"))\n",
    "        \n",
    "    model.add(Dropout(dout_rate))\n",
    "    model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(reg = regularizers.l2, PoolType = keras.layers.MaxPooling1D, PoolSize = 3, \n",
    "               learn_rate= 0.001, fil = [4], k_size = [10],\n",
    "               dout_rate = 0.2, dense = [10]):\n",
    "    # create the mode\n",
    "    model=create_CNN(reg,PoolType, PoolSize, learn_rate, fil, k_size, dout_rate, dense)\n",
    "    # compile the model\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "str0 = \"ts_L60_Z12_A500.0_DX50_bias5_N10000\"\n",
    "\n",
    "fnamex = \"DATA/x_\"+str0+\".csv\"\n",
    "fnamey = \"DATA/y_\"+str0+\".csv\"\n",
    "\n",
    "x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "N = len(x)\n",
    "print(N)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_std =  scaler.fit_transform(x.T).T\n",
    "\n",
    "plt.plot(x_std[0], label = '0')\n",
    "plt.plot(x_std[1], label = '1')\n",
    "plt.plot(x_std[2], label = '2')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "y = to_categorical(categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(x[0])\n",
    "input_shape = (len(x[0]),1)\n",
    "N_categ = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2)\n",
    "x_train = x_train.reshape(x_train.shape[0],L,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 50, 5)             60        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 25, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 19, 5)             180       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 9, 5)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 45)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                460       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 733\n",
      "Trainable params: 733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "model = compile_model( fil = [5,5], k_size = [11,7], PoolSize = 2, dense = [10], learn_rate = 0.001)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 - 1s - loss: 11158.9082 - accuracy: 0.3291 - val_loss: 548.3271 - val_accuracy: 0.3327\n",
      "Epoch 2/250\n",
      "32/32 - 0s - loss: 520.7242 - accuracy: 0.3388 - val_loss: 1.1329 - val_accuracy: 0.3359\n",
      "Epoch 3/250\n",
      "32/32 - 0s - loss: 1.2055 - accuracy: 0.3351 - val_loss: 1.1242 - val_accuracy: 0.3365\n",
      "Epoch 4/250\n",
      "32/32 - 0s - loss: 1.1216 - accuracy: 0.3368 - val_loss: 1.1202 - val_accuracy: 0.3376\n",
      "Epoch 5/250\n",
      "32/32 - 0s - loss: 1.1218 - accuracy: 0.3375 - val_loss: 1.1191 - val_accuracy: 0.3372\n",
      "Epoch 6/250\n",
      "32/32 - 0s - loss: 1.1181 - accuracy: 0.3374 - val_loss: 1.1180 - val_accuracy: 0.3370\n",
      "Epoch 7/250\n",
      "32/32 - 0s - loss: 1.1189 - accuracy: 0.3365 - val_loss: 1.1172 - val_accuracy: 0.3369\n",
      "Epoch 8/250\n",
      "32/32 - 0s - loss: 1.1223 - accuracy: 0.3366 - val_loss: 1.1162 - val_accuracy: 0.3370\n",
      "Epoch 9/250\n",
      "32/32 - 0s - loss: 1.1200 - accuracy: 0.3372 - val_loss: 1.1157 - val_accuracy: 0.3369\n",
      "Epoch 10/250\n",
      "32/32 - 0s - loss: 1.1180 - accuracy: 0.3369 - val_loss: 1.1140 - val_accuracy: 0.3371\n",
      "Epoch 11/250\n",
      "32/32 - 0s - loss: 1.1160 - accuracy: 0.3365 - val_loss: 1.1134 - val_accuracy: 0.3371\n",
      "Epoch 12/250\n",
      "32/32 - 0s - loss: 1.1145 - accuracy: 0.3365 - val_loss: 1.1125 - val_accuracy: 0.3371\n",
      "Epoch 13/250\n",
      "32/32 - 0s - loss: 1.1158 - accuracy: 0.3364 - val_loss: 1.1122 - val_accuracy: 0.3371\n",
      "Epoch 14/250\n",
      "32/32 - 0s - loss: 1.1117 - accuracy: 0.3370 - val_loss: 1.1113 - val_accuracy: 0.3374\n",
      "Epoch 15/250\n",
      "32/32 - 0s - loss: 539.2399 - accuracy: 0.3384 - val_loss: 1.1047 - val_accuracy: 0.3332\n",
      "Epoch 16/250\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3332 - val_loss: 1.1000 - val_accuracy: 0.3332\n",
      "Epoch 17/250\n",
      "32/32 - 0s - loss: 1.1005 - accuracy: 0.3332 - val_loss: 1.0998 - val_accuracy: 0.3332\n",
      "Epoch 18/250\n",
      "32/32 - 0s - loss: 1.1004 - accuracy: 0.3331 - val_loss: 1.0994 - val_accuracy: 0.3332\n",
      "Epoch 19/250\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3331 - val_loss: 1.0996 - val_accuracy: 0.3332\n",
      "Epoch 20/250\n",
      "32/32 - 0s - loss: 1.1005 - accuracy: 0.3329 - val_loss: 1.0992 - val_accuracy: 0.3331\n",
      "Epoch 21/250\n",
      "32/32 - 0s - loss: 1.0992 - accuracy: 0.3331 - val_loss: 1.1000 - val_accuracy: 0.3331\n",
      "Epoch 22/250\n",
      "32/32 - 0s - loss: 1.1014 - accuracy: 0.3369 - val_loss: 1.0988 - val_accuracy: 0.3376\n",
      "Epoch 23/250\n",
      "32/32 - 0s - loss: 1.0992 - accuracy: 0.3374 - val_loss: 1.0986 - val_accuracy: 0.3375\n",
      "Epoch 24/250\n",
      "32/32 - 0s - loss: 1.0988 - accuracy: 0.3374 - val_loss: 1.0986 - val_accuracy: 0.3376\n",
      "Epoch 25/250\n",
      "32/32 - 0s - loss: 1.0991 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3377\n",
      "Epoch 26/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0986 - val_accuracy: 0.3376\n",
      "Epoch 27/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0986 - val_accuracy: 0.3376\n",
      "Epoch 28/250\n",
      "32/32 - 0s - loss: 1.0991 - accuracy: 0.3376 - val_loss: 1.0984 - val_accuracy: 0.3377\n",
      "Epoch 29/250\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3375 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 30/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3376\n",
      "Epoch 31/250\n",
      "32/32 - 0s - loss: 1.0987 - accuracy: 0.3375 - val_loss: 1.0983 - val_accuracy: 0.3375\n",
      "Epoch 32/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3375\n",
      "Epoch 33/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 34/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 35/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 36/250\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 37/250\n",
      "32/32 - 0s - loss: 1.0988 - accuracy: 0.3374 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 38/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 39/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 40/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 41/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 42/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 43/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 44/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 45/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 46/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 47/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 48/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 49/250\n",
      "32/32 - 0s - loss: 1.0987 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 50/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 51/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 52/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 53/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 54/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 55/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 56/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 57/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 58/250\n",
      "32/32 - 0s - loss: 1.1006 - accuracy: 0.3374 - val_loss: 1.0985 - val_accuracy: 0.3377\n",
      "Epoch 59/250\n",
      "32/32 - 0s - loss: 1.0998 - accuracy: 0.3375 - val_loss: 1.0994 - val_accuracy: 0.3376\n",
      "Epoch 60/250\n",
      "32/32 - 0s - loss: 1.0996 - accuracy: 0.3374 - val_loss: 1.0982 - val_accuracy: 0.3375\n",
      "Epoch 61/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3377\n",
      "Epoch 62/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0984 - val_accuracy: 0.3377\n",
      "Epoch 63/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 64/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 65/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 66/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 67/250\n",
      "32/32 - 0s - loss: 1.0981 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 68/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 69/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 70/250\n",
      "32/32 - 0s - loss: 1.0981 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 71/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 72/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 73/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 74/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 75/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 76/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 77/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 78/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 79/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 80/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 81/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 82/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 84/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 85/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3377\n",
      "Epoch 86/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 87/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3376\n",
      "Epoch 88/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0984 - val_accuracy: 0.3377\n",
      "Epoch 89/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 90/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 91/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 92/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 93/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 94/250\n",
      "32/32 - 0s - loss: 1.1002 - accuracy: 0.3377 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 95/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.1013 - val_accuracy: 0.3376\n",
      "Epoch 96/250\n",
      "32/32 - 0s - loss: 1.1089 - accuracy: 0.3371 - val_loss: 1.1016 - val_accuracy: 0.3376\n",
      "Epoch 97/250\n",
      "32/32 - 0s - loss: 1.1008 - accuracy: 0.3379 - val_loss: 1.0986 - val_accuracy: 0.3375\n",
      "Epoch 98/250\n",
      "32/32 - 0s - loss: 1.0987 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3376\n",
      "Epoch 99/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3379\n",
      "Epoch 100/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3379 - val_loss: 1.0983 - val_accuracy: 0.3379\n",
      "Epoch 101/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 102/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3379\n",
      "Epoch 103/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 104/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 105/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 106/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 107/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 108/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 109/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 110/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 111/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 112/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 113/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 114/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 115/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 116/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 117/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 118/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 119/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 120/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 121/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 122/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 123/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 124/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 125/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 126/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 127/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 128/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 129/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3379\n",
      "Epoch 130/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3379\n",
      "Epoch 131/250\n",
      "32/32 - 0s - loss: 1.0988 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3379\n",
      "Epoch 132/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3379 - val_loss: 1.0985 - val_accuracy: 0.3377\n",
      "Epoch 133/250\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3374 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 134/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 135/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 136/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 137/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 138/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 139/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 140/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 141/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 142/250\n",
      "32/32 - 0s - loss: 1.0987 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 143/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 144/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 145/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 146/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 147/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 148/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 149/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 150/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 151/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 152/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3376\n",
      "Epoch 153/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 154/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 155/250\n",
      "32/32 - 0s - loss: 1.0987 - accuracy: 0.3377 - val_loss: 1.0985 - val_accuracy: 0.3377\n",
      "Epoch 156/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3379 - val_loss: 1.0984 - val_accuracy: 0.3377\n",
      "Epoch 157/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 158/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 159/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 160/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3374 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 161/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 162/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3376\n",
      "Epoch 163/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 164/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 166/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 167/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 168/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 169/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 170/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 171/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 172/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 173/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 174/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3374 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 175/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 176/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 177/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 178/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 179/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 180/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 181/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3376\n",
      "Epoch 182/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0997 - val_accuracy: 0.3377\n",
      "Epoch 183/250\n",
      "32/32 - 0s - loss: 1.1007 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 184/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0984 - val_accuracy: 0.3376\n",
      "Epoch 185/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3376\n",
      "Epoch 186/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 187/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 188/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 189/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 190/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 191/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 192/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 193/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 194/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 195/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 196/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3379\n",
      "Epoch 197/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3379\n",
      "Epoch 198/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 199/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 200/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 201/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 202/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 203/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 204/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 205/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 206/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 207/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 208/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 209/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 210/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 211/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 212/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 213/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 214/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3379\n",
      "Epoch 215/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 216/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 217/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 218/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 219/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 220/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3379\n",
      "Epoch 221/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 222/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 223/250\n",
      "32/32 - 0s - loss: 1.0997 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 224/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3376 - val_loss: 1.0999 - val_accuracy: 0.3376\n",
      "Epoch 225/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0985 - val_accuracy: 0.3376\n",
      "Epoch 226/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0985 - val_accuracy: 0.3376\n",
      "Epoch 227/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 228/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 229/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 230/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0986 - val_accuracy: 0.3377\n",
      "Epoch 231/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 232/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 233/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 234/250\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 235/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3376 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 236/250\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3376 - val_loss: 1.0983 - val_accuracy: 0.3377\n",
      "Epoch 237/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 238/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3377 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 239/250\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3376 - val_loss: 1.0984 - val_accuracy: 0.3376\n",
      "Epoch 240/250\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3376\n",
      "Epoch 241/250\n",
      "32/32 - 1s - loss: 1.0991 - accuracy: 0.3376 - val_loss: 1.0986 - val_accuracy: 0.3375\n",
      "Epoch 242/250\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3375 - val_loss: 1.0984 - val_accuracy: 0.3379\n",
      "Epoch 243/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3379 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 244/250\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3377 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 245/250\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3375 - val_loss: 1.0982 - val_accuracy: 0.3377\n",
      "Epoch 246/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3377\n",
      "Epoch 247/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 248/250\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3376 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 249/250\n",
      "32/32 - 1s - loss: 1.0982 - accuracy: 0.3375 - val_loss: 1.0981 - val_accuracy: 0.3376\n",
      "Epoch 250/250\n",
      "32/32 - 0s - loss: 1.0981 - accuracy: 0.3377 - val_loss: 1.0981 - val_accuracy: 0.3377\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = 250, epochs = 250, \n",
    "                 validation_data = (x_train, y_train), \n",
    "                verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss  is 0.32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation loss  is {model.evaluate(x_test, y_test, verbose = 0)[1]:1.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Working!\n",
    "The NN has as input larger and larger numbers. We shall manipulate the data at the beginning for example reshuffling them as they have average 0 and remove their standard deviation (set it to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x_std, y, test_size=0.2)\n",
    "x_train = x_train.reshape(x_train.shape[0],L,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],L,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 - 1s - loss: 1.0923 - accuracy: 0.3664 - val_loss: 1.0867 - val_accuracy: 0.3885\n",
      "Epoch 2/250\n",
      "32/32 - 0s - loss: 1.0803 - accuracy: 0.3966 - val_loss: 1.0693 - val_accuracy: 0.4232\n",
      "Epoch 3/250\n",
      "32/32 - 0s - loss: 1.0595 - accuracy: 0.4250 - val_loss: 1.0412 - val_accuracy: 0.4611\n",
      "Epoch 4/250\n",
      "32/32 - 0s - loss: 1.0321 - accuracy: 0.4516 - val_loss: 1.0071 - val_accuracy: 0.4656\n",
      "Epoch 5/250\n",
      "32/32 - 0s - loss: 1.0002 - accuracy: 0.4812 - val_loss: 0.9745 - val_accuracy: 0.5076\n",
      "Epoch 6/250\n",
      "32/32 - 0s - loss: 0.9751 - accuracy: 0.5077 - val_loss: 0.9408 - val_accuracy: 0.5446\n",
      "Epoch 7/250\n",
      "32/32 - 0s - loss: 0.9444 - accuracy: 0.5263 - val_loss: 0.9129 - val_accuracy: 0.5767\n",
      "Epoch 8/250\n",
      "32/32 - 0s - loss: 0.9205 - accuracy: 0.5614 - val_loss: 0.8889 - val_accuracy: 0.6036\n",
      "Epoch 9/250\n",
      "32/32 - 0s - loss: 0.9026 - accuracy: 0.5715 - val_loss: 0.8618 - val_accuracy: 0.6223\n",
      "Epoch 10/250\n",
      "32/32 - 0s - loss: 0.8784 - accuracy: 0.5976 - val_loss: 0.8383 - val_accuracy: 0.6406\n",
      "Epoch 11/250\n",
      "32/32 - 0s - loss: 0.8549 - accuracy: 0.6173 - val_loss: 0.8140 - val_accuracy: 0.6593\n",
      "Epoch 12/250\n",
      "32/32 - 0s - loss: 0.8379 - accuracy: 0.6256 - val_loss: 0.7891 - val_accuracy: 0.6718\n",
      "Epoch 13/250\n",
      "32/32 - 0s - loss: 0.8120 - accuracy: 0.6522 - val_loss: 0.7641 - val_accuracy: 0.6900\n",
      "Epoch 14/250\n",
      "32/32 - 0s - loss: 0.7906 - accuracy: 0.6625 - val_loss: 0.7445 - val_accuracy: 0.7005\n",
      "Epoch 15/250\n",
      "32/32 - 0s - loss: 0.7785 - accuracy: 0.6709 - val_loss: 0.7302 - val_accuracy: 0.7095\n",
      "Epoch 16/250\n",
      "32/32 - 0s - loss: 0.7589 - accuracy: 0.6833 - val_loss: 0.7144 - val_accuracy: 0.7168\n",
      "Epoch 17/250\n",
      "32/32 - 0s - loss: 0.7461 - accuracy: 0.6856 - val_loss: 0.6960 - val_accuracy: 0.7266\n",
      "Epoch 18/250\n",
      "32/32 - 0s - loss: 0.7415 - accuracy: 0.6916 - val_loss: 0.6870 - val_accuracy: 0.7274\n",
      "Epoch 19/250\n",
      "32/32 - 0s - loss: 0.7239 - accuracy: 0.6994 - val_loss: 0.6727 - val_accuracy: 0.7347\n",
      "Epoch 20/250\n",
      "32/32 - 0s - loss: 0.7169 - accuracy: 0.6984 - val_loss: 0.6601 - val_accuracy: 0.7409\n",
      "Epoch 21/250\n",
      "32/32 - 0s - loss: 0.7086 - accuracy: 0.7051 - val_loss: 0.6586 - val_accuracy: 0.7409\n",
      "Epoch 22/250\n",
      "32/32 - 0s - loss: 0.6989 - accuracy: 0.7132 - val_loss: 0.6389 - val_accuracy: 0.7465\n",
      "Epoch 23/250\n",
      "32/32 - 0s - loss: 0.6846 - accuracy: 0.7080 - val_loss: 0.6309 - val_accuracy: 0.7510\n",
      "Epoch 24/250\n",
      "32/32 - 0s - loss: 0.6803 - accuracy: 0.7132 - val_loss: 0.6213 - val_accuracy: 0.7561\n",
      "Epoch 25/250\n",
      "32/32 - 0s - loss: 0.6702 - accuracy: 0.7206 - val_loss: 0.6135 - val_accuracy: 0.7607\n",
      "Epoch 26/250\n",
      "32/32 - 0s - loss: 0.6629 - accuracy: 0.7237 - val_loss: 0.6059 - val_accuracy: 0.7653\n",
      "Epoch 27/250\n",
      "32/32 - 0s - loss: 0.6547 - accuracy: 0.7274 - val_loss: 0.5937 - val_accuracy: 0.7689\n",
      "Epoch 28/250\n",
      "32/32 - 0s - loss: 0.6496 - accuracy: 0.7300 - val_loss: 0.5861 - val_accuracy: 0.7686\n",
      "Epoch 29/250\n",
      "32/32 - 0s - loss: 0.6414 - accuracy: 0.7327 - val_loss: 0.5785 - val_accuracy: 0.7739\n",
      "Epoch 30/250\n",
      "32/32 - 0s - loss: 0.6315 - accuracy: 0.7368 - val_loss: 0.5728 - val_accuracy: 0.7768\n",
      "Epoch 31/250\n",
      "32/32 - 0s - loss: 0.6294 - accuracy: 0.7437 - val_loss: 0.5724 - val_accuracy: 0.7734\n",
      "Epoch 32/250\n",
      "32/32 - 0s - loss: 0.6250 - accuracy: 0.7389 - val_loss: 0.5637 - val_accuracy: 0.7804\n",
      "Epoch 33/250\n",
      "32/32 - 0s - loss: 0.6261 - accuracy: 0.7426 - val_loss: 0.5582 - val_accuracy: 0.7862\n",
      "Epoch 34/250\n",
      "32/32 - 0s - loss: 0.6100 - accuracy: 0.7480 - val_loss: 0.5562 - val_accuracy: 0.7839\n",
      "Epoch 35/250\n",
      "32/32 - 0s - loss: 0.6116 - accuracy: 0.7502 - val_loss: 0.5483 - val_accuracy: 0.7851\n",
      "Epoch 36/250\n",
      "32/32 - 0s - loss: 0.6065 - accuracy: 0.7542 - val_loss: 0.5470 - val_accuracy: 0.7859\n",
      "Epoch 37/250\n",
      "32/32 - 0s - loss: 0.6037 - accuracy: 0.7529 - val_loss: 0.5415 - val_accuracy: 0.7905\n",
      "Epoch 38/250\n",
      "32/32 - 0s - loss: 0.6063 - accuracy: 0.7542 - val_loss: 0.5543 - val_accuracy: 0.7790\n",
      "Epoch 39/250\n",
      "32/32 - 0s - loss: 0.5981 - accuracy: 0.7611 - val_loss: 0.5342 - val_accuracy: 0.7906\n",
      "Epoch 40/250\n",
      "32/32 - 0s - loss: 0.5961 - accuracy: 0.7596 - val_loss: 0.5336 - val_accuracy: 0.7937\n",
      "Epoch 41/250\n",
      "32/32 - 0s - loss: 0.5920 - accuracy: 0.7581 - val_loss: 0.5325 - val_accuracy: 0.7893\n",
      "Epoch 42/250\n",
      "32/32 - 0s - loss: 0.5883 - accuracy: 0.7616 - val_loss: 0.5314 - val_accuracy: 0.7919\n",
      "Epoch 43/250\n",
      "32/32 - 0s - loss: 0.5863 - accuracy: 0.7657 - val_loss: 0.5265 - val_accuracy: 0.7943\n",
      "Epoch 44/250\n",
      "32/32 - 0s - loss: 0.5867 - accuracy: 0.7586 - val_loss: 0.5202 - val_accuracy: 0.7970\n",
      "Epoch 45/250\n",
      "32/32 - 0s - loss: 0.5819 - accuracy: 0.7641 - val_loss: 0.5245 - val_accuracy: 0.7944\n",
      "Epoch 46/250\n",
      "32/32 - 0s - loss: 0.5775 - accuracy: 0.7663 - val_loss: 0.5176 - val_accuracy: 0.7983\n",
      "Epoch 47/250\n",
      "32/32 - 0s - loss: 0.5723 - accuracy: 0.7678 - val_loss: 0.5139 - val_accuracy: 0.8001\n",
      "Epoch 48/250\n",
      "32/32 - 0s - loss: 0.5731 - accuracy: 0.7703 - val_loss: 0.5139 - val_accuracy: 0.8012\n",
      "Epoch 49/250\n",
      "32/32 - 0s - loss: 0.5708 - accuracy: 0.7725 - val_loss: 0.5155 - val_accuracy: 0.7977\n",
      "Epoch 50/250\n",
      "32/32 - 0s - loss: 0.5733 - accuracy: 0.7686 - val_loss: 0.5167 - val_accuracy: 0.7979\n",
      "Epoch 51/250\n",
      "32/32 - 0s - loss: 0.5697 - accuracy: 0.7716 - val_loss: 0.5076 - val_accuracy: 0.8020\n",
      "Epoch 52/250\n",
      "32/32 - 0s - loss: 0.5566 - accuracy: 0.7770 - val_loss: 0.5041 - val_accuracy: 0.8030\n",
      "Epoch 53/250\n",
      "32/32 - 0s - loss: 0.5630 - accuracy: 0.7761 - val_loss: 0.5033 - val_accuracy: 0.8031\n",
      "Epoch 54/250\n",
      "32/32 - 0s - loss: 0.5591 - accuracy: 0.7749 - val_loss: 0.5004 - val_accuracy: 0.8029\n",
      "Epoch 55/250\n",
      "32/32 - 0s - loss: 0.5614 - accuracy: 0.7725 - val_loss: 0.5012 - val_accuracy: 0.8021\n",
      "Epoch 56/250\n",
      "32/32 - 0s - loss: 0.5582 - accuracy: 0.7726 - val_loss: 0.4969 - val_accuracy: 0.8035\n",
      "Epoch 57/250\n",
      "32/32 - 0s - loss: 0.5564 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.8074\n",
      "Epoch 58/250\n",
      "32/32 - 0s - loss: 0.5602 - accuracy: 0.7735 - val_loss: 0.5038 - val_accuracy: 0.8021\n",
      "Epoch 59/250\n",
      "32/32 - 0s - loss: 0.5508 - accuracy: 0.7809 - val_loss: 0.4924 - val_accuracy: 0.8069\n",
      "Epoch 60/250\n",
      "32/32 - 0s - loss: 0.5502 - accuracy: 0.7824 - val_loss: 0.4931 - val_accuracy: 0.8089\n",
      "Epoch 61/250\n",
      "32/32 - 0s - loss: 0.5434 - accuracy: 0.7857 - val_loss: 0.4887 - val_accuracy: 0.8099\n",
      "Epoch 62/250\n",
      "32/32 - 0s - loss: 0.5499 - accuracy: 0.7839 - val_loss: 0.4893 - val_accuracy: 0.8079\n",
      "Epoch 63/250\n",
      "32/32 - 0s - loss: 0.5476 - accuracy: 0.7820 - val_loss: 0.4869 - val_accuracy: 0.8119\n",
      "Epoch 64/250\n",
      "32/32 - 0s - loss: 0.5459 - accuracy: 0.7849 - val_loss: 0.4887 - val_accuracy: 0.8094\n",
      "Epoch 65/250\n",
      "32/32 - 0s - loss: 0.5427 - accuracy: 0.7861 - val_loss: 0.4836 - val_accuracy: 0.8104\n",
      "Epoch 66/250\n",
      "32/32 - 0s - loss: 0.5364 - accuracy: 0.7906 - val_loss: 0.4827 - val_accuracy: 0.8106\n",
      "Epoch 67/250\n",
      "32/32 - 0s - loss: 0.5375 - accuracy: 0.7865 - val_loss: 0.4812 - val_accuracy: 0.8105\n",
      "Epoch 68/250\n",
      "32/32 - 0s - loss: 0.5406 - accuracy: 0.7849 - val_loss: 0.4859 - val_accuracy: 0.8102\n",
      "Epoch 69/250\n",
      "32/32 - 0s - loss: 0.5378 - accuracy: 0.7876 - val_loss: 0.4824 - val_accuracy: 0.8105\n",
      "Epoch 70/250\n",
      "32/32 - 0s - loss: 0.5384 - accuracy: 0.7828 - val_loss: 0.4781 - val_accuracy: 0.8150\n",
      "Epoch 71/250\n",
      "32/32 - 0s - loss: 0.5308 - accuracy: 0.7935 - val_loss: 0.4795 - val_accuracy: 0.8121\n",
      "Epoch 72/250\n",
      "32/32 - 0s - loss: 0.5320 - accuracy: 0.7866 - val_loss: 0.4768 - val_accuracy: 0.8154\n",
      "Epoch 73/250\n",
      "32/32 - 0s - loss: 0.5336 - accuracy: 0.7881 - val_loss: 0.4787 - val_accuracy: 0.8124\n",
      "Epoch 74/250\n",
      "32/32 - 0s - loss: 0.5316 - accuracy: 0.7879 - val_loss: 0.4743 - val_accuracy: 0.8165\n",
      "Epoch 75/250\n",
      "32/32 - 0s - loss: 0.5316 - accuracy: 0.7887 - val_loss: 0.4741 - val_accuracy: 0.8148\n",
      "Epoch 76/250\n",
      "32/32 - 0s - loss: 0.5286 - accuracy: 0.7880 - val_loss: 0.4732 - val_accuracy: 0.8165\n",
      "Epoch 77/250\n",
      "32/32 - 0s - loss: 0.5249 - accuracy: 0.7928 - val_loss: 0.4701 - val_accuracy: 0.8164\n",
      "Epoch 78/250\n",
      "32/32 - 0s - loss: 0.5209 - accuracy: 0.7916 - val_loss: 0.4701 - val_accuracy: 0.8181\n",
      "Epoch 79/250\n",
      "32/32 - 0s - loss: 0.5230 - accuracy: 0.7954 - val_loss: 0.4698 - val_accuracy: 0.8169\n",
      "Epoch 80/250\n",
      "32/32 - 0s - loss: 0.5194 - accuracy: 0.7971 - val_loss: 0.4691 - val_accuracy: 0.8194\n",
      "Epoch 81/250\n",
      "32/32 - 0s - loss: 0.5236 - accuracy: 0.7909 - val_loss: 0.4643 - val_accuracy: 0.8183\n",
      "Epoch 82/250\n",
      "32/32 - 0s - loss: 0.5168 - accuracy: 0.7994 - val_loss: 0.4748 - val_accuracy: 0.8186\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.5260 - accuracy: 0.7943 - val_loss: 0.4647 - val_accuracy: 0.8199\n",
      "Epoch 84/250\n",
      "32/32 - 0s - loss: 0.5236 - accuracy: 0.7916 - val_loss: 0.4625 - val_accuracy: 0.8185\n",
      "Epoch 85/250\n",
      "32/32 - 0s - loss: 0.5205 - accuracy: 0.7951 - val_loss: 0.4615 - val_accuracy: 0.8196\n",
      "Epoch 86/250\n",
      "32/32 - 0s - loss: 0.5210 - accuracy: 0.7928 - val_loss: 0.4617 - val_accuracy: 0.8186\n",
      "Epoch 87/250\n",
      "32/32 - 0s - loss: 0.5239 - accuracy: 0.7971 - val_loss: 0.4610 - val_accuracy: 0.8188\n",
      "Epoch 88/250\n",
      "32/32 - 0s - loss: 0.5133 - accuracy: 0.7980 - val_loss: 0.4618 - val_accuracy: 0.8213\n",
      "Epoch 89/250\n",
      "32/32 - 0s - loss: 0.5160 - accuracy: 0.7943 - val_loss: 0.4642 - val_accuracy: 0.8200\n",
      "Epoch 90/250\n",
      "32/32 - 0s - loss: 0.5159 - accuracy: 0.8001 - val_loss: 0.4615 - val_accuracy: 0.8188\n",
      "Epoch 91/250\n",
      "32/32 - 0s - loss: 0.5170 - accuracy: 0.7954 - val_loss: 0.4594 - val_accuracy: 0.8188\n",
      "Epoch 92/250\n",
      "32/32 - 0s - loss: 0.5168 - accuracy: 0.7920 - val_loss: 0.4544 - val_accuracy: 0.8251\n",
      "Epoch 93/250\n",
      "32/32 - 0s - loss: 0.5079 - accuracy: 0.7971 - val_loss: 0.4589 - val_accuracy: 0.8209\n",
      "Epoch 94/250\n",
      "32/32 - 0s - loss: 0.5127 - accuracy: 0.7972 - val_loss: 0.4540 - val_accuracy: 0.8235\n",
      "Epoch 95/250\n",
      "32/32 - 0s - loss: 0.5086 - accuracy: 0.8030 - val_loss: 0.4578 - val_accuracy: 0.8189\n",
      "Epoch 96/250\n",
      "32/32 - 0s - loss: 0.5111 - accuracy: 0.7970 - val_loss: 0.4542 - val_accuracy: 0.8215\n",
      "Epoch 97/250\n",
      "32/32 - 0s - loss: 0.5115 - accuracy: 0.7990 - val_loss: 0.4521 - val_accuracy: 0.8266\n",
      "Epoch 98/250\n",
      "32/32 - 0s - loss: 0.5024 - accuracy: 0.8020 - val_loss: 0.4535 - val_accuracy: 0.8220\n",
      "Epoch 99/250\n",
      "32/32 - 0s - loss: 0.5080 - accuracy: 0.8016 - val_loss: 0.4513 - val_accuracy: 0.8238\n",
      "Epoch 100/250\n",
      "32/32 - 0s - loss: 0.5016 - accuracy: 0.8058 - val_loss: 0.4543 - val_accuracy: 0.8234\n",
      "Epoch 101/250\n",
      "32/32 - 0s - loss: 0.5081 - accuracy: 0.8045 - val_loss: 0.4551 - val_accuracy: 0.8220\n",
      "Epoch 102/250\n",
      "32/32 - 0s - loss: 0.5030 - accuracy: 0.8054 - val_loss: 0.4470 - val_accuracy: 0.8278\n",
      "Epoch 103/250\n",
      "32/32 - 0s - loss: 0.5017 - accuracy: 0.8075 - val_loss: 0.4620 - val_accuracy: 0.8221\n",
      "Epoch 104/250\n",
      "32/32 - 0s - loss: 0.5047 - accuracy: 0.8000 - val_loss: 0.4609 - val_accuracy: 0.8234\n",
      "Epoch 105/250\n",
      "32/32 - 0s - loss: 0.5047 - accuracy: 0.7999 - val_loss: 0.4453 - val_accuracy: 0.8274\n",
      "Epoch 106/250\n",
      "32/32 - 0s - loss: 0.5012 - accuracy: 0.8048 - val_loss: 0.4463 - val_accuracy: 0.8263\n",
      "Epoch 107/250\n",
      "32/32 - 0s - loss: 0.5023 - accuracy: 0.8045 - val_loss: 0.4448 - val_accuracy: 0.8284\n",
      "Epoch 108/250\n",
      "32/32 - 0s - loss: 0.5059 - accuracy: 0.8002 - val_loss: 0.4451 - val_accuracy: 0.8266\n",
      "Epoch 109/250\n",
      "32/32 - 0s - loss: 0.4974 - accuracy: 0.8054 - val_loss: 0.4434 - val_accuracy: 0.8291\n",
      "Epoch 110/250\n",
      "32/32 - 0s - loss: 0.4993 - accuracy: 0.8062 - val_loss: 0.4426 - val_accuracy: 0.8281\n",
      "Epoch 111/250\n",
      "32/32 - 0s - loss: 0.5007 - accuracy: 0.8005 - val_loss: 0.4423 - val_accuracy: 0.8281\n",
      "Epoch 112/250\n",
      "32/32 - 0s - loss: 0.5001 - accuracy: 0.8033 - val_loss: 0.4424 - val_accuracy: 0.8260\n",
      "Epoch 113/250\n",
      "32/32 - 0s - loss: 0.4978 - accuracy: 0.8020 - val_loss: 0.4438 - val_accuracy: 0.8292\n",
      "Epoch 114/250\n",
      "32/32 - 0s - loss: 0.4967 - accuracy: 0.8035 - val_loss: 0.4408 - val_accuracy: 0.8290\n",
      "Epoch 115/250\n",
      "32/32 - 0s - loss: 0.4985 - accuracy: 0.8030 - val_loss: 0.4415 - val_accuracy: 0.8281\n",
      "Epoch 116/250\n",
      "32/32 - 0s - loss: 0.4966 - accuracy: 0.8055 - val_loss: 0.4384 - val_accuracy: 0.8300\n",
      "Epoch 117/250\n",
      "32/32 - 0s - loss: 0.4985 - accuracy: 0.8069 - val_loss: 0.4427 - val_accuracy: 0.8284\n",
      "Epoch 118/250\n",
      "32/32 - 0s - loss: 0.5016 - accuracy: 0.8056 - val_loss: 0.4452 - val_accuracy: 0.8286\n",
      "Epoch 119/250\n",
      "32/32 - 0s - loss: 0.4923 - accuracy: 0.8100 - val_loss: 0.4425 - val_accuracy: 0.8271\n",
      "Epoch 120/250\n",
      "32/32 - 0s - loss: 0.4990 - accuracy: 0.8058 - val_loss: 0.4362 - val_accuracy: 0.8321\n",
      "Epoch 121/250\n",
      "32/32 - 0s - loss: 0.4859 - accuracy: 0.8139 - val_loss: 0.4400 - val_accuracy: 0.8288\n",
      "Epoch 122/250\n",
      "32/32 - 0s - loss: 0.4910 - accuracy: 0.8056 - val_loss: 0.4360 - val_accuracy: 0.8307\n",
      "Epoch 123/250\n",
      "32/32 - 0s - loss: 0.4899 - accuracy: 0.8075 - val_loss: 0.4343 - val_accuracy: 0.8322\n",
      "Epoch 124/250\n",
      "32/32 - 0s - loss: 0.4909 - accuracy: 0.8071 - val_loss: 0.4373 - val_accuracy: 0.8299\n",
      "Epoch 125/250\n",
      "32/32 - 0s - loss: 0.4922 - accuracy: 0.8056 - val_loss: 0.4345 - val_accuracy: 0.8317\n",
      "Epoch 126/250\n",
      "32/32 - 0s - loss: 0.4912 - accuracy: 0.8067 - val_loss: 0.4320 - val_accuracy: 0.8305\n",
      "Epoch 127/250\n",
      "32/32 - 0s - loss: 0.4941 - accuracy: 0.8049 - val_loss: 0.4348 - val_accuracy: 0.8307\n",
      "Epoch 128/250\n",
      "32/32 - 0s - loss: 0.4874 - accuracy: 0.8073 - val_loss: 0.4334 - val_accuracy: 0.8304\n",
      "Epoch 129/250\n",
      "32/32 - 0s - loss: 0.4848 - accuracy: 0.8056 - val_loss: 0.4340 - val_accuracy: 0.8341\n",
      "Epoch 130/250\n",
      "32/32 - 0s - loss: 0.4876 - accuracy: 0.8106 - val_loss: 0.4329 - val_accuracy: 0.8335\n",
      "Epoch 131/250\n",
      "32/32 - 0s - loss: 0.4892 - accuracy: 0.8092 - val_loss: 0.4313 - val_accuracy: 0.8307\n",
      "Epoch 132/250\n",
      "32/32 - 0s - loss: 0.4859 - accuracy: 0.8114 - val_loss: 0.4357 - val_accuracy: 0.8313\n",
      "Epoch 133/250\n",
      "32/32 - 0s - loss: 0.4948 - accuracy: 0.8060 - val_loss: 0.4326 - val_accuracy: 0.8309\n",
      "Epoch 134/250\n",
      "32/32 - 0s - loss: 0.4875 - accuracy: 0.8056 - val_loss: 0.4369 - val_accuracy: 0.8315\n",
      "Epoch 135/250\n",
      "32/32 - 0s - loss: 0.4806 - accuracy: 0.8114 - val_loss: 0.4316 - val_accuracy: 0.8334\n",
      "Epoch 136/250\n",
      "32/32 - 0s - loss: 0.4843 - accuracy: 0.8067 - val_loss: 0.4330 - val_accuracy: 0.8303\n",
      "Epoch 137/250\n",
      "32/32 - 0s - loss: 0.4867 - accuracy: 0.8117 - val_loss: 0.4286 - val_accuracy: 0.8329\n",
      "Epoch 138/250\n",
      "32/32 - 0s - loss: 0.4844 - accuracy: 0.8116 - val_loss: 0.4377 - val_accuracy: 0.8316\n",
      "Epoch 139/250\n",
      "32/32 - 0s - loss: 0.4807 - accuracy: 0.8115 - val_loss: 0.4275 - val_accuracy: 0.8335\n",
      "Epoch 140/250\n",
      "32/32 - 0s - loss: 0.4838 - accuracy: 0.8123 - val_loss: 0.4269 - val_accuracy: 0.8346\n",
      "Epoch 141/250\n",
      "32/32 - 0s - loss: 0.4830 - accuracy: 0.8079 - val_loss: 0.4283 - val_accuracy: 0.8339\n",
      "Epoch 142/250\n",
      "32/32 - 0s - loss: 0.4800 - accuracy: 0.8104 - val_loss: 0.4256 - val_accuracy: 0.8342\n",
      "Epoch 143/250\n",
      "32/32 - 0s - loss: 0.4830 - accuracy: 0.8133 - val_loss: 0.4296 - val_accuracy: 0.8356\n",
      "Epoch 144/250\n",
      "32/32 - 0s - loss: 0.4880 - accuracy: 0.8091 - val_loss: 0.4263 - val_accuracy: 0.8332\n",
      "Epoch 145/250\n",
      "32/32 - 0s - loss: 0.4780 - accuracy: 0.8141 - val_loss: 0.4245 - val_accuracy: 0.8355\n",
      "Epoch 146/250\n",
      "32/32 - 0s - loss: 0.4813 - accuracy: 0.8165 - val_loss: 0.4267 - val_accuracy: 0.8340\n",
      "Epoch 147/250\n",
      "32/32 - 0s - loss: 0.4836 - accuracy: 0.8102 - val_loss: 0.4238 - val_accuracy: 0.8339\n",
      "Epoch 148/250\n",
      "32/32 - 0s - loss: 0.4833 - accuracy: 0.8080 - val_loss: 0.4225 - val_accuracy: 0.8356\n",
      "Epoch 149/250\n",
      "32/32 - 0s - loss: 0.4868 - accuracy: 0.8154 - val_loss: 0.4237 - val_accuracy: 0.8363\n",
      "Epoch 150/250\n",
      "32/32 - 0s - loss: 0.4804 - accuracy: 0.8114 - val_loss: 0.4222 - val_accuracy: 0.8356\n",
      "Epoch 151/250\n",
      "32/32 - 0s - loss: 0.4832 - accuracy: 0.8117 - val_loss: 0.4234 - val_accuracy: 0.8361\n",
      "Epoch 152/250\n",
      "32/32 - 0s - loss: 0.4784 - accuracy: 0.8173 - val_loss: 0.4270 - val_accuracy: 0.8351\n",
      "Epoch 153/250\n",
      "32/32 - 0s - loss: 0.4807 - accuracy: 0.8126 - val_loss: 0.4238 - val_accuracy: 0.8356\n",
      "Epoch 154/250\n",
      "32/32 - 0s - loss: 0.4761 - accuracy: 0.8130 - val_loss: 0.4209 - val_accuracy: 0.8342\n",
      "Epoch 155/250\n",
      "32/32 - 0s - loss: 0.4769 - accuracy: 0.8156 - val_loss: 0.4284 - val_accuracy: 0.8313\n",
      "Epoch 156/250\n",
      "32/32 - 0s - loss: 0.4794 - accuracy: 0.8105 - val_loss: 0.4219 - val_accuracy: 0.8366\n",
      "Epoch 157/250\n",
      "32/32 - 0s - loss: 0.4784 - accuracy: 0.8100 - val_loss: 0.4208 - val_accuracy: 0.8366\n",
      "Epoch 158/250\n",
      "32/32 - 0s - loss: 0.4815 - accuracy: 0.8146 - val_loss: 0.4199 - val_accuracy: 0.8354\n",
      "Epoch 159/250\n",
      "32/32 - 0s - loss: 0.4789 - accuracy: 0.8144 - val_loss: 0.4306 - val_accuracy: 0.8359\n",
      "Epoch 160/250\n",
      "32/32 - 0s - loss: 0.4775 - accuracy: 0.8127 - val_loss: 0.4227 - val_accuracy: 0.8372\n",
      "Epoch 161/250\n",
      "32/32 - 0s - loss: 0.4806 - accuracy: 0.8124 - val_loss: 0.4200 - val_accuracy: 0.8380\n",
      "Epoch 162/250\n",
      "32/32 - 0s - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4176 - val_accuracy: 0.8389\n",
      "Epoch 163/250\n",
      "32/32 - 0s - loss: 0.4780 - accuracy: 0.8120 - val_loss: 0.4185 - val_accuracy: 0.8393\n",
      "Epoch 164/250\n",
      "32/32 - 0s - loss: 0.4758 - accuracy: 0.8124 - val_loss: 0.4172 - val_accuracy: 0.8386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "32/32 - 0s - loss: 0.4737 - accuracy: 0.8125 - val_loss: 0.4178 - val_accuracy: 0.8366\n",
      "Epoch 166/250\n",
      "32/32 - 0s - loss: 0.4729 - accuracy: 0.8130 - val_loss: 0.4187 - val_accuracy: 0.8386\n",
      "Epoch 167/250\n",
      "32/32 - 0s - loss: 0.4730 - accuracy: 0.8177 - val_loss: 0.4220 - val_accuracy: 0.8376\n",
      "Epoch 168/250\n",
      "32/32 - 0s - loss: 0.4753 - accuracy: 0.8146 - val_loss: 0.4219 - val_accuracy: 0.8357\n",
      "Epoch 169/250\n",
      "32/32 - 0s - loss: 0.4707 - accuracy: 0.8114 - val_loss: 0.4199 - val_accuracy: 0.8401\n",
      "Epoch 170/250\n",
      "32/32 - 0s - loss: 0.4711 - accuracy: 0.8163 - val_loss: 0.4191 - val_accuracy: 0.8379\n",
      "Epoch 171/250\n",
      "32/32 - 0s - loss: 0.4695 - accuracy: 0.8190 - val_loss: 0.4151 - val_accuracy: 0.8378\n",
      "Epoch 172/250\n",
      "32/32 - 0s - loss: 0.4701 - accuracy: 0.8155 - val_loss: 0.4147 - val_accuracy: 0.8403\n",
      "Epoch 173/250\n",
      "32/32 - 0s - loss: 0.4692 - accuracy: 0.8123 - val_loss: 0.4225 - val_accuracy: 0.8378\n",
      "Epoch 174/250\n",
      "32/32 - 0s - loss: 0.4741 - accuracy: 0.8099 - val_loss: 0.4262 - val_accuracy: 0.8370\n",
      "Epoch 175/250\n",
      "32/32 - 0s - loss: 0.4746 - accuracy: 0.8125 - val_loss: 0.4165 - val_accuracy: 0.8391\n",
      "Epoch 176/250\n",
      "32/32 - 0s - loss: 0.4668 - accuracy: 0.8191 - val_loss: 0.4160 - val_accuracy: 0.8411\n",
      "Epoch 177/250\n",
      "32/32 - 0s - loss: 0.4683 - accuracy: 0.8164 - val_loss: 0.4152 - val_accuracy: 0.8413\n",
      "Epoch 178/250\n",
      "32/32 - 0s - loss: 0.4706 - accuracy: 0.8158 - val_loss: 0.4162 - val_accuracy: 0.8406\n",
      "Epoch 179/250\n",
      "32/32 - 0s - loss: 0.4672 - accuracy: 0.8164 - val_loss: 0.4138 - val_accuracy: 0.8436\n",
      "Epoch 180/250\n",
      "32/32 - 0s - loss: 0.4666 - accuracy: 0.8161 - val_loss: 0.4130 - val_accuracy: 0.8394\n",
      "Epoch 181/250\n",
      "32/32 - 0s - loss: 0.4776 - accuracy: 0.8138 - val_loss: 0.4212 - val_accuracy: 0.8379\n",
      "Epoch 182/250\n",
      "32/32 - 0s - loss: 0.4687 - accuracy: 0.8214 - val_loss: 0.4120 - val_accuracy: 0.8400\n",
      "Epoch 183/250\n",
      "32/32 - 0s - loss: 0.4704 - accuracy: 0.8148 - val_loss: 0.4129 - val_accuracy: 0.8403\n",
      "Epoch 184/250\n",
      "32/32 - 0s - loss: 0.4662 - accuracy: 0.8199 - val_loss: 0.4195 - val_accuracy: 0.8341\n",
      "Epoch 185/250\n",
      "32/32 - 0s - loss: 0.4706 - accuracy: 0.8139 - val_loss: 0.4137 - val_accuracy: 0.8384\n",
      "Epoch 186/250\n",
      "32/32 - 0s - loss: 0.4702 - accuracy: 0.8158 - val_loss: 0.4137 - val_accuracy: 0.8379\n",
      "Epoch 187/250\n",
      "32/32 - 0s - loss: 0.4661 - accuracy: 0.8186 - val_loss: 0.4111 - val_accuracy: 0.8400\n",
      "Epoch 188/250\n",
      "32/32 - 0s - loss: 0.4758 - accuracy: 0.8140 - val_loss: 0.4145 - val_accuracy: 0.8371\n",
      "Epoch 189/250\n",
      "32/32 - 0s - loss: 0.4646 - accuracy: 0.8149 - val_loss: 0.4180 - val_accuracy: 0.8422\n",
      "Epoch 190/250\n",
      "32/32 - 0s - loss: 0.4709 - accuracy: 0.8160 - val_loss: 0.4122 - val_accuracy: 0.8416\n",
      "Epoch 191/250\n",
      "32/32 - 0s - loss: 0.4733 - accuracy: 0.8171 - val_loss: 0.4117 - val_accuracy: 0.8421\n",
      "Epoch 192/250\n",
      "32/32 - 0s - loss: 0.4652 - accuracy: 0.8144 - val_loss: 0.4173 - val_accuracy: 0.8394\n",
      "Epoch 193/250\n",
      "32/32 - 0s - loss: 0.4691 - accuracy: 0.8151 - val_loss: 0.4099 - val_accuracy: 0.8435\n",
      "Epoch 194/250\n",
      "32/32 - 0s - loss: 0.4680 - accuracy: 0.8152 - val_loss: 0.4142 - val_accuracy: 0.8390\n",
      "Epoch 195/250\n",
      "32/32 - 0s - loss: 0.4726 - accuracy: 0.8139 - val_loss: 0.4100 - val_accuracy: 0.8428\n",
      "Epoch 196/250\n",
      "32/32 - 0s - loss: 0.4655 - accuracy: 0.8138 - val_loss: 0.4144 - val_accuracy: 0.8389\n",
      "Epoch 197/250\n",
      "32/32 - 0s - loss: 0.4689 - accuracy: 0.8163 - val_loss: 0.4142 - val_accuracy: 0.8363\n",
      "Epoch 198/250\n",
      "32/32 - 0s - loss: 0.4705 - accuracy: 0.8154 - val_loss: 0.4088 - val_accuracy: 0.8416\n",
      "Epoch 199/250\n",
      "32/32 - 0s - loss: 0.4630 - accuracy: 0.8205 - val_loss: 0.4103 - val_accuracy: 0.8379\n",
      "Epoch 200/250\n",
      "32/32 - 0s - loss: 0.4622 - accuracy: 0.8188 - val_loss: 0.4105 - val_accuracy: 0.8415\n",
      "Epoch 201/250\n",
      "32/32 - 0s - loss: 0.4705 - accuracy: 0.8151 - val_loss: 0.4134 - val_accuracy: 0.8390\n",
      "Epoch 202/250\n",
      "32/32 - 0s - loss: 0.4578 - accuracy: 0.8217 - val_loss: 0.4098 - val_accuracy: 0.8418\n",
      "Epoch 203/250\n",
      "32/32 - 0s - loss: 0.4695 - accuracy: 0.8189 - val_loss: 0.4127 - val_accuracy: 0.8410\n",
      "Epoch 204/250\n",
      "32/32 - 0s - loss: 0.4593 - accuracy: 0.8214 - val_loss: 0.4070 - val_accuracy: 0.8411\n",
      "Epoch 205/250\n",
      "32/32 - 0s - loss: 0.4666 - accuracy: 0.8195 - val_loss: 0.4080 - val_accuracy: 0.8434\n",
      "Epoch 206/250\n",
      "32/32 - 0s - loss: 0.4627 - accuracy: 0.8200 - val_loss: 0.4092 - val_accuracy: 0.8416\n",
      "Epoch 207/250\n",
      "32/32 - 0s - loss: 0.4635 - accuracy: 0.8181 - val_loss: 0.4059 - val_accuracy: 0.8445\n",
      "Epoch 208/250\n",
      "32/32 - 0s - loss: 0.4652 - accuracy: 0.8154 - val_loss: 0.4123 - val_accuracy: 0.8394\n",
      "Epoch 209/250\n",
      "32/32 - 0s - loss: 0.4597 - accuracy: 0.8224 - val_loss: 0.4078 - val_accuracy: 0.8430\n",
      "Epoch 210/250\n",
      "32/32 - 0s - loss: 0.4640 - accuracy: 0.8190 - val_loss: 0.4059 - val_accuracy: 0.8426\n",
      "Epoch 211/250\n",
      "32/32 - 0s - loss: 0.4647 - accuracy: 0.8164 - val_loss: 0.4062 - val_accuracy: 0.8444\n",
      "Epoch 212/250\n",
      "32/32 - 0s - loss: 0.4658 - accuracy: 0.8175 - val_loss: 0.4091 - val_accuracy: 0.8418\n",
      "Epoch 213/250\n",
      "32/32 - 0s - loss: 0.4639 - accuracy: 0.8175 - val_loss: 0.4080 - val_accuracy: 0.8440\n",
      "Epoch 214/250\n",
      "32/32 - 0s - loss: 0.4609 - accuracy: 0.8186 - val_loss: 0.4083 - val_accuracy: 0.8400\n",
      "Epoch 215/250\n",
      "32/32 - 0s - loss: 0.4647 - accuracy: 0.8144 - val_loss: 0.4070 - val_accuracy: 0.8409\n",
      "Epoch 216/250\n",
      "32/32 - 0s - loss: 0.4670 - accuracy: 0.8177 - val_loss: 0.4093 - val_accuracy: 0.8400\n",
      "Epoch 217/250\n",
      "32/32 - 0s - loss: 0.4587 - accuracy: 0.8221 - val_loss: 0.4044 - val_accuracy: 0.8455\n",
      "Epoch 218/250\n",
      "32/32 - 0s - loss: 0.4574 - accuracy: 0.8263 - val_loss: 0.4057 - val_accuracy: 0.8411\n",
      "Epoch 219/250\n",
      "32/32 - 0s - loss: 0.4653 - accuracy: 0.8184 - val_loss: 0.4075 - val_accuracy: 0.8453\n",
      "Epoch 220/250\n",
      "32/32 - 0s - loss: 0.4673 - accuracy: 0.8199 - val_loss: 0.4081 - val_accuracy: 0.8424\n",
      "Epoch 221/250\n",
      "32/32 - 0s - loss: 0.4600 - accuracy: 0.8214 - val_loss: 0.4071 - val_accuracy: 0.8413\n",
      "Epoch 222/250\n",
      "32/32 - 0s - loss: 0.4571 - accuracy: 0.8204 - val_loss: 0.4025 - val_accuracy: 0.8445\n",
      "Epoch 223/250\n",
      "32/32 - 0s - loss: 0.4601 - accuracy: 0.8189 - val_loss: 0.4042 - val_accuracy: 0.8428\n",
      "Epoch 224/250\n",
      "32/32 - 0s - loss: 0.4567 - accuracy: 0.8234 - val_loss: 0.4072 - val_accuracy: 0.8411\n",
      "Epoch 225/250\n",
      "32/32 - 0s - loss: 0.4587 - accuracy: 0.8209 - val_loss: 0.4105 - val_accuracy: 0.8386\n",
      "Epoch 226/250\n",
      "32/32 - 0s - loss: 0.4596 - accuracy: 0.8220 - val_loss: 0.4033 - val_accuracy: 0.8441\n",
      "Epoch 227/250\n",
      "32/32 - 0s - loss: 0.4627 - accuracy: 0.8190 - val_loss: 0.4040 - val_accuracy: 0.8451\n",
      "Epoch 228/250\n",
      "32/32 - 0s - loss: 0.4588 - accuracy: 0.8216 - val_loss: 0.4026 - val_accuracy: 0.8440\n",
      "Epoch 229/250\n",
      "32/32 - 0s - loss: 0.4601 - accuracy: 0.8201 - val_loss: 0.4018 - val_accuracy: 0.8462\n",
      "Epoch 230/250\n",
      "32/32 - 0s - loss: 0.4612 - accuracy: 0.8188 - val_loss: 0.4043 - val_accuracy: 0.8468\n",
      "Epoch 231/250\n",
      "32/32 - 0s - loss: 0.4646 - accuracy: 0.8155 - val_loss: 0.4048 - val_accuracy: 0.8453\n",
      "Epoch 232/250\n",
      "32/32 - 0s - loss: 0.4584 - accuracy: 0.8204 - val_loss: 0.4038 - val_accuracy: 0.8440\n",
      "Epoch 233/250\n",
      "32/32 - 0s - loss: 0.4518 - accuracy: 0.8211 - val_loss: 0.4070 - val_accuracy: 0.8421\n",
      "Epoch 234/250\n",
      "32/32 - 0s - loss: 0.4610 - accuracy: 0.8198 - val_loss: 0.4043 - val_accuracy: 0.8428\n",
      "Epoch 235/250\n",
      "32/32 - 0s - loss: 0.4607 - accuracy: 0.8239 - val_loss: 0.4051 - val_accuracy: 0.8428\n",
      "Epoch 236/250\n",
      "32/32 - 0s - loss: 0.4540 - accuracy: 0.8205 - val_loss: 0.4029 - val_accuracy: 0.8446\n",
      "Epoch 237/250\n",
      "32/32 - 0s - loss: 0.4589 - accuracy: 0.8148 - val_loss: 0.4024 - val_accuracy: 0.8447\n",
      "Epoch 238/250\n",
      "32/32 - 0s - loss: 0.4636 - accuracy: 0.8186 - val_loss: 0.4026 - val_accuracy: 0.8475\n",
      "Epoch 239/250\n",
      "32/32 - 0s - loss: 0.4611 - accuracy: 0.8214 - val_loss: 0.4054 - val_accuracy: 0.8422\n",
      "Epoch 240/250\n",
      "32/32 - 0s - loss: 0.4554 - accuracy: 0.8211 - val_loss: 0.4034 - val_accuracy: 0.8435\n",
      "Epoch 241/250\n",
      "32/32 - 0s - loss: 0.4577 - accuracy: 0.8189 - val_loss: 0.4069 - val_accuracy: 0.8400\n",
      "Epoch 242/250\n",
      "32/32 - 0s - loss: 0.4608 - accuracy: 0.8169 - val_loss: 0.4059 - val_accuracy: 0.8459\n",
      "Epoch 243/250\n",
      "32/32 - 0s - loss: 0.4579 - accuracy: 0.8213 - val_loss: 0.4007 - val_accuracy: 0.8420\n",
      "Epoch 244/250\n",
      "32/32 - 0s - loss: 0.4571 - accuracy: 0.8201 - val_loss: 0.3997 - val_accuracy: 0.8472\n",
      "Epoch 245/250\n",
      "32/32 - 0s - loss: 0.4544 - accuracy: 0.8209 - val_loss: 0.4028 - val_accuracy: 0.8426\n",
      "Epoch 246/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4546 - accuracy: 0.8238 - val_loss: 0.4017 - val_accuracy: 0.8449\n",
      "Epoch 247/250\n",
      "32/32 - 0s - loss: 0.4555 - accuracy: 0.8224 - val_loss: 0.4031 - val_accuracy: 0.8469\n",
      "Epoch 248/250\n",
      "32/32 - 0s - loss: 0.4599 - accuracy: 0.8188 - val_loss: 0.4000 - val_accuracy: 0.8482\n",
      "Epoch 249/250\n",
      "32/32 - 0s - loss: 0.4602 - accuracy: 0.8175 - val_loss: 0.4003 - val_accuracy: 0.8428\n",
      "Epoch 250/250\n",
      "32/32 - 0s - loss: 0.4617 - accuracy: 0.8245 - val_loss: 0.4006 - val_accuracy: 0.8440\n"
     ]
    }
   ],
   "source": [
    "model = compile_model( fil = [5,5], k_size = [11,7], PoolSize = 2, dense = [10], learn_rate = 0.001)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size = 250, epochs = 250, \n",
    "                 validation_data = (x_train, y_train), \n",
    "                verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss is 0.82\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation loss is {model.evaluate(x_test, y_test, verbose = 0)[1]:1.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reshaping the model is working fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(np.argmax(y_test, axis =1),np.argmax(model.predict(x_test), axis=1),  normalize = 'true')\n",
    "\n",
    "\n",
    "#Better visualization of confusion matrices\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize = (15, 8))\n",
    "ax1.matshow(c_matrix, cmap = plt.cm.YlGn, alpha = 0.5)\n",
    "ax1.set_xticks(np.arange(3))\n",
    "ax1.set_yticks(np.arange(3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax1.text(x=j, y=i, s=round(c_matrix[i, j],2), ha=\"center\", va=\"center\")\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.set_xlabel('Predicted label')\n",
    "ax1.set_ylabel('True label')\n",
    "ax1.set_title('CNN')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Discrimination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1004 - accuracy: 0.3347 - val_loss: 1.0995 - val_accuracy: 0.3435\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.0998 - accuracy: 0.3309 - val_loss: 1.0990 - val_accuracy: 0.3395\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3326 - val_loss: 1.0990 - val_accuracy: 0.3490\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3392 - val_loss: 1.0988 - val_accuracy: 0.3535\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3425 - val_loss: 1.0989 - val_accuracy: 0.3455\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3397 - val_loss: 1.0989 - val_accuracy: 0.3500\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3347 - val_loss: 1.0989 - val_accuracy: 0.3440\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3374 - val_loss: 1.0990 - val_accuracy: 0.3510\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0988 - accuracy: 0.3376 - val_loss: 1.0989 - val_accuracy: 0.3495\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3433 - val_loss: 1.0990 - val_accuracy: 0.3460\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3429 - val_loss: 1.0990 - val_accuracy: 0.3455\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3419 - val_loss: 1.0990 - val_accuracy: 0.3435\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0988 - accuracy: 0.3377 - val_loss: 1.0991 - val_accuracy: 0.3430\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3408 - val_loss: 1.0991 - val_accuracy: 0.3435\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0978 - accuracy: 0.3421 - val_loss: 1.0992 - val_accuracy: 0.3430\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3514 - val_loss: 1.0992 - val_accuracy: 0.3425\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3454 - val_loss: 1.0991 - val_accuracy: 0.3390\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3445 - val_loss: 1.0990 - val_accuracy: 0.3380\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0981 - accuracy: 0.3425 - val_loss: 1.0990 - val_accuracy: 0.3450\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0976 - accuracy: 0.3469 - val_loss: 1.0990 - val_accuracy: 0.3385\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3434 - val_loss: 1.0991 - val_accuracy: 0.3420\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0977 - accuracy: 0.3442 - val_loss: 1.0991 - val_accuracy: 0.3440\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3433 - val_loss: 1.0990 - val_accuracy: 0.3425\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3481 - val_loss: 1.0991 - val_accuracy: 0.3395\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0976 - accuracy: 0.3498 - val_loss: 1.0992 - val_accuracy: 0.3455\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0978 - accuracy: 0.3490 - val_loss: 1.0992 - val_accuracy: 0.3355\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0974 - accuracy: 0.3498 - val_loss: 1.0992 - val_accuracy: 0.3400\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0969 - accuracy: 0.3473 - val_loss: 1.0992 - val_accuracy: 0.3360\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0970 - accuracy: 0.3454 - val_loss: 1.0993 - val_accuracy: 0.3325\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0971 - accuracy: 0.3455 - val_loss: 1.0992 - val_accuracy: 0.3430\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0972 - accuracy: 0.3447 - val_loss: 1.0992 - val_accuracy: 0.3415\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0973 - accuracy: 0.3447 - val_loss: 1.0992 - val_accuracy: 0.3360\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0974 - accuracy: 0.3460 - val_loss: 1.0992 - val_accuracy: 0.3290\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0968 - accuracy: 0.3575 - val_loss: 1.0993 - val_accuracy: 0.3330\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0968 - accuracy: 0.3506 - val_loss: 1.0993 - val_accuracy: 0.3280\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 1.0969 - accuracy: 0.3496 - val_loss: 1.0992 - val_accuracy: 0.3280\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 1.0970 - accuracy: 0.3494 - val_loss: 1.0993 - val_accuracy: 0.3270\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 1.0960 - accuracy: 0.3580 - val_loss: 1.0993 - val_accuracy: 0.3315\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0963 - accuracy: 0.3528 - val_loss: 1.0993 - val_accuracy: 0.3345\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 1.0971 - accuracy: 0.3439 - val_loss: 1.0994 - val_accuracy: 0.3270\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 1.0964 - accuracy: 0.3600 - val_loss: 1.0994 - val_accuracy: 0.3320\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 1.0963 - accuracy: 0.3577 - val_loss: 1.0994 - val_accuracy: 0.3230\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 1.0961 - accuracy: 0.3569 - val_loss: 1.0995 - val_accuracy: 0.3265\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3551 - val_loss: 1.0996 - val_accuracy: 0.3310\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3614 - val_loss: 1.0996 - val_accuracy: 0.3305\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3526 - val_loss: 1.0995 - val_accuracy: 0.3390\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 1.0955 - accuracy: 0.3584 - val_loss: 1.0995 - val_accuracy: 0.3370\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3571 - val_loss: 1.0995 - val_accuracy: 0.3355\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 1.0950 - accuracy: 0.3606 - val_loss: 1.0995 - val_accuracy: 0.3360\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 1.0950 - accuracy: 0.3594 - val_loss: 1.0996 - val_accuracy: 0.3350\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3610 - val_loss: 1.0996 - val_accuracy: 0.3360\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 1.0952 - accuracy: 0.3576 - val_loss: 1.0998 - val_accuracy: 0.3370\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 1.0955 - accuracy: 0.3532 - val_loss: 1.0999 - val_accuracy: 0.3290\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 1.0953 - accuracy: 0.3641 - val_loss: 1.0999 - val_accuracy: 0.3350\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 1.0953 - accuracy: 0.3579 - val_loss: 1.1000 - val_accuracy: 0.3405\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 1.0943 - accuracy: 0.3658 - val_loss: 1.1001 - val_accuracy: 0.3340\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 1.0944 - accuracy: 0.3630 - val_loss: 1.1002 - val_accuracy: 0.3370\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 1.0939 - accuracy: 0.3668 - val_loss: 1.1002 - val_accuracy: 0.3385\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 1.0951 - accuracy: 0.3540 - val_loss: 1.1001 - val_accuracy: 0.3375\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 1.0947 - accuracy: 0.3626 - val_loss: 1.1003 - val_accuracy: 0.3355\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 1.0947 - accuracy: 0.3580 - val_loss: 1.1002 - val_accuracy: 0.3355\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 1.0936 - accuracy: 0.3632 - val_loss: 1.1004 - val_accuracy: 0.3360\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 1.0936 - accuracy: 0.3611 - val_loss: 1.1005 - val_accuracy: 0.3345\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 1.0943 - accuracy: 0.3641 - val_loss: 1.1006 - val_accuracy: 0.3355\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 1.0944 - accuracy: 0.3535 - val_loss: 1.1009 - val_accuracy: 0.3360\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 1.0941 - accuracy: 0.3632 - val_loss: 1.1004 - val_accuracy: 0.3355\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 1.0931 - accuracy: 0.3651 - val_loss: 1.1008 - val_accuracy: 0.3335\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 1.0936 - accuracy: 0.3665 - val_loss: 1.1010 - val_accuracy: 0.3275\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 1.0934 - accuracy: 0.3660 - val_loss: 1.1007 - val_accuracy: 0.3300\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 1.0931 - accuracy: 0.3669 - val_loss: 1.1012 - val_accuracy: 0.3330\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 1.0930 - accuracy: 0.3672 - val_loss: 1.1009 - val_accuracy: 0.3320\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 1.0934 - accuracy: 0.3652 - val_loss: 1.1011 - val_accuracy: 0.3370\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 1.0924 - accuracy: 0.3705 - val_loss: 1.1014 - val_accuracy: 0.3315\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 1.0925 - accuracy: 0.3685 - val_loss: 1.1016 - val_accuracy: 0.3320\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3694 - val_loss: 1.1015 - val_accuracy: 0.3260\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 1.0931 - accuracy: 0.3684 - val_loss: 1.1020 - val_accuracy: 0.3205\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 1.0927 - accuracy: 0.3675 - val_loss: 1.1015 - val_accuracy: 0.3295\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 1.0919 - accuracy: 0.3669 - val_loss: 1.1014 - val_accuracy: 0.3340\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3636 - val_loss: 1.1021 - val_accuracy: 0.3375\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 1.0922 - accuracy: 0.3684 - val_loss: 1.1021 - val_accuracy: 0.3260\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 1.0917 - accuracy: 0.3745 - val_loss: 1.1019 - val_accuracy: 0.3265\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 1.0914 - accuracy: 0.3700 - val_loss: 1.1020 - val_accuracy: 0.3295\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 1.0925 - accuracy: 0.3726 - val_loss: 1.1023 - val_accuracy: 0.3295\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 1.0920 - accuracy: 0.3688 - val_loss: 1.1017 - val_accuracy: 0.3310\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 1.0921 - accuracy: 0.3640 - val_loss: 1.1023 - val_accuracy: 0.3275\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 1.0911 - accuracy: 0.3714 - val_loss: 1.1030 - val_accuracy: 0.3280\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 1.0922 - accuracy: 0.3654 - val_loss: 1.1024 - val_accuracy: 0.3405\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 1.0917 - accuracy: 0.3664 - val_loss: 1.1027 - val_accuracy: 0.3270\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 1.0915 - accuracy: 0.3666 - val_loss: 1.1026 - val_accuracy: 0.3295\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 1.0916 - accuracy: 0.3690 - val_loss: 1.1023 - val_accuracy: 0.3300\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 1.0903 - accuracy: 0.3747 - val_loss: 1.1036 - val_accuracy: 0.3270\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 1.0903 - accuracy: 0.3746 - val_loss: 1.1036 - val_accuracy: 0.3270\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 1.0908 - accuracy: 0.3735 - val_loss: 1.1029 - val_accuracy: 0.3340\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 1.0898 - accuracy: 0.3758 - val_loss: 1.1038 - val_accuracy: 0.3235\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 1.0900 - accuracy: 0.3734 - val_loss: 1.1028 - val_accuracy: 0.3345\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 1.0897 - accuracy: 0.3781 - val_loss: 1.1033 - val_accuracy: 0.3370\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 1.0896 - accuracy: 0.3730 - val_loss: 1.1034 - val_accuracy: 0.3335\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 1.0893 - accuracy: 0.3767 - val_loss: 1.1036 - val_accuracy: 0.3335\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 1.0886 - accuracy: 0.3779 - val_loss: 1.1043 - val_accuracy: 0.3280\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 1.0885 - accuracy: 0.3819 - val_loss: 1.1045 - val_accuracy: 0.3315\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 1.0899 - accuracy: 0.3750 - val_loss: 1.1040 - val_accuracy: 0.3320\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 1.0890 - accuracy: 0.3761 - val_loss: 1.1044 - val_accuracy: 0.3355\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 1.0887 - accuracy: 0.3776 - val_loss: 1.1045 - val_accuracy: 0.3390\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 1.0898 - accuracy: 0.3728 - val_loss: 1.1041 - val_accuracy: 0.3280\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 1.0890 - accuracy: 0.3821 - val_loss: 1.1040 - val_accuracy: 0.3335\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 1.0888 - accuracy: 0.3766 - val_loss: 1.1043 - val_accuracy: 0.3330\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 1.0890 - accuracy: 0.3735 - val_loss: 1.1047 - val_accuracy: 0.3365\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 1.0886 - accuracy: 0.3765 - val_loss: 1.1039 - val_accuracy: 0.3340\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 1.0888 - accuracy: 0.3809 - val_loss: 1.1048 - val_accuracy: 0.3365\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 1.0877 - accuracy: 0.3790 - val_loss: 1.1047 - val_accuracy: 0.3315\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 1.0874 - accuracy: 0.3796 - val_loss: 1.1041 - val_accuracy: 0.3395\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 1.0884 - accuracy: 0.3776 - val_loss: 1.1048 - val_accuracy: 0.3355\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 1.0868 - accuracy: 0.3812 - val_loss: 1.1051 - val_accuracy: 0.3345\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 1.0881 - accuracy: 0.3761 - val_loss: 1.1051 - val_accuracy: 0.3325\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 1.0867 - accuracy: 0.3783 - val_loss: 1.1051 - val_accuracy: 0.3400\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 1.0884 - accuracy: 0.3778 - val_loss: 1.1043 - val_accuracy: 0.3375\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 1.0853 - accuracy: 0.3844 - val_loss: 1.1051 - val_accuracy: 0.3350\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 1.0875 - accuracy: 0.3742 - val_loss: 1.1053 - val_accuracy: 0.3325\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 1.0872 - accuracy: 0.3839 - val_loss: 1.1052 - val_accuracy: 0.3325\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 1.0857 - accuracy: 0.3817 - val_loss: 1.1047 - val_accuracy: 0.3410\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 1.0867 - accuracy: 0.3814 - val_loss: 1.1058 - val_accuracy: 0.3420\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 1.0863 - accuracy: 0.3765 - val_loss: 1.1052 - val_accuracy: 0.3305\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 1.0863 - accuracy: 0.3831 - val_loss: 1.1059 - val_accuracy: 0.3365\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 1.0848 - accuracy: 0.3800 - val_loss: 1.1057 - val_accuracy: 0.3370\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 1.0852 - accuracy: 0.3866 - val_loss: 1.1059 - val_accuracy: 0.3305\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 1.0845 - accuracy: 0.3828 - val_loss: 1.1062 - val_accuracy: 0.3315\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 1.0860 - accuracy: 0.3842 - val_loss: 1.1056 - val_accuracy: 0.3340\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 1.0861 - accuracy: 0.3832 - val_loss: 1.1052 - val_accuracy: 0.3380\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 1.0841 - accuracy: 0.3808 - val_loss: 1.1059 - val_accuracy: 0.3380\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 1.0840 - accuracy: 0.3887 - val_loss: 1.1068 - val_accuracy: 0.3355\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 1.0855 - accuracy: 0.3792 - val_loss: 1.1065 - val_accuracy: 0.3370\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 1.0845 - accuracy: 0.3864 - val_loss: 1.1056 - val_accuracy: 0.3410\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 1.0850 - accuracy: 0.3864 - val_loss: 1.1059 - val_accuracy: 0.3435\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 1.0840 - accuracy: 0.3885 - val_loss: 1.1062 - val_accuracy: 0.3370\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 1.0833 - accuracy: 0.3845 - val_loss: 1.1059 - val_accuracy: 0.3320\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 1.0828 - accuracy: 0.3880 - val_loss: 1.1068 - val_accuracy: 0.3455\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 1.0821 - accuracy: 0.3896 - val_loss: 1.1074 - val_accuracy: 0.3285\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 1.0817 - accuracy: 0.3895 - val_loss: 1.1067 - val_accuracy: 0.3385\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 1.0833 - accuracy: 0.3885 - val_loss: 1.1060 - val_accuracy: 0.3450\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 1.0825 - accuracy: 0.3880 - val_loss: 1.1073 - val_accuracy: 0.3320\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 1.0817 - accuracy: 0.3866 - val_loss: 1.1073 - val_accuracy: 0.3400\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 1.0825 - accuracy: 0.3914 - val_loss: 1.1078 - val_accuracy: 0.3405\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 1.0826 - accuracy: 0.3873 - val_loss: 1.1072 - val_accuracy: 0.3360\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 1.0810 - accuracy: 0.3899 - val_loss: 1.1074 - val_accuracy: 0.3380\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 1.0813 - accuracy: 0.3914 - val_loss: 1.1072 - val_accuracy: 0.3315\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 1.0817 - accuracy: 0.3915 - val_loss: 1.1086 - val_accuracy: 0.3280\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 1.0835 - accuracy: 0.3830 - val_loss: 1.1076 - val_accuracy: 0.3450\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 1.0806 - accuracy: 0.3901 - val_loss: 1.1083 - val_accuracy: 0.3350\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 1.0806 - accuracy: 0.3855 - val_loss: 1.1079 - val_accuracy: 0.3315\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 1.0816 - accuracy: 0.3947 - val_loss: 1.1080 - val_accuracy: 0.3360\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1019 - accuracy: 0.3327 - val_loss: 1.0999 - val_accuracy: 0.3330\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.0999 - accuracy: 0.3299 - val_loss: 1.0994 - val_accuracy: 0.3320\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0996 - accuracy: 0.3304 - val_loss: 1.0992 - val_accuracy: 0.3345\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3299 - val_loss: 1.0990 - val_accuracy: 0.3440\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3372 - val_loss: 1.0989 - val_accuracy: 0.3400\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3410 - val_loss: 1.0989 - val_accuracy: 0.3355\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3397 - val_loss: 1.0988 - val_accuracy: 0.3465\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3449 - val_loss: 1.0988 - val_accuracy: 0.3410\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3521 - val_loss: 1.0988 - val_accuracy: 0.3440\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0976 - accuracy: 0.3475 - val_loss: 1.0987 - val_accuracy: 0.3455\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3428 - val_loss: 1.0987 - val_accuracy: 0.3550\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0975 - accuracy: 0.3517 - val_loss: 1.0988 - val_accuracy: 0.3305\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0976 - accuracy: 0.3539 - val_loss: 1.0989 - val_accuracy: 0.3435\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0974 - accuracy: 0.3499 - val_loss: 1.0988 - val_accuracy: 0.3360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0972 - accuracy: 0.3584 - val_loss: 1.0989 - val_accuracy: 0.3395\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0970 - accuracy: 0.3537 - val_loss: 1.0989 - val_accuracy: 0.3320\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0971 - accuracy: 0.3525 - val_loss: 1.0990 - val_accuracy: 0.3360\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0965 - accuracy: 0.3638 - val_loss: 1.0990 - val_accuracy: 0.3405\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3610 - val_loss: 1.0992 - val_accuracy: 0.3300\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3616 - val_loss: 1.0991 - val_accuracy: 0.3415\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3582 - val_loss: 1.0989 - val_accuracy: 0.3370\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0960 - accuracy: 0.3568 - val_loss: 1.0989 - val_accuracy: 0.3455\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3591 - val_loss: 1.0989 - val_accuracy: 0.3480\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0954 - accuracy: 0.3569 - val_loss: 1.0992 - val_accuracy: 0.3435\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0954 - accuracy: 0.3579 - val_loss: 1.0989 - val_accuracy: 0.3480\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3566 - val_loss: 1.0987 - val_accuracy: 0.3540\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0952 - accuracy: 0.3604 - val_loss: 1.0989 - val_accuracy: 0.3510\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0952 - accuracy: 0.3575 - val_loss: 1.0989 - val_accuracy: 0.3480\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0946 - accuracy: 0.3676 - val_loss: 1.0993 - val_accuracy: 0.3370\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0939 - accuracy: 0.3697 - val_loss: 1.0991 - val_accuracy: 0.3420\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0950 - accuracy: 0.3611 - val_loss: 1.0990 - val_accuracy: 0.3520\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0946 - accuracy: 0.3696 - val_loss: 1.0994 - val_accuracy: 0.3430\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0941 - accuracy: 0.3640 - val_loss: 1.0991 - val_accuracy: 0.3485\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0941 - accuracy: 0.3665 - val_loss: 1.0993 - val_accuracy: 0.3440\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0929 - accuracy: 0.3724 - val_loss: 1.0993 - val_accuracy: 0.3515\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 1.0935 - accuracy: 0.3719 - val_loss: 1.0994 - val_accuracy: 0.3475\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 1.0932 - accuracy: 0.3649 - val_loss: 1.0997 - val_accuracy: 0.3555\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 1.0933 - accuracy: 0.3686 - val_loss: 1.1001 - val_accuracy: 0.3510\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0927 - accuracy: 0.3686 - val_loss: 1.0998 - val_accuracy: 0.3435\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 1.0923 - accuracy: 0.3681 - val_loss: 1.0994 - val_accuracy: 0.3535\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 1.0913 - accuracy: 0.3781 - val_loss: 1.0997 - val_accuracy: 0.3465\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 1.0921 - accuracy: 0.3746 - val_loss: 1.0991 - val_accuracy: 0.3570\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 1.0922 - accuracy: 0.3744 - val_loss: 1.1004 - val_accuracy: 0.3440\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 1.0915 - accuracy: 0.3730 - val_loss: 1.0997 - val_accuracy: 0.3530\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 1.0912 - accuracy: 0.3756 - val_loss: 1.0997 - val_accuracy: 0.3550\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 1.0919 - accuracy: 0.3708 - val_loss: 1.0995 - val_accuracy: 0.3545\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 1.0911 - accuracy: 0.3744 - val_loss: 1.1005 - val_accuracy: 0.3495\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 1.0914 - accuracy: 0.3716 - val_loss: 1.0996 - val_accuracy: 0.3515\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 1.0897 - accuracy: 0.3798 - val_loss: 1.0998 - val_accuracy: 0.3560\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 1.0910 - accuracy: 0.3771 - val_loss: 1.1003 - val_accuracy: 0.3465\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 1.0908 - accuracy: 0.3784 - val_loss: 1.1003 - val_accuracy: 0.3490\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 1.0904 - accuracy: 0.3708 - val_loss: 1.1006 - val_accuracy: 0.3475\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 1.0892 - accuracy: 0.3875 - val_loss: 1.1003 - val_accuracy: 0.3460\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 1.0902 - accuracy: 0.3756 - val_loss: 1.1000 - val_accuracy: 0.3530\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 1.0898 - accuracy: 0.3779 - val_loss: 1.1004 - val_accuracy: 0.3520\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 1.0889 - accuracy: 0.3825 - val_loss: 1.1017 - val_accuracy: 0.3390\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 1.0900 - accuracy: 0.3733 - val_loss: 1.1009 - val_accuracy: 0.3485\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 1.0892 - accuracy: 0.3815 - val_loss: 1.1010 - val_accuracy: 0.3465\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 1.0899 - accuracy: 0.3734 - val_loss: 1.1012 - val_accuracy: 0.3355\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 1.0890 - accuracy: 0.3849 - val_loss: 1.1009 - val_accuracy: 0.3485\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 1.0877 - accuracy: 0.3828 - val_loss: 1.1011 - val_accuracy: 0.3425\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 1.0877 - accuracy: 0.3844 - val_loss: 1.1021 - val_accuracy: 0.3420\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 1.0874 - accuracy: 0.3891 - val_loss: 1.1012 - val_accuracy: 0.3415\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 1.0888 - accuracy: 0.3776 - val_loss: 1.1015 - val_accuracy: 0.3495\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 1.0882 - accuracy: 0.3835 - val_loss: 1.1012 - val_accuracy: 0.3520\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 1.0871 - accuracy: 0.3879 - val_loss: 1.1018 - val_accuracy: 0.3450\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 1.0861 - accuracy: 0.3842 - val_loss: 1.1021 - val_accuracy: 0.3540\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 1.0866 - accuracy: 0.3898 - val_loss: 1.1017 - val_accuracy: 0.3540\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 1.0865 - accuracy: 0.3929 - val_loss: 1.1031 - val_accuracy: 0.3380\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 1.0860 - accuracy: 0.3850 - val_loss: 1.1038 - val_accuracy: 0.3390\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 1.0868 - accuracy: 0.3879 - val_loss: 1.1027 - val_accuracy: 0.3465\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 1.0862 - accuracy: 0.3934 - val_loss: 1.1034 - val_accuracy: 0.3455\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 1.0857 - accuracy: 0.3921 - val_loss: 1.1027 - val_accuracy: 0.3495\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 1.0871 - accuracy: 0.3853 - val_loss: 1.1027 - val_accuracy: 0.3465\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 1.0845 - accuracy: 0.3913 - val_loss: 1.1031 - val_accuracy: 0.3465\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 1.0853 - accuracy: 0.3896 - val_loss: 1.1042 - val_accuracy: 0.3485\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 1.0855 - accuracy: 0.3837 - val_loss: 1.1029 - val_accuracy: 0.3540\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 1.0855 - accuracy: 0.3864 - val_loss: 1.1036 - val_accuracy: 0.3520\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 1.0844 - accuracy: 0.3918 - val_loss: 1.1031 - val_accuracy: 0.3510\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 1.0868 - accuracy: 0.3899 - val_loss: 1.1033 - val_accuracy: 0.3555\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 1.0842 - accuracy: 0.3920 - val_loss: 1.1054 - val_accuracy: 0.3495\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 1.0836 - accuracy: 0.3911 - val_loss: 1.1036 - val_accuracy: 0.3485\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 1.0827 - accuracy: 0.3943 - val_loss: 1.1054 - val_accuracy: 0.3590\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 1.0840 - accuracy: 0.3895 - val_loss: 1.1043 - val_accuracy: 0.3515\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 1.0850 - accuracy: 0.3929 - val_loss: 1.1056 - val_accuracy: 0.3540\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 1.0813 - accuracy: 0.3969 - val_loss: 1.1057 - val_accuracy: 0.3520\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 1.0834 - accuracy: 0.3943 - val_loss: 1.1064 - val_accuracy: 0.3430\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 1.0814 - accuracy: 0.3918 - val_loss: 1.1056 - val_accuracy: 0.3460\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 1.0819 - accuracy: 0.3934 - val_loss: 1.1074 - val_accuracy: 0.3480\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 1.0824 - accuracy: 0.3925 - val_loss: 1.1053 - val_accuracy: 0.3490\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 1.0817 - accuracy: 0.3945 - val_loss: 1.1072 - val_accuracy: 0.3485\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 1.0821 - accuracy: 0.3963 - val_loss: 1.1065 - val_accuracy: 0.3500\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 1.0808 - accuracy: 0.3985 - val_loss: 1.1077 - val_accuracy: 0.3395\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 1.0811 - accuracy: 0.3940 - val_loss: 1.1071 - val_accuracy: 0.3445\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 1.0807 - accuracy: 0.3977 - val_loss: 1.1066 - val_accuracy: 0.3485\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 1.0806 - accuracy: 0.3946 - val_loss: 1.1071 - val_accuracy: 0.3475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 1.0804 - accuracy: 0.3931 - val_loss: 1.1085 - val_accuracy: 0.3485\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 1.0796 - accuracy: 0.3979 - val_loss: 1.1085 - val_accuracy: 0.3470\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 1.0798 - accuracy: 0.3970 - val_loss: 1.1066 - val_accuracy: 0.3470\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 1.0790 - accuracy: 0.3971 - val_loss: 1.1080 - val_accuracy: 0.3360\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 1.0779 - accuracy: 0.4044 - val_loss: 1.1098 - val_accuracy: 0.3430\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 1.0776 - accuracy: 0.4027 - val_loss: 1.1088 - val_accuracy: 0.3470\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 1.0798 - accuracy: 0.3943 - val_loss: 1.1082 - val_accuracy: 0.3515\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 1.0786 - accuracy: 0.4001 - val_loss: 1.1085 - val_accuracy: 0.3405\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 1.0795 - accuracy: 0.3974 - val_loss: 1.1090 - val_accuracy: 0.3405\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 1.0775 - accuracy: 0.4002 - val_loss: 1.1098 - val_accuracy: 0.3455\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 1.0770 - accuracy: 0.4044 - val_loss: 1.1106 - val_accuracy: 0.3500\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 1.0764 - accuracy: 0.4029 - val_loss: 1.1087 - val_accuracy: 0.3465\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 1.0786 - accuracy: 0.3944 - val_loss: 1.1092 - val_accuracy: 0.3465\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 1.0756 - accuracy: 0.4000 - val_loss: 1.1113 - val_accuracy: 0.3420\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 1.0761 - accuracy: 0.4055 - val_loss: 1.1118 - val_accuracy: 0.3405\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 1.0769 - accuracy: 0.3977 - val_loss: 1.1107 - val_accuracy: 0.3440\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 1.0756 - accuracy: 0.4059 - val_loss: 1.1125 - val_accuracy: 0.3350\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 1.0762 - accuracy: 0.4036 - val_loss: 1.1109 - val_accuracy: 0.3415\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 1.0770 - accuracy: 0.3999 - val_loss: 1.1112 - val_accuracy: 0.3405\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 1.0743 - accuracy: 0.4027 - val_loss: 1.1111 - val_accuracy: 0.3445\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 1.0767 - accuracy: 0.4005 - val_loss: 1.1124 - val_accuracy: 0.3380\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 1.0767 - accuracy: 0.3964 - val_loss: 1.1122 - val_accuracy: 0.3385\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 1.0749 - accuracy: 0.4020 - val_loss: 1.1136 - val_accuracy: 0.3390\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 1.0747 - accuracy: 0.4009 - val_loss: 1.1134 - val_accuracy: 0.3365\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 1.0740 - accuracy: 0.4058 - val_loss: 1.1142 - val_accuracy: 0.3360\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 1.0751 - accuracy: 0.4074 - val_loss: 1.1117 - val_accuracy: 0.3400\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 1.0743 - accuracy: 0.4081 - val_loss: 1.1138 - val_accuracy: 0.3500\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 1.0778 - accuracy: 0.4002 - val_loss: 1.1143 - val_accuracy: 0.3400\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 1.0753 - accuracy: 0.4078 - val_loss: 1.1141 - val_accuracy: 0.3420\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 1.0722 - accuracy: 0.4064 - val_loss: 1.1147 - val_accuracy: 0.3440\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 1.0737 - accuracy: 0.4081 - val_loss: 1.1135 - val_accuracy: 0.3330\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 1.0744 - accuracy: 0.4015 - val_loss: 1.1164 - val_accuracy: 0.3335\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 1.0736 - accuracy: 0.4039 - val_loss: 1.1154 - val_accuracy: 0.3440\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 1.0717 - accuracy: 0.4094 - val_loss: 1.1153 - val_accuracy: 0.3370\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 1.0745 - accuracy: 0.4025 - val_loss: 1.1151 - val_accuracy: 0.3360\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 1.0736 - accuracy: 0.4074 - val_loss: 1.1143 - val_accuracy: 0.3415\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 1.0721 - accuracy: 0.4078 - val_loss: 1.1159 - val_accuracy: 0.3420\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 1.0718 - accuracy: 0.4045 - val_loss: 1.1170 - val_accuracy: 0.3415\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 1.0700 - accuracy: 0.4169 - val_loss: 1.1194 - val_accuracy: 0.3365\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 1.0745 - accuracy: 0.4034 - val_loss: 1.1168 - val_accuracy: 0.3335\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 1.0731 - accuracy: 0.4058 - val_loss: 1.1171 - val_accuracy: 0.3425\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 1.0733 - accuracy: 0.4069 - val_loss: 1.1156 - val_accuracy: 0.3445\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 1.0708 - accuracy: 0.4141 - val_loss: 1.1188 - val_accuracy: 0.3350\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 1.0715 - accuracy: 0.4080 - val_loss: 1.1173 - val_accuracy: 0.3410\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 1.0699 - accuracy: 0.4149 - val_loss: 1.1167 - val_accuracy: 0.3380\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 1.0710 - accuracy: 0.4054 - val_loss: 1.1156 - val_accuracy: 0.3425\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 1.0715 - accuracy: 0.4081 - val_loss: 1.1184 - val_accuracy: 0.3395\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 1.0712 - accuracy: 0.4148 - val_loss: 1.1183 - val_accuracy: 0.3495\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 1.0703 - accuracy: 0.4064 - val_loss: 1.1193 - val_accuracy: 0.3375\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 1.0692 - accuracy: 0.4109 - val_loss: 1.1179 - val_accuracy: 0.3430\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 1.0688 - accuracy: 0.4125 - val_loss: 1.1194 - val_accuracy: 0.3380\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 1.0688 - accuracy: 0.4083 - val_loss: 1.1216 - val_accuracy: 0.3405\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 1.0685 - accuracy: 0.4096 - val_loss: 1.1217 - val_accuracy: 0.3320\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 1.0678 - accuracy: 0.4126 - val_loss: 1.1208 - val_accuracy: 0.3405\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1014 - accuracy: 0.3232 - val_loss: 1.1003 - val_accuracy: 0.3275\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.0997 - accuracy: 0.3356 - val_loss: 1.0994 - val_accuracy: 0.3325\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0991 - accuracy: 0.3369 - val_loss: 1.0992 - val_accuracy: 0.3310\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3365 - val_loss: 1.0990 - val_accuracy: 0.3375\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3384 - val_loss: 1.0991 - val_accuracy: 0.3355\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0987 - accuracy: 0.3405 - val_loss: 1.0990 - val_accuracy: 0.3395\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3487 - val_loss: 1.0990 - val_accuracy: 0.3310\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3434 - val_loss: 1.0988 - val_accuracy: 0.3450\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0981 - accuracy: 0.3458 - val_loss: 1.0987 - val_accuracy: 0.3465\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0978 - accuracy: 0.3524 - val_loss: 1.0988 - val_accuracy: 0.3410\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0977 - accuracy: 0.3483 - val_loss: 1.0989 - val_accuracy: 0.3410\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0974 - accuracy: 0.3532 - val_loss: 1.0988 - val_accuracy: 0.3365\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0971 - accuracy: 0.3536 - val_loss: 1.0989 - val_accuracy: 0.3445\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0973 - accuracy: 0.3455 - val_loss: 1.0990 - val_accuracy: 0.3365\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0967 - accuracy: 0.3505 - val_loss: 1.0989 - val_accuracy: 0.3325\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0970 - accuracy: 0.3530 - val_loss: 1.0989 - val_accuracy: 0.3335\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0964 - accuracy: 0.3614 - val_loss: 1.0991 - val_accuracy: 0.3345\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3604 - val_loss: 1.0993 - val_accuracy: 0.3360\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3625 - val_loss: 1.0993 - val_accuracy: 0.3320\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0963 - accuracy: 0.3524 - val_loss: 1.0991 - val_accuracy: 0.3350\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0967 - accuracy: 0.3611 - val_loss: 1.0992 - val_accuracy: 0.3265\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0959 - accuracy: 0.3568 - val_loss: 1.0994 - val_accuracy: 0.3300\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0964 - accuracy: 0.3606 - val_loss: 1.0992 - val_accuracy: 0.3320\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3690 - val_loss: 1.0998 - val_accuracy: 0.3350\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0951 - accuracy: 0.3663 - val_loss: 1.0991 - val_accuracy: 0.3310\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0952 - accuracy: 0.3620 - val_loss: 1.0997 - val_accuracy: 0.3305\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0950 - accuracy: 0.3618 - val_loss: 1.0994 - val_accuracy: 0.3295\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0947 - accuracy: 0.3668 - val_loss: 1.0995 - val_accuracy: 0.3285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3615 - val_loss: 1.0992 - val_accuracy: 0.3295\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0948 - accuracy: 0.3632 - val_loss: 1.0993 - val_accuracy: 0.3345\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0943 - accuracy: 0.3680 - val_loss: 1.0990 - val_accuracy: 0.3335\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0944 - accuracy: 0.3670 - val_loss: 1.0990 - val_accuracy: 0.3310\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0933 - accuracy: 0.3699 - val_loss: 1.0998 - val_accuracy: 0.3235\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0935 - accuracy: 0.3691 - val_loss: 1.0992 - val_accuracy: 0.3280\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0942 - accuracy: 0.3613 - val_loss: 1.0986 - val_accuracy: 0.3335\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 1.0928 - accuracy: 0.3747 - val_loss: 1.0994 - val_accuracy: 0.3270\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 1.0933 - accuracy: 0.3705 - val_loss: 1.0989 - val_accuracy: 0.3290\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 1.0928 - accuracy: 0.3669 - val_loss: 1.0989 - val_accuracy: 0.3275\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0921 - accuracy: 0.3680 - val_loss: 1.0984 - val_accuracy: 0.3355\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 1.0918 - accuracy: 0.3695 - val_loss: 1.0987 - val_accuracy: 0.3300\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 1.0922 - accuracy: 0.3779 - val_loss: 1.0986 - val_accuracy: 0.3300\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 1.0919 - accuracy: 0.3772 - val_loss: 1.0987 - val_accuracy: 0.3310\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 1.0920 - accuracy: 0.3715 - val_loss: 1.0989 - val_accuracy: 0.3350\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 1.0895 - accuracy: 0.3803 - val_loss: 1.0987 - val_accuracy: 0.3375\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 1.0908 - accuracy: 0.3815 - val_loss: 1.0983 - val_accuracy: 0.3350\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 1.0906 - accuracy: 0.3676 - val_loss: 1.0982 - val_accuracy: 0.3430\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 1.0910 - accuracy: 0.3694 - val_loss: 1.0975 - val_accuracy: 0.3480\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 1.0894 - accuracy: 0.3728 - val_loss: 1.0979 - val_accuracy: 0.3395\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 1.0892 - accuracy: 0.3834 - val_loss: 1.0979 - val_accuracy: 0.3405\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 1.0873 - accuracy: 0.3781 - val_loss: 1.0989 - val_accuracy: 0.3405\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 1.0894 - accuracy: 0.3794 - val_loss: 1.0979 - val_accuracy: 0.3335\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 1.0883 - accuracy: 0.3830 - val_loss: 1.0972 - val_accuracy: 0.3450\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 1.0879 - accuracy: 0.3887 - val_loss: 1.0983 - val_accuracy: 0.3430\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 1.0876 - accuracy: 0.3853 - val_loss: 1.0971 - val_accuracy: 0.3465\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 1.0870 - accuracy: 0.3890 - val_loss: 1.0989 - val_accuracy: 0.3440\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 1.0877 - accuracy: 0.3854 - val_loss: 1.0984 - val_accuracy: 0.3460\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 1.0871 - accuracy: 0.3849 - val_loss: 1.0974 - val_accuracy: 0.3470\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 1.0862 - accuracy: 0.3856 - val_loss: 1.0980 - val_accuracy: 0.3415\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 1.0862 - accuracy: 0.3851 - val_loss: 1.0985 - val_accuracy: 0.3430\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 1.0862 - accuracy: 0.3825 - val_loss: 1.0977 - val_accuracy: 0.3495\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 1.0859 - accuracy: 0.3904 - val_loss: 1.0975 - val_accuracy: 0.3515\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 1.0846 - accuracy: 0.3919 - val_loss: 1.0987 - val_accuracy: 0.3490\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 1.0855 - accuracy: 0.3918 - val_loss: 1.0983 - val_accuracy: 0.3500\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 1.0850 - accuracy: 0.3902 - val_loss: 1.0975 - val_accuracy: 0.3575\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 1.0842 - accuracy: 0.3929 - val_loss: 1.0991 - val_accuracy: 0.3505\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 1.0841 - accuracy: 0.3905 - val_loss: 1.0984 - val_accuracy: 0.3535\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 1.0839 - accuracy: 0.3923 - val_loss: 1.0986 - val_accuracy: 0.3480\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 1.0827 - accuracy: 0.3926 - val_loss: 1.0985 - val_accuracy: 0.3435\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 1.0829 - accuracy: 0.3946 - val_loss: 1.1002 - val_accuracy: 0.3520\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 1.0823 - accuracy: 0.3900 - val_loss: 1.0999 - val_accuracy: 0.3430\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 1.0810 - accuracy: 0.3956 - val_loss: 1.0988 - val_accuracy: 0.3530\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 1.0818 - accuracy: 0.3936 - val_loss: 1.0997 - val_accuracy: 0.3495\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 1.0822 - accuracy: 0.3974 - val_loss: 1.0990 - val_accuracy: 0.3515\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 1.0825 - accuracy: 0.3952 - val_loss: 1.0990 - val_accuracy: 0.3510\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 1.0817 - accuracy: 0.3949 - val_loss: 1.0983 - val_accuracy: 0.3575\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 1.0803 - accuracy: 0.4034 - val_loss: 1.0994 - val_accuracy: 0.3605\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 1.0801 - accuracy: 0.3983 - val_loss: 1.0992 - val_accuracy: 0.3530\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 1.0807 - accuracy: 0.3977 - val_loss: 1.0992 - val_accuracy: 0.3495\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 1.0808 - accuracy: 0.3901 - val_loss: 1.0996 - val_accuracy: 0.3620\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 1.0783 - accuracy: 0.4072 - val_loss: 1.0994 - val_accuracy: 0.3545\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 1.0788 - accuracy: 0.4006 - val_loss: 1.1011 - val_accuracy: 0.3545\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 1.0781 - accuracy: 0.3986 - val_loss: 1.0979 - val_accuracy: 0.3705\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 1.0793 - accuracy: 0.4006 - val_loss: 1.0997 - val_accuracy: 0.3565\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 1.0785 - accuracy: 0.3996 - val_loss: 1.0989 - val_accuracy: 0.3595\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 1.0791 - accuracy: 0.4017 - val_loss: 1.0996 - val_accuracy: 0.3685\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 1.0785 - accuracy: 0.3966 - val_loss: 1.1009 - val_accuracy: 0.3580\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 1.0779 - accuracy: 0.4051 - val_loss: 1.1004 - val_accuracy: 0.3615\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 1.0772 - accuracy: 0.3997 - val_loss: 1.1012 - val_accuracy: 0.3570\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 1.0774 - accuracy: 0.4067 - val_loss: 1.1016 - val_accuracy: 0.3545\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 1.0767 - accuracy: 0.4062 - val_loss: 1.0999 - val_accuracy: 0.3575\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 1.0784 - accuracy: 0.4031 - val_loss: 1.0996 - val_accuracy: 0.3630\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 1.0774 - accuracy: 0.4008 - val_loss: 1.1010 - val_accuracy: 0.3625\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 1.0762 - accuracy: 0.4038 - val_loss: 1.1003 - val_accuracy: 0.3565\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 1.0741 - accuracy: 0.4085 - val_loss: 1.1010 - val_accuracy: 0.3660\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 1.0732 - accuracy: 0.4075 - val_loss: 1.0995 - val_accuracy: 0.3635\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 1.0755 - accuracy: 0.4132 - val_loss: 1.1009 - val_accuracy: 0.3670\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 1.0747 - accuracy: 0.4139 - val_loss: 1.1035 - val_accuracy: 0.3660\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 1.0739 - accuracy: 0.4109 - val_loss: 1.1006 - val_accuracy: 0.3625\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 1.0746 - accuracy: 0.4047 - val_loss: 1.1007 - val_accuracy: 0.3700\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 1.0750 - accuracy: 0.4085 - val_loss: 1.1011 - val_accuracy: 0.3665\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 1.0739 - accuracy: 0.4119 - val_loss: 1.1005 - val_accuracy: 0.3640\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 1.0743 - accuracy: 0.4064 - val_loss: 1.1013 - val_accuracy: 0.3560\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 1.0734 - accuracy: 0.4103 - val_loss: 1.1002 - val_accuracy: 0.3650\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 1.0729 - accuracy: 0.4098 - val_loss: 1.1003 - val_accuracy: 0.3735\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 1.0718 - accuracy: 0.4174 - val_loss: 1.1013 - val_accuracy: 0.3670\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 1.0719 - accuracy: 0.4144 - val_loss: 1.1027 - val_accuracy: 0.3705\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 1.0710 - accuracy: 0.4146 - val_loss: 1.1024 - val_accuracy: 0.3630\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 1.0701 - accuracy: 0.4166 - val_loss: 1.1013 - val_accuracy: 0.3600\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 1.0728 - accuracy: 0.4033 - val_loss: 1.1017 - val_accuracy: 0.3710\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 1.0719 - accuracy: 0.4105 - val_loss: 1.1012 - val_accuracy: 0.3715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 1.0697 - accuracy: 0.4216 - val_loss: 1.1026 - val_accuracy: 0.3715\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 1.0699 - accuracy: 0.4150 - val_loss: 1.1028 - val_accuracy: 0.3620\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 1.0703 - accuracy: 0.4218 - val_loss: 1.1014 - val_accuracy: 0.3635\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 1.0709 - accuracy: 0.4193 - val_loss: 1.1028 - val_accuracy: 0.3610\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 1.0692 - accuracy: 0.4176 - val_loss: 1.1023 - val_accuracy: 0.3650\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 1.0684 - accuracy: 0.4230 - val_loss: 1.1034 - val_accuracy: 0.3635\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 1.0690 - accuracy: 0.4175 - val_loss: 1.1034 - val_accuracy: 0.3655\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 1.0693 - accuracy: 0.4207 - val_loss: 1.1038 - val_accuracy: 0.3630\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 1.0684 - accuracy: 0.4161 - val_loss: 1.1036 - val_accuracy: 0.3645\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 1.0700 - accuracy: 0.4168 - val_loss: 1.1035 - val_accuracy: 0.3685\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 1.0688 - accuracy: 0.4248 - val_loss: 1.1031 - val_accuracy: 0.3605\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 1.0664 - accuracy: 0.4189 - val_loss: 1.1044 - val_accuracy: 0.3625\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 1.0680 - accuracy: 0.4219 - val_loss: 1.1052 - val_accuracy: 0.3640\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 1.0644 - accuracy: 0.4266 - val_loss: 1.1049 - val_accuracy: 0.3615\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 1.0660 - accuracy: 0.4244 - val_loss: 1.1047 - val_accuracy: 0.3650\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 1.0665 - accuracy: 0.4187 - val_loss: 1.1048 - val_accuracy: 0.3620\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 1.0650 - accuracy: 0.4226 - val_loss: 1.1035 - val_accuracy: 0.3630\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 1.0672 - accuracy: 0.4241 - val_loss: 1.1040 - val_accuracy: 0.3655\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 1.0664 - accuracy: 0.4238 - val_loss: 1.1042 - val_accuracy: 0.3645\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 1.0658 - accuracy: 0.4257 - val_loss: 1.1063 - val_accuracy: 0.3675\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 1.0647 - accuracy: 0.4234 - val_loss: 1.1054 - val_accuracy: 0.3675\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 1.0660 - accuracy: 0.4220 - val_loss: 1.1041 - val_accuracy: 0.3635\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 1.0658 - accuracy: 0.4276 - val_loss: 1.1055 - val_accuracy: 0.3600\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 1.0629 - accuracy: 0.4249 - val_loss: 1.1064 - val_accuracy: 0.3655\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 1.0658 - accuracy: 0.4185 - val_loss: 1.1049 - val_accuracy: 0.3585\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 1.0652 - accuracy: 0.4261 - val_loss: 1.1053 - val_accuracy: 0.3630\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 1.0657 - accuracy: 0.4170 - val_loss: 1.1050 - val_accuracy: 0.3620\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 1.0643 - accuracy: 0.4264 - val_loss: 1.1055 - val_accuracy: 0.3585\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 1.0635 - accuracy: 0.4272 - val_loss: 1.1068 - val_accuracy: 0.3680\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 1.0627 - accuracy: 0.4243 - val_loss: 1.1069 - val_accuracy: 0.3610\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 1.0641 - accuracy: 0.4218 - val_loss: 1.1073 - val_accuracy: 0.3660\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 1.0642 - accuracy: 0.4216 - val_loss: 1.1059 - val_accuracy: 0.3650\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 1.0611 - accuracy: 0.4283 - val_loss: 1.1094 - val_accuracy: 0.3610\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 1.0625 - accuracy: 0.4209 - val_loss: 1.1101 - val_accuracy: 0.3615\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 1.0652 - accuracy: 0.4202 - val_loss: 1.1072 - val_accuracy: 0.3615\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 1.0618 - accuracy: 0.4322 - val_loss: 1.1071 - val_accuracy: 0.3615\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 1.0644 - accuracy: 0.4239 - val_loss: 1.1073 - val_accuracy: 0.3670\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 1.0605 - accuracy: 0.4311 - val_loss: 1.1108 - val_accuracy: 0.3680\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 1.0613 - accuracy: 0.4241 - val_loss: 1.1082 - val_accuracy: 0.3655\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 1.0613 - accuracy: 0.4261 - val_loss: 1.1088 - val_accuracy: 0.3640\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1009 - accuracy: 0.3336 - val_loss: 1.1025 - val_accuracy: 0.3180\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.1007 - accuracy: 0.3325 - val_loss: 1.1005 - val_accuracy: 0.3270\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3321 - val_loss: 1.1003 - val_accuracy: 0.3255\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3400 - val_loss: 1.1000 - val_accuracy: 0.3265\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3413 - val_loss: 1.1001 - val_accuracy: 0.3260\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3459 - val_loss: 1.0996 - val_accuracy: 0.3265\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0980 - accuracy: 0.3467 - val_loss: 1.0997 - val_accuracy: 0.3315\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0972 - accuracy: 0.3577 - val_loss: 1.0996 - val_accuracy: 0.3295\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0976 - accuracy: 0.3511 - val_loss: 1.0992 - val_accuracy: 0.3365\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0975 - accuracy: 0.3553 - val_loss: 1.0994 - val_accuracy: 0.3415\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0968 - accuracy: 0.3594 - val_loss: 1.0990 - val_accuracy: 0.3465\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0967 - accuracy: 0.3546 - val_loss: 1.0984 - val_accuracy: 0.3480\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0965 - accuracy: 0.3590 - val_loss: 1.0986 - val_accuracy: 0.3425\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0966 - accuracy: 0.3605 - val_loss: 1.0982 - val_accuracy: 0.3490\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0963 - accuracy: 0.3589 - val_loss: 1.0979 - val_accuracy: 0.3430\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0955 - accuracy: 0.3607 - val_loss: 1.0980 - val_accuracy: 0.3445\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3613 - val_loss: 1.0973 - val_accuracy: 0.3505\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0951 - accuracy: 0.3690 - val_loss: 1.0974 - val_accuracy: 0.3465\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0954 - accuracy: 0.3625 - val_loss: 1.0967 - val_accuracy: 0.3535\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0945 - accuracy: 0.3630 - val_loss: 1.0963 - val_accuracy: 0.3600\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0946 - accuracy: 0.3708 - val_loss: 1.0959 - val_accuracy: 0.3570\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0937 - accuracy: 0.3689 - val_loss: 1.0959 - val_accuracy: 0.3605\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0936 - accuracy: 0.3639 - val_loss: 1.0953 - val_accuracy: 0.3615\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3729 - val_loss: 1.0949 - val_accuracy: 0.3655\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0925 - accuracy: 0.3798 - val_loss: 1.0945 - val_accuracy: 0.3675\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3725 - val_loss: 1.0937 - val_accuracy: 0.3755\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0916 - accuracy: 0.3765 - val_loss: 1.0941 - val_accuracy: 0.3590\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0917 - accuracy: 0.3785 - val_loss: 1.0928 - val_accuracy: 0.3705\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0901 - accuracy: 0.3881 - val_loss: 1.0934 - val_accuracy: 0.3695\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0908 - accuracy: 0.3783 - val_loss: 1.0920 - val_accuracy: 0.3680\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0883 - accuracy: 0.3923 - val_loss: 1.0913 - val_accuracy: 0.3725\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0886 - accuracy: 0.3815 - val_loss: 1.0903 - val_accuracy: 0.3820\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0870 - accuracy: 0.3821 - val_loss: 1.0899 - val_accuracy: 0.3800\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0877 - accuracy: 0.3881 - val_loss: 1.0899 - val_accuracy: 0.3785\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0860 - accuracy: 0.3911 - val_loss: 1.0890 - val_accuracy: 0.3805\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 1.0850 - accuracy: 0.3949 - val_loss: 1.0878 - val_accuracy: 0.3825\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 1.0840 - accuracy: 0.3990 - val_loss: 1.0871 - val_accuracy: 0.3825\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 1.0829 - accuracy: 0.3966 - val_loss: 1.0874 - val_accuracy: 0.3860\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0825 - accuracy: 0.3955 - val_loss: 1.0857 - val_accuracy: 0.3770\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 1.0822 - accuracy: 0.4105 - val_loss: 1.0850 - val_accuracy: 0.3900\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 1.0805 - accuracy: 0.4040 - val_loss: 1.0834 - val_accuracy: 0.3905\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 1.0798 - accuracy: 0.4001 - val_loss: 1.0838 - val_accuracy: 0.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 1.0784 - accuracy: 0.4040 - val_loss: 1.0838 - val_accuracy: 0.3865\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 1.0771 - accuracy: 0.4079 - val_loss: 1.0815 - val_accuracy: 0.4020\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 1.0796 - accuracy: 0.4024 - val_loss: 1.0832 - val_accuracy: 0.3925\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 1.0770 - accuracy: 0.4062 - val_loss: 1.0821 - val_accuracy: 0.3900\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 1.0732 - accuracy: 0.4168 - val_loss: 1.0809 - val_accuracy: 0.3980\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 1.0737 - accuracy: 0.4165 - val_loss: 1.0801 - val_accuracy: 0.3965\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 1.0729 - accuracy: 0.4125 - val_loss: 1.0785 - val_accuracy: 0.4055\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 1.0743 - accuracy: 0.4104 - val_loss: 1.0783 - val_accuracy: 0.4035\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 1.0717 - accuracy: 0.4161 - val_loss: 1.0798 - val_accuracy: 0.4040\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 1.0713 - accuracy: 0.4146 - val_loss: 1.0775 - val_accuracy: 0.4045\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 1.0711 - accuracy: 0.4187 - val_loss: 1.0767 - val_accuracy: 0.4075\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 1.0699 - accuracy: 0.4261 - val_loss: 1.0785 - val_accuracy: 0.3935\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 1.0709 - accuracy: 0.4153 - val_loss: 1.0780 - val_accuracy: 0.4040\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 1.0692 - accuracy: 0.4190 - val_loss: 1.0778 - val_accuracy: 0.4050\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 1.0667 - accuracy: 0.4215 - val_loss: 1.0764 - val_accuracy: 0.4085\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 1.0679 - accuracy: 0.4206 - val_loss: 1.0768 - val_accuracy: 0.4075\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 1.0674 - accuracy: 0.4196 - val_loss: 1.0756 - val_accuracy: 0.4175\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 1.0635 - accuracy: 0.4291 - val_loss: 1.0747 - val_accuracy: 0.4155\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 1.0677 - accuracy: 0.4239 - val_loss: 1.0783 - val_accuracy: 0.4055\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 1.0651 - accuracy: 0.4240 - val_loss: 1.0756 - val_accuracy: 0.4130\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 1.0656 - accuracy: 0.4231 - val_loss: 1.0764 - val_accuracy: 0.4035\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 1.0638 - accuracy: 0.4270 - val_loss: 1.0761 - val_accuracy: 0.4140\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 1.0643 - accuracy: 0.4336 - val_loss: 1.0753 - val_accuracy: 0.4100\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 1.0629 - accuracy: 0.4295 - val_loss: 1.0735 - val_accuracy: 0.4205\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 1.0635 - accuracy: 0.4280 - val_loss: 1.0762 - val_accuracy: 0.4150\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 1.0618 - accuracy: 0.4315 - val_loss: 1.0738 - val_accuracy: 0.4140\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 1.0593 - accuracy: 0.4365 - val_loss: 1.0736 - val_accuracy: 0.4145\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 1.0598 - accuracy: 0.4327 - val_loss: 1.0739 - val_accuracy: 0.4150\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 1.0598 - accuracy: 0.4340 - val_loss: 1.0742 - val_accuracy: 0.4090\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 1.0588 - accuracy: 0.4372 - val_loss: 1.0780 - val_accuracy: 0.4120\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 1.0560 - accuracy: 0.4435 - val_loss: 1.0790 - val_accuracy: 0.4150\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 1.0561 - accuracy: 0.4415 - val_loss: 1.0743 - val_accuracy: 0.4095\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 1.0554 - accuracy: 0.4425 - val_loss: 1.0764 - val_accuracy: 0.4150\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 1.0573 - accuracy: 0.4355 - val_loss: 1.0730 - val_accuracy: 0.4155\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 1.0573 - accuracy: 0.4409 - val_loss: 1.0723 - val_accuracy: 0.4190\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 1.0525 - accuracy: 0.4421 - val_loss: 1.0716 - val_accuracy: 0.4190\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 1.0535 - accuracy: 0.4421 - val_loss: 1.0717 - val_accuracy: 0.4200\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 1.0528 - accuracy: 0.4457 - val_loss: 1.0686 - val_accuracy: 0.4245\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 1.0522 - accuracy: 0.4436 - val_loss: 1.0739 - val_accuracy: 0.4120\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 1.0516 - accuracy: 0.4496 - val_loss: 1.0703 - val_accuracy: 0.4170\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 1.0503 - accuracy: 0.4502 - val_loss: 1.0699 - val_accuracy: 0.4190\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 1.0527 - accuracy: 0.4485 - val_loss: 1.0705 - val_accuracy: 0.4180\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 1.0511 - accuracy: 0.4481 - val_loss: 1.0718 - val_accuracy: 0.4190\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 1.0501 - accuracy: 0.4491 - val_loss: 1.0678 - val_accuracy: 0.4240\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 1.0524 - accuracy: 0.4442 - val_loss: 1.0700 - val_accuracy: 0.4245\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 1.0476 - accuracy: 0.4451 - val_loss: 1.0672 - val_accuracy: 0.4215\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 1.0497 - accuracy: 0.4448 - val_loss: 1.0673 - val_accuracy: 0.4160\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 1.0476 - accuracy: 0.4471 - val_loss: 1.0707 - val_accuracy: 0.4195\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 1.0471 - accuracy: 0.4530 - val_loss: 1.0686 - val_accuracy: 0.4295\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 1.0481 - accuracy: 0.4529 - val_loss: 1.0680 - val_accuracy: 0.4205\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 1.0471 - accuracy: 0.4512 - val_loss: 1.0718 - val_accuracy: 0.4250\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 1.0457 - accuracy: 0.4475 - val_loss: 1.0697 - val_accuracy: 0.4165\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 1.0442 - accuracy: 0.4540 - val_loss: 1.0703 - val_accuracy: 0.4150\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 1.0457 - accuracy: 0.4536 - val_loss: 1.0659 - val_accuracy: 0.4320\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 1.0454 - accuracy: 0.4535 - val_loss: 1.0660 - val_accuracy: 0.4310\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 1.0416 - accuracy: 0.4602 - val_loss: 1.0671 - val_accuracy: 0.4275\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 1.0425 - accuracy: 0.4538 - val_loss: 1.0650 - val_accuracy: 0.4235\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 1.0438 - accuracy: 0.4570 - val_loss: 1.0652 - val_accuracy: 0.4250\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 1.0413 - accuracy: 0.4571 - val_loss: 1.0694 - val_accuracy: 0.4165\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 1.0431 - accuracy: 0.4535 - val_loss: 1.0640 - val_accuracy: 0.4305\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 1.0420 - accuracy: 0.4596 - val_loss: 1.0678 - val_accuracy: 0.4195\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 1.0405 - accuracy: 0.4625 - val_loss: 1.0675 - val_accuracy: 0.4245\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 1.0386 - accuracy: 0.4610 - val_loss: 1.0634 - val_accuracy: 0.4320\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 1.0418 - accuracy: 0.4565 - val_loss: 1.0660 - val_accuracy: 0.4225\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 1.0390 - accuracy: 0.4620 - val_loss: 1.0661 - val_accuracy: 0.4260\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 1.0391 - accuracy: 0.4589 - val_loss: 1.0634 - val_accuracy: 0.4285\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 1.0378 - accuracy: 0.4638 - val_loss: 1.0661 - val_accuracy: 0.4235\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 1.0398 - accuracy: 0.4611 - val_loss: 1.0641 - val_accuracy: 0.4240\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 1.0372 - accuracy: 0.4659 - val_loss: 1.0684 - val_accuracy: 0.4250\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 1.0335 - accuracy: 0.4724 - val_loss: 1.0669 - val_accuracy: 0.4265\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 1.0358 - accuracy: 0.4606 - val_loss: 1.0647 - val_accuracy: 0.4255\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 1.0361 - accuracy: 0.4652 - val_loss: 1.0678 - val_accuracy: 0.4185\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 1.0357 - accuracy: 0.4681 - val_loss: 1.0621 - val_accuracy: 0.4330\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 1.0379 - accuracy: 0.4570 - val_loss: 1.0720 - val_accuracy: 0.4145\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 1.0367 - accuracy: 0.4670 - val_loss: 1.0611 - val_accuracy: 0.4325\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 1.0374 - accuracy: 0.4601 - val_loss: 1.0637 - val_accuracy: 0.4275\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 1.0364 - accuracy: 0.4656 - val_loss: 1.0636 - val_accuracy: 0.4265\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 1.0323 - accuracy: 0.4706 - val_loss: 1.0642 - val_accuracy: 0.4320\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 1.0349 - accuracy: 0.4634 - val_loss: 1.0628 - val_accuracy: 0.4275\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 1.0340 - accuracy: 0.4659 - val_loss: 1.0646 - val_accuracy: 0.4305\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 1.0341 - accuracy: 0.4745 - val_loss: 1.0610 - val_accuracy: 0.4360\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 1.0322 - accuracy: 0.4701 - val_loss: 1.0684 - val_accuracy: 0.4290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 1.0332 - accuracy: 0.4697 - val_loss: 1.0632 - val_accuracy: 0.4315\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 1.0329 - accuracy: 0.4688 - val_loss: 1.0680 - val_accuracy: 0.4220\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 1.0328 - accuracy: 0.4695 - val_loss: 1.0653 - val_accuracy: 0.4235\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 1.0295 - accuracy: 0.4706 - val_loss: 1.0690 - val_accuracy: 0.4210\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 1.0321 - accuracy: 0.4681 - val_loss: 1.0596 - val_accuracy: 0.4385\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 1.0324 - accuracy: 0.4638 - val_loss: 1.0663 - val_accuracy: 0.4275\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 1.0310 - accuracy: 0.4723 - val_loss: 1.0617 - val_accuracy: 0.4380\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 1.0328 - accuracy: 0.4690 - val_loss: 1.0632 - val_accuracy: 0.4340\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 1.0282 - accuracy: 0.4753 - val_loss: 1.0627 - val_accuracy: 0.4335\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 1.0310 - accuracy: 0.4697 - val_loss: 1.0613 - val_accuracy: 0.4330\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 1.0313 - accuracy: 0.4740 - val_loss: 1.0622 - val_accuracy: 0.4340\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 1.0273 - accuracy: 0.4748 - val_loss: 1.0605 - val_accuracy: 0.4355\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 1.0292 - accuracy: 0.4719 - val_loss: 1.0645 - val_accuracy: 0.4285\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 1.0297 - accuracy: 0.4771 - val_loss: 1.0630 - val_accuracy: 0.4385\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 1.0315 - accuracy: 0.4710 - val_loss: 1.0610 - val_accuracy: 0.4330\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 1.0259 - accuracy: 0.4764 - val_loss: 1.0605 - val_accuracy: 0.4375\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 1.0283 - accuracy: 0.4796 - val_loss: 1.0638 - val_accuracy: 0.4375\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 1.0296 - accuracy: 0.4749 - val_loss: 1.0597 - val_accuracy: 0.4360\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 1.0298 - accuracy: 0.4686 - val_loss: 1.0671 - val_accuracy: 0.4305\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 1.0272 - accuracy: 0.4733 - val_loss: 1.0612 - val_accuracy: 0.4335\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 1.0259 - accuracy: 0.4771 - val_loss: 1.0634 - val_accuracy: 0.4345\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 1.0255 - accuracy: 0.4770 - val_loss: 1.0623 - val_accuracy: 0.4370\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 1.0275 - accuracy: 0.4740 - val_loss: 1.0604 - val_accuracy: 0.4370\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 1.0267 - accuracy: 0.4744 - val_loss: 1.0614 - val_accuracy: 0.4355\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 1.0230 - accuracy: 0.4746 - val_loss: 1.0619 - val_accuracy: 0.4345\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 1.0240 - accuracy: 0.4794 - val_loss: 1.0594 - val_accuracy: 0.4350\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1015 - accuracy: 0.3282 - val_loss: 1.0997 - val_accuracy: 0.3410\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.1002 - accuracy: 0.3295 - val_loss: 1.0989 - val_accuracy: 0.3415\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0996 - accuracy: 0.3316 - val_loss: 1.0982 - val_accuracy: 0.3520\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0983 - accuracy: 0.3410 - val_loss: 1.0980 - val_accuracy: 0.3555\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3470 - val_loss: 1.0976 - val_accuracy: 0.3545\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0981 - accuracy: 0.3461 - val_loss: 1.0973 - val_accuracy: 0.3560\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0973 - accuracy: 0.3529 - val_loss: 1.0971 - val_accuracy: 0.3545\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0967 - accuracy: 0.3569 - val_loss: 1.0967 - val_accuracy: 0.3660\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0960 - accuracy: 0.3647 - val_loss: 1.0964 - val_accuracy: 0.3580\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0959 - accuracy: 0.3685 - val_loss: 1.0961 - val_accuracy: 0.3565\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0957 - accuracy: 0.3661 - val_loss: 1.0957 - val_accuracy: 0.3640\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0952 - accuracy: 0.3684 - val_loss: 1.0953 - val_accuracy: 0.3645\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0953 - accuracy: 0.3672 - val_loss: 1.0947 - val_accuracy: 0.3665\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0943 - accuracy: 0.3699 - val_loss: 1.0943 - val_accuracy: 0.3665\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0936 - accuracy: 0.3764 - val_loss: 1.0936 - val_accuracy: 0.3725\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3775 - val_loss: 1.0930 - val_accuracy: 0.3720\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0924 - accuracy: 0.3722 - val_loss: 1.0922 - val_accuracy: 0.3810\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0915 - accuracy: 0.3825 - val_loss: 1.0915 - val_accuracy: 0.3780\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0913 - accuracy: 0.3744 - val_loss: 1.0907 - val_accuracy: 0.3810\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0910 - accuracy: 0.3819 - val_loss: 1.0899 - val_accuracy: 0.3810\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0889 - accuracy: 0.3810 - val_loss: 1.0890 - val_accuracy: 0.3890\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0877 - accuracy: 0.3816 - val_loss: 1.0881 - val_accuracy: 0.3895\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0865 - accuracy: 0.3934 - val_loss: 1.0869 - val_accuracy: 0.3845\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0856 - accuracy: 0.3954 - val_loss: 1.0863 - val_accuracy: 0.3980\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0836 - accuracy: 0.3988 - val_loss: 1.0851 - val_accuracy: 0.3945\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0846 - accuracy: 0.3975 - val_loss: 1.0842 - val_accuracy: 0.3935\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0811 - accuracy: 0.4033 - val_loss: 1.0835 - val_accuracy: 0.4020\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0799 - accuracy: 0.4059 - val_loss: 1.0820 - val_accuracy: 0.4040\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0790 - accuracy: 0.4083 - val_loss: 1.0811 - val_accuracy: 0.4145\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0773 - accuracy: 0.4115 - val_loss: 1.0799 - val_accuracy: 0.4070\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0770 - accuracy: 0.4119 - val_loss: 1.0793 - val_accuracy: 0.4160\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0745 - accuracy: 0.4162 - val_loss: 1.0782 - val_accuracy: 0.4180\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0739 - accuracy: 0.4181 - val_loss: 1.0775 - val_accuracy: 0.4150\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0759 - accuracy: 0.4101 - val_loss: 1.0768 - val_accuracy: 0.4230\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0730 - accuracy: 0.4148 - val_loss: 1.0763 - val_accuracy: 0.4155\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 1.0707 - accuracy: 0.4241 - val_loss: 1.0754 - val_accuracy: 0.4205\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 1.0698 - accuracy: 0.4219 - val_loss: 1.0744 - val_accuracy: 0.4200\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 1.0700 - accuracy: 0.4248 - val_loss: 1.0736 - val_accuracy: 0.4220\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0678 - accuracy: 0.4269 - val_loss: 1.0727 - val_accuracy: 0.4255\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 1.0653 - accuracy: 0.4259 - val_loss: 1.0715 - val_accuracy: 0.4300\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 1.0635 - accuracy: 0.4364 - val_loss: 1.0710 - val_accuracy: 0.4320\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 1.0642 - accuracy: 0.4289 - val_loss: 1.0686 - val_accuracy: 0.4310\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 1.0620 - accuracy: 0.4330 - val_loss: 1.0684 - val_accuracy: 0.4300\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 1.0625 - accuracy: 0.4321 - val_loss: 1.0681 - val_accuracy: 0.4340\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 1.0595 - accuracy: 0.4406 - val_loss: 1.0675 - val_accuracy: 0.4370\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 1.0595 - accuracy: 0.4375 - val_loss: 1.0667 - val_accuracy: 0.4380\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 1.0573 - accuracy: 0.4439 - val_loss: 1.0655 - val_accuracy: 0.4350\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 1.0557 - accuracy: 0.4389 - val_loss: 1.0656 - val_accuracy: 0.4375\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 1.0508 - accuracy: 0.4478 - val_loss: 1.0630 - val_accuracy: 0.4365\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 1.0537 - accuracy: 0.4453 - val_loss: 1.0615 - val_accuracy: 0.4425\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 1.0526 - accuracy: 0.4450 - val_loss: 1.0613 - val_accuracy: 0.4450\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 1.0490 - accuracy: 0.4459 - val_loss: 1.0597 - val_accuracy: 0.4385\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 1.0502 - accuracy: 0.4509 - val_loss: 1.0591 - val_accuracy: 0.4485\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 1.0506 - accuracy: 0.4485 - val_loss: 1.0582 - val_accuracy: 0.4535\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 1.0456 - accuracy: 0.4556 - val_loss: 1.0559 - val_accuracy: 0.4500\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 1.0457 - accuracy: 0.4580 - val_loss: 1.0549 - val_accuracy: 0.4510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 1.0461 - accuracy: 0.4594 - val_loss: 1.0545 - val_accuracy: 0.4525\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 1.0456 - accuracy: 0.4556 - val_loss: 1.0546 - val_accuracy: 0.4525\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 1.0450 - accuracy: 0.4589 - val_loss: 1.0537 - val_accuracy: 0.4540\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 1.0416 - accuracy: 0.4641 - val_loss: 1.0521 - val_accuracy: 0.4580\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 1.0398 - accuracy: 0.4645 - val_loss: 1.0514 - val_accuracy: 0.4535\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 1.0395 - accuracy: 0.4611 - val_loss: 1.0511 - val_accuracy: 0.4485\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 1.0353 - accuracy: 0.4701 - val_loss: 1.0498 - val_accuracy: 0.4585\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 1.0394 - accuracy: 0.4644 - val_loss: 1.0499 - val_accuracy: 0.4550\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 1.0414 - accuracy: 0.4638 - val_loss: 1.0488 - val_accuracy: 0.4565\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 1.0363 - accuracy: 0.4711 - val_loss: 1.0498 - val_accuracy: 0.4560\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 1.0405 - accuracy: 0.4609 - val_loss: 1.0509 - val_accuracy: 0.4500\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 1.0330 - accuracy: 0.4708 - val_loss: 1.0487 - val_accuracy: 0.4540\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 1.0312 - accuracy: 0.4767 - val_loss: 1.0461 - val_accuracy: 0.4605\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 1.0309 - accuracy: 0.4748 - val_loss: 1.0451 - val_accuracy: 0.4610\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 1.0317 - accuracy: 0.4700 - val_loss: 1.0454 - val_accuracy: 0.4635\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 1.0302 - accuracy: 0.4803 - val_loss: 1.0438 - val_accuracy: 0.4635\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 1.0264 - accuracy: 0.4780 - val_loss: 1.0428 - val_accuracy: 0.4680\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 1.0277 - accuracy: 0.4804 - val_loss: 1.0432 - val_accuracy: 0.4545\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 1.0277 - accuracy: 0.4803 - val_loss: 1.0413 - val_accuracy: 0.4590\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 1.0279 - accuracy: 0.4778 - val_loss: 1.0432 - val_accuracy: 0.4570\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 1.0298 - accuracy: 0.4680 - val_loss: 1.0414 - val_accuracy: 0.4585\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 1.0240 - accuracy: 0.4798 - val_loss: 1.0409 - val_accuracy: 0.4690\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 1.0222 - accuracy: 0.4848 - val_loss: 1.0399 - val_accuracy: 0.4570\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 1.0214 - accuracy: 0.4794 - val_loss: 1.0393 - val_accuracy: 0.4600\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 1.0223 - accuracy: 0.4785 - val_loss: 1.0380 - val_accuracy: 0.4675\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 1.0199 - accuracy: 0.4870 - val_loss: 1.0374 - val_accuracy: 0.4625\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 1.0193 - accuracy: 0.4803 - val_loss: 1.0372 - val_accuracy: 0.4720\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 1.0208 - accuracy: 0.4814 - val_loss: 1.0395 - val_accuracy: 0.4565\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 1.0181 - accuracy: 0.4894 - val_loss: 1.0381 - val_accuracy: 0.4650\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 1.0160 - accuracy: 0.4911 - val_loss: 1.0362 - val_accuracy: 0.4630\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 1.0172 - accuracy: 0.4877 - val_loss: 1.0359 - val_accuracy: 0.4730\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 1.0181 - accuracy: 0.4910 - val_loss: 1.0380 - val_accuracy: 0.4755\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 1.0163 - accuracy: 0.4920 - val_loss: 1.0352 - val_accuracy: 0.4715\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 1.0197 - accuracy: 0.4818 - val_loss: 1.0368 - val_accuracy: 0.4630\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 1.0125 - accuracy: 0.4956 - val_loss: 1.0331 - val_accuracy: 0.4715\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 1.0134 - accuracy: 0.4942 - val_loss: 1.0351 - val_accuracy: 0.4700\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 1.0104 - accuracy: 0.4996 - val_loss: 1.0358 - val_accuracy: 0.4800\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 1.0105 - accuracy: 0.4984 - val_loss: 1.0340 - val_accuracy: 0.4665\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 1.0078 - accuracy: 0.4954 - val_loss: 1.0333 - val_accuracy: 0.4765\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 1.0129 - accuracy: 0.4964 - val_loss: 1.0355 - val_accuracy: 0.4750\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 1.0115 - accuracy: 0.4974 - val_loss: 1.0318 - val_accuracy: 0.4760\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 1.0110 - accuracy: 0.4926 - val_loss: 1.0309 - val_accuracy: 0.4715\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 1.0101 - accuracy: 0.4986 - val_loss: 1.0329 - val_accuracy: 0.4790\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 1.0094 - accuracy: 0.4975 - val_loss: 1.0325 - val_accuracy: 0.4755\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 1.0080 - accuracy: 0.4978 - val_loss: 1.0311 - val_accuracy: 0.4755\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 1.0063 - accuracy: 0.4969 - val_loss: 1.0304 - val_accuracy: 0.4745\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 1.0066 - accuracy: 0.4986 - val_loss: 1.0293 - val_accuracy: 0.4755\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 1.0029 - accuracy: 0.4986 - val_loss: 1.0278 - val_accuracy: 0.4865\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 1.0045 - accuracy: 0.5029 - val_loss: 1.0287 - val_accuracy: 0.4775\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 1.0023 - accuracy: 0.5035 - val_loss: 1.0298 - val_accuracy: 0.4770\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 1.0006 - accuracy: 0.5088 - val_loss: 1.0284 - val_accuracy: 0.4865\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 1.0051 - accuracy: 0.5041 - val_loss: 1.0261 - val_accuracy: 0.4845\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.9998 - accuracy: 0.5067 - val_loss: 1.0280 - val_accuracy: 0.4895\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 1.0017 - accuracy: 0.5049 - val_loss: 1.0286 - val_accuracy: 0.4850\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.9961 - accuracy: 0.5094 - val_loss: 1.0273 - val_accuracy: 0.4885\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.9997 - accuracy: 0.5084 - val_loss: 1.0267 - val_accuracy: 0.4850\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.9957 - accuracy: 0.5142 - val_loss: 1.0297 - val_accuracy: 0.4865\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.9979 - accuracy: 0.5099 - val_loss: 1.0266 - val_accuracy: 0.4865\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 1.0020 - accuracy: 0.5029 - val_loss: 1.0261 - val_accuracy: 0.4840\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.9960 - accuracy: 0.5146 - val_loss: 1.0260 - val_accuracy: 0.4930\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.9996 - accuracy: 0.5081 - val_loss: 1.0269 - val_accuracy: 0.4870\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.9966 - accuracy: 0.5074 - val_loss: 1.0246 - val_accuracy: 0.4855\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.9973 - accuracy: 0.5113 - val_loss: 1.0249 - val_accuracy: 0.4905\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.9950 - accuracy: 0.5154 - val_loss: 1.0253 - val_accuracy: 0.4830\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.9984 - accuracy: 0.5140 - val_loss: 1.0246 - val_accuracy: 0.4990\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.9937 - accuracy: 0.5201 - val_loss: 1.0243 - val_accuracy: 0.4925\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.9947 - accuracy: 0.5092 - val_loss: 1.0252 - val_accuracy: 0.4940\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.9928 - accuracy: 0.5186 - val_loss: 1.0229 - val_accuracy: 0.4975\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.9921 - accuracy: 0.5136 - val_loss: 1.0238 - val_accuracy: 0.4965\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.9924 - accuracy: 0.5138 - val_loss: 1.0220 - val_accuracy: 0.4915\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.9950 - accuracy: 0.5086 - val_loss: 1.0228 - val_accuracy: 0.4980\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.9922 - accuracy: 0.5159 - val_loss: 1.0234 - val_accuracy: 0.4925\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.9955 - accuracy: 0.5126 - val_loss: 1.0241 - val_accuracy: 0.4920\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.9914 - accuracy: 0.5145 - val_loss: 1.0255 - val_accuracy: 0.4875\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.9914 - accuracy: 0.5134 - val_loss: 1.0241 - val_accuracy: 0.4920\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.9852 - accuracy: 0.5242 - val_loss: 1.0222 - val_accuracy: 0.5015\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.9899 - accuracy: 0.5150 - val_loss: 1.0210 - val_accuracy: 0.5030\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.9874 - accuracy: 0.5189 - val_loss: 1.0227 - val_accuracy: 0.4995\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.9894 - accuracy: 0.5170 - val_loss: 1.0213 - val_accuracy: 0.4935\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.9885 - accuracy: 0.5186 - val_loss: 1.0217 - val_accuracy: 0.4970\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.9884 - accuracy: 0.5199 - val_loss: 1.0213 - val_accuracy: 0.4995\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.9876 - accuracy: 0.5196 - val_loss: 1.0244 - val_accuracy: 0.4955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.9871 - accuracy: 0.5255 - val_loss: 1.0217 - val_accuracy: 0.4920\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.9885 - accuracy: 0.5176 - val_loss: 1.0200 - val_accuracy: 0.5055\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.9891 - accuracy: 0.5144 - val_loss: 1.0205 - val_accuracy: 0.4985\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.9842 - accuracy: 0.5178 - val_loss: 1.0210 - val_accuracy: 0.4990\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.9882 - accuracy: 0.5182 - val_loss: 1.0204 - val_accuracy: 0.5000\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.9895 - accuracy: 0.5129 - val_loss: 1.0206 - val_accuracy: 0.5020\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.9836 - accuracy: 0.5199 - val_loss: 1.0199 - val_accuracy: 0.5000\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.9874 - accuracy: 0.5156 - val_loss: 1.0210 - val_accuracy: 0.4990\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.9872 - accuracy: 0.5229 - val_loss: 1.0190 - val_accuracy: 0.5010\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.9864 - accuracy: 0.5109 - val_loss: 1.0199 - val_accuracy: 0.4975\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.9852 - accuracy: 0.5251 - val_loss: 1.0181 - val_accuracy: 0.5030\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.9877 - accuracy: 0.5192 - val_loss: 1.0225 - val_accuracy: 0.4950\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1028 - accuracy: 0.3277 - val_loss: 1.0987 - val_accuracy: 0.3255\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3401 - val_loss: 1.0982 - val_accuracy: 0.3325\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3429 - val_loss: 1.0978 - val_accuracy: 0.3335\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0971 - accuracy: 0.3516 - val_loss: 1.0972 - val_accuracy: 0.3400\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0962 - accuracy: 0.3581 - val_loss: 1.0966 - val_accuracy: 0.3540\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0959 - accuracy: 0.3594 - val_loss: 1.0961 - val_accuracy: 0.3665\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0959 - accuracy: 0.3636 - val_loss: 1.0957 - val_accuracy: 0.3660\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0947 - accuracy: 0.3639 - val_loss: 1.0950 - val_accuracy: 0.3700\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0940 - accuracy: 0.3729 - val_loss: 1.0944 - val_accuracy: 0.3700\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0928 - accuracy: 0.3749 - val_loss: 1.0935 - val_accuracy: 0.3810\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3724 - val_loss: 1.0926 - val_accuracy: 0.3885\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0902 - accuracy: 0.3836 - val_loss: 1.0915 - val_accuracy: 0.3860\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0903 - accuracy: 0.3831 - val_loss: 1.0902 - val_accuracy: 0.3950\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0886 - accuracy: 0.3839 - val_loss: 1.0889 - val_accuracy: 0.3950\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0867 - accuracy: 0.3907 - val_loss: 1.0874 - val_accuracy: 0.3970\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0859 - accuracy: 0.3910 - val_loss: 1.0855 - val_accuracy: 0.4040\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0836 - accuracy: 0.3966 - val_loss: 1.0833 - val_accuracy: 0.4070\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0823 - accuracy: 0.3971 - val_loss: 1.0815 - val_accuracy: 0.4115\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0784 - accuracy: 0.4089 - val_loss: 1.0794 - val_accuracy: 0.4195\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0759 - accuracy: 0.4117 - val_loss: 1.0770 - val_accuracy: 0.4185\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0734 - accuracy: 0.4173 - val_loss: 1.0746 - val_accuracy: 0.4215\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0700 - accuracy: 0.4206 - val_loss: 1.0717 - val_accuracy: 0.4300\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0672 - accuracy: 0.4254 - val_loss: 1.0680 - val_accuracy: 0.4320\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0619 - accuracy: 0.4366 - val_loss: 1.0653 - val_accuracy: 0.4350\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0595 - accuracy: 0.4411 - val_loss: 1.0626 - val_accuracy: 0.4405\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0564 - accuracy: 0.4424 - val_loss: 1.0597 - val_accuracy: 0.4440\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0533 - accuracy: 0.4498 - val_loss: 1.0561 - val_accuracy: 0.4445\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0502 - accuracy: 0.4568 - val_loss: 1.0524 - val_accuracy: 0.4535\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0454 - accuracy: 0.4611 - val_loss: 1.0504 - val_accuracy: 0.4600\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0436 - accuracy: 0.4606 - val_loss: 1.0466 - val_accuracy: 0.4580\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0417 - accuracy: 0.4627 - val_loss: 1.0446 - val_accuracy: 0.4615\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0379 - accuracy: 0.4652 - val_loss: 1.0418 - val_accuracy: 0.4630\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0316 - accuracy: 0.4775 - val_loss: 1.0385 - val_accuracy: 0.4680\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0297 - accuracy: 0.4820 - val_loss: 1.0366 - val_accuracy: 0.4700\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0294 - accuracy: 0.4757 - val_loss: 1.0337 - val_accuracy: 0.4675\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 1.0247 - accuracy: 0.4765 - val_loss: 1.0319 - val_accuracy: 0.4720\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 1.0223 - accuracy: 0.4901 - val_loss: 1.0288 - val_accuracy: 0.4760\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 1.0184 - accuracy: 0.4891 - val_loss: 1.0288 - val_accuracy: 0.4705\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0175 - accuracy: 0.4926 - val_loss: 1.0249 - val_accuracy: 0.4850\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 1.0140 - accuracy: 0.4959 - val_loss: 1.0221 - val_accuracy: 0.4930\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 1.0101 - accuracy: 0.4911 - val_loss: 1.0203 - val_accuracy: 0.4920\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 1.0075 - accuracy: 0.5041 - val_loss: 1.0173 - val_accuracy: 0.4945\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 1.0020 - accuracy: 0.5116 - val_loss: 1.0149 - val_accuracy: 0.4970\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 1.0041 - accuracy: 0.5038 - val_loss: 1.0131 - val_accuracy: 0.4900\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.9972 - accuracy: 0.5099 - val_loss: 1.0141 - val_accuracy: 0.4960\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 1.0006 - accuracy: 0.5073 - val_loss: 1.0110 - val_accuracy: 0.4990\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.9950 - accuracy: 0.5131 - val_loss: 1.0095 - val_accuracy: 0.5025\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.9929 - accuracy: 0.5171 - val_loss: 1.0076 - val_accuracy: 0.5075\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.9909 - accuracy: 0.5154 - val_loss: 1.0069 - val_accuracy: 0.5075\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.9857 - accuracy: 0.5178 - val_loss: 1.0036 - val_accuracy: 0.5130\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.9845 - accuracy: 0.5238 - val_loss: 1.0034 - val_accuracy: 0.5040\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.9829 - accuracy: 0.5260 - val_loss: 1.0024 - val_accuracy: 0.5110\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.9762 - accuracy: 0.5263 - val_loss: 1.0006 - val_accuracy: 0.5165\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.9806 - accuracy: 0.5293 - val_loss: 0.9991 - val_accuracy: 0.5105\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.9748 - accuracy: 0.5269 - val_loss: 0.9968 - val_accuracy: 0.5200\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.9775 - accuracy: 0.5254 - val_loss: 0.9959 - val_accuracy: 0.5210\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.9724 - accuracy: 0.5316 - val_loss: 0.9979 - val_accuracy: 0.5150\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.9714 - accuracy: 0.5300 - val_loss: 0.9954 - val_accuracy: 0.5220\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.9698 - accuracy: 0.5335 - val_loss: 0.9935 - val_accuracy: 0.5190\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.9677 - accuracy: 0.5343 - val_loss: 0.9903 - val_accuracy: 0.5285\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.9636 - accuracy: 0.5389 - val_loss: 0.9895 - val_accuracy: 0.5300\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.9642 - accuracy: 0.5356 - val_loss: 0.9886 - val_accuracy: 0.5360\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.9619 - accuracy: 0.5389 - val_loss: 0.9902 - val_accuracy: 0.5260\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.9578 - accuracy: 0.5418 - val_loss: 0.9896 - val_accuracy: 0.5265\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.9602 - accuracy: 0.5375 - val_loss: 0.9843 - val_accuracy: 0.5290\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.9604 - accuracy: 0.5389 - val_loss: 0.9830 - val_accuracy: 0.5240\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.9562 - accuracy: 0.5414 - val_loss: 0.9829 - val_accuracy: 0.5250\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.9530 - accuracy: 0.5502 - val_loss: 0.9808 - val_accuracy: 0.5325\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.9518 - accuracy: 0.5474 - val_loss: 0.9791 - val_accuracy: 0.5340\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.9464 - accuracy: 0.5474 - val_loss: 0.9773 - val_accuracy: 0.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.9449 - accuracy: 0.5545 - val_loss: 0.9818 - val_accuracy: 0.5265\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.9441 - accuracy: 0.5508 - val_loss: 0.9734 - val_accuracy: 0.5405\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.9492 - accuracy: 0.5505 - val_loss: 0.9714 - val_accuracy: 0.5340\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.9394 - accuracy: 0.5590 - val_loss: 0.9713 - val_accuracy: 0.5300\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.9348 - accuracy: 0.5555 - val_loss: 0.9692 - val_accuracy: 0.5350\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.9356 - accuracy: 0.5616 - val_loss: 0.9664 - val_accuracy: 0.5395\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.9359 - accuracy: 0.5602 - val_loss: 0.9694 - val_accuracy: 0.5280\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.9352 - accuracy: 0.5649 - val_loss: 0.9649 - val_accuracy: 0.5365\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.9320 - accuracy: 0.5633 - val_loss: 0.9627 - val_accuracy: 0.5425\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.9326 - accuracy: 0.5620 - val_loss: 0.9581 - val_accuracy: 0.5450\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.9275 - accuracy: 0.5688 - val_loss: 0.9556 - val_accuracy: 0.5440\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.9246 - accuracy: 0.5698 - val_loss: 0.9548 - val_accuracy: 0.5405\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.9283 - accuracy: 0.5686 - val_loss: 0.9606 - val_accuracy: 0.5445\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.9189 - accuracy: 0.5702 - val_loss: 0.9529 - val_accuracy: 0.5420\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.9220 - accuracy: 0.5745 - val_loss: 0.9507 - val_accuracy: 0.5435\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.9189 - accuracy: 0.5761 - val_loss: 0.9471 - val_accuracy: 0.5435\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.9158 - accuracy: 0.5715 - val_loss: 0.9452 - val_accuracy: 0.5515\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.9127 - accuracy: 0.5803 - val_loss: 0.9430 - val_accuracy: 0.5480\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.9152 - accuracy: 0.5801 - val_loss: 0.9457 - val_accuracy: 0.5485\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.9174 - accuracy: 0.5770 - val_loss: 0.9411 - val_accuracy: 0.5515\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.9139 - accuracy: 0.5811 - val_loss: 0.9430 - val_accuracy: 0.5520\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.9110 - accuracy: 0.5884 - val_loss: 0.9431 - val_accuracy: 0.5570\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.9113 - accuracy: 0.5779 - val_loss: 0.9366 - val_accuracy: 0.5495\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.9160 - accuracy: 0.5741 - val_loss: 0.9362 - val_accuracy: 0.5525\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.9022 - accuracy: 0.5831 - val_loss: 0.9392 - val_accuracy: 0.5550\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.9100 - accuracy: 0.5830 - val_loss: 0.9371 - val_accuracy: 0.5620\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.9045 - accuracy: 0.5824 - val_loss: 0.9365 - val_accuracy: 0.5545\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.9029 - accuracy: 0.5854 - val_loss: 0.9341 - val_accuracy: 0.5550\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.9076 - accuracy: 0.5835 - val_loss: 0.9356 - val_accuracy: 0.5570\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.8983 - accuracy: 0.5897 - val_loss: 0.9321 - val_accuracy: 0.5560\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.9013 - accuracy: 0.5878 - val_loss: 0.9371 - val_accuracy: 0.5580\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.8981 - accuracy: 0.5915 - val_loss: 0.9300 - val_accuracy: 0.5600\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.9005 - accuracy: 0.5895 - val_loss: 0.9284 - val_accuracy: 0.5690\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.9008 - accuracy: 0.5875 - val_loss: 0.9281 - val_accuracy: 0.5610\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.8973 - accuracy: 0.5870 - val_loss: 0.9280 - val_accuracy: 0.5590\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.8969 - accuracy: 0.5880 - val_loss: 0.9257 - val_accuracy: 0.5620\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.8982 - accuracy: 0.5890 - val_loss: 0.9254 - val_accuracy: 0.5650\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.8945 - accuracy: 0.5924 - val_loss: 0.9287 - val_accuracy: 0.5620\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.8919 - accuracy: 0.5936 - val_loss: 0.9261 - val_accuracy: 0.5615\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.8975 - accuracy: 0.5921 - val_loss: 0.9248 - val_accuracy: 0.5650\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.8930 - accuracy: 0.5943 - val_loss: 0.9220 - val_accuracy: 0.5610\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.8901 - accuracy: 0.5943 - val_loss: 0.9205 - val_accuracy: 0.5640\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.8927 - accuracy: 0.5946 - val_loss: 0.9223 - val_accuracy: 0.5645\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.8864 - accuracy: 0.5919 - val_loss: 0.9243 - val_accuracy: 0.5685\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.8964 - accuracy: 0.5924 - val_loss: 0.9203 - val_accuracy: 0.5600\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.8895 - accuracy: 0.5878 - val_loss: 0.9277 - val_accuracy: 0.5625\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.8890 - accuracy: 0.5943 - val_loss: 0.9228 - val_accuracy: 0.5655\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.8878 - accuracy: 0.5980 - val_loss: 0.9213 - val_accuracy: 0.5610\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.8840 - accuracy: 0.5996 - val_loss: 0.9230 - val_accuracy: 0.5640\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.8893 - accuracy: 0.5905 - val_loss: 0.9178 - val_accuracy: 0.5675\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.8886 - accuracy: 0.5929 - val_loss: 0.9172 - val_accuracy: 0.5645\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.8868 - accuracy: 0.5970 - val_loss: 0.9160 - val_accuracy: 0.5670\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.8854 - accuracy: 0.5978 - val_loss: 0.9178 - val_accuracy: 0.5645\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.8859 - accuracy: 0.5987 - val_loss: 0.9205 - val_accuracy: 0.5675\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.8770 - accuracy: 0.5996 - val_loss: 0.9166 - val_accuracy: 0.5630\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.8811 - accuracy: 0.5957 - val_loss: 0.9186 - val_accuracy: 0.5695\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.8827 - accuracy: 0.5993 - val_loss: 0.9238 - val_accuracy: 0.5715\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.8844 - accuracy: 0.6011 - val_loss: 0.9172 - val_accuracy: 0.5680\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.8831 - accuracy: 0.6012 - val_loss: 0.9147 - val_accuracy: 0.5715\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.8792 - accuracy: 0.6041 - val_loss: 0.9213 - val_accuracy: 0.5690\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.8818 - accuracy: 0.5987 - val_loss: 0.9167 - val_accuracy: 0.5730\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.8798 - accuracy: 0.5956 - val_loss: 0.9126 - val_accuracy: 0.5715\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.8767 - accuracy: 0.6024 - val_loss: 0.9156 - val_accuracy: 0.5745\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.8787 - accuracy: 0.5981 - val_loss: 0.9179 - val_accuracy: 0.5695\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.8721 - accuracy: 0.6015 - val_loss: 0.9150 - val_accuracy: 0.5725\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.8750 - accuracy: 0.6008 - val_loss: 0.9181 - val_accuracy: 0.5710\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.8762 - accuracy: 0.6005 - val_loss: 0.9132 - val_accuracy: 0.5760\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.8759 - accuracy: 0.6058 - val_loss: 0.9127 - val_accuracy: 0.5720\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.8773 - accuracy: 0.6001 - val_loss: 0.9117 - val_accuracy: 0.5765\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.8786 - accuracy: 0.6011 - val_loss: 0.9174 - val_accuracy: 0.5710\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.8750 - accuracy: 0.6006 - val_loss: 0.9155 - val_accuracy: 0.5795\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.8774 - accuracy: 0.5984 - val_loss: 0.9142 - val_accuracy: 0.5840\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.8737 - accuracy: 0.6024 - val_loss: 0.9116 - val_accuracy: 0.5770\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.8737 - accuracy: 0.6060 - val_loss: 0.9152 - val_accuracy: 0.5750\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.8751 - accuracy: 0.5991 - val_loss: 0.9109 - val_accuracy: 0.5800\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.8742 - accuracy: 0.6102 - val_loss: 0.9099 - val_accuracy: 0.5780\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.8737 - accuracy: 0.6046 - val_loss: 0.9134 - val_accuracy: 0.5735\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.8757 - accuracy: 0.6035 - val_loss: 0.9096 - val_accuracy: 0.5805\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.8764 - accuracy: 0.6034 - val_loss: 0.9137 - val_accuracy: 0.5860\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.8731 - accuracy: 0.6003 - val_loss: 0.9145 - val_accuracy: 0.5770\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1036 - accuracy: 0.3309 - val_loss: 1.1019 - val_accuracy: 0.3135\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3455 - val_loss: 1.1001 - val_accuracy: 0.3360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3571 - val_loss: 1.0993 - val_accuracy: 0.3465\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0976 - accuracy: 0.3587 - val_loss: 1.0982 - val_accuracy: 0.3555\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0959 - accuracy: 0.3740 - val_loss: 1.0971 - val_accuracy: 0.3665\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0948 - accuracy: 0.3775 - val_loss: 1.0958 - val_accuracy: 0.3710\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0937 - accuracy: 0.3808 - val_loss: 1.0942 - val_accuracy: 0.3780\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0926 - accuracy: 0.3829 - val_loss: 1.0923 - val_accuracy: 0.3890\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0891 - accuracy: 0.3898 - val_loss: 1.0904 - val_accuracy: 0.3925\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0875 - accuracy: 0.3952 - val_loss: 1.0874 - val_accuracy: 0.4030\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0858 - accuracy: 0.3924 - val_loss: 1.0848 - val_accuracy: 0.4080\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0825 - accuracy: 0.4074 - val_loss: 1.0817 - val_accuracy: 0.4100\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0812 - accuracy: 0.3977 - val_loss: 1.0784 - val_accuracy: 0.4090\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0780 - accuracy: 0.3979 - val_loss: 1.0745 - val_accuracy: 0.4125\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0746 - accuracy: 0.4071 - val_loss: 1.0709 - val_accuracy: 0.4125\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0707 - accuracy: 0.4095 - val_loss: 1.0678 - val_accuracy: 0.4075\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0678 - accuracy: 0.4174 - val_loss: 1.0627 - val_accuracy: 0.4125\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0628 - accuracy: 0.4276 - val_loss: 1.0588 - val_accuracy: 0.4145\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0586 - accuracy: 0.4306 - val_loss: 1.0528 - val_accuracy: 0.4210\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0552 - accuracy: 0.4371 - val_loss: 1.0485 - val_accuracy: 0.4305\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0498 - accuracy: 0.4400 - val_loss: 1.0450 - val_accuracy: 0.4345\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0480 - accuracy: 0.4380 - val_loss: 1.0382 - val_accuracy: 0.4435\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0409 - accuracy: 0.4500 - val_loss: 1.0360 - val_accuracy: 0.4440\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0392 - accuracy: 0.4491 - val_loss: 1.0320 - val_accuracy: 0.4530\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0370 - accuracy: 0.4487 - val_loss: 1.0283 - val_accuracy: 0.4620\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.0330 - accuracy: 0.4524 - val_loss: 1.0218 - val_accuracy: 0.4695\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.0335 - accuracy: 0.4466 - val_loss: 1.0209 - val_accuracy: 0.4700\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.0251 - accuracy: 0.4622 - val_loss: 1.0171 - val_accuracy: 0.4635\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0249 - accuracy: 0.4570 - val_loss: 1.0110 - val_accuracy: 0.4675\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0179 - accuracy: 0.4642 - val_loss: 1.0096 - val_accuracy: 0.4760\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0151 - accuracy: 0.4714 - val_loss: 1.0027 - val_accuracy: 0.4835\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0094 - accuracy: 0.4742 - val_loss: 1.0019 - val_accuracy: 0.4840\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0113 - accuracy: 0.4717 - val_loss: 0.9970 - val_accuracy: 0.4915\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0071 - accuracy: 0.4759 - val_loss: 0.9940 - val_accuracy: 0.4965\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0009 - accuracy: 0.4824 - val_loss: 0.9943 - val_accuracy: 0.4965\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 0.9972 - accuracy: 0.4843 - val_loss: 0.9860 - val_accuracy: 0.4995\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 0.9958 - accuracy: 0.4848 - val_loss: 0.9819 - val_accuracy: 0.5075\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 0.9920 - accuracy: 0.4871 - val_loss: 0.9815 - val_accuracy: 0.5095\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 0.9912 - accuracy: 0.4920 - val_loss: 0.9794 - val_accuracy: 0.5120\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 0.9892 - accuracy: 0.4938 - val_loss: 0.9742 - val_accuracy: 0.5165\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 0.9871 - accuracy: 0.4974 - val_loss: 0.9697 - val_accuracy: 0.5265\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.9810 - accuracy: 0.4995 - val_loss: 0.9885 - val_accuracy: 0.5065\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.9810 - accuracy: 0.5030 - val_loss: 0.9636 - val_accuracy: 0.5315\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.9738 - accuracy: 0.5098 - val_loss: 0.9650 - val_accuracy: 0.5240\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.9749 - accuracy: 0.5074 - val_loss: 0.9592 - val_accuracy: 0.5305\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.9723 - accuracy: 0.5082 - val_loss: 0.9568 - val_accuracy: 0.5330\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.9698 - accuracy: 0.5166 - val_loss: 0.9547 - val_accuracy: 0.5420\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.9692 - accuracy: 0.5154 - val_loss: 0.9523 - val_accuracy: 0.5580\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.9628 - accuracy: 0.5185 - val_loss: 0.9466 - val_accuracy: 0.5540\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.9555 - accuracy: 0.5306 - val_loss: 0.9554 - val_accuracy: 0.5440\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.9561 - accuracy: 0.5251 - val_loss: 0.9414 - val_accuracy: 0.5565\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.9556 - accuracy: 0.5230 - val_loss: 0.9475 - val_accuracy: 0.5580\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.9466 - accuracy: 0.5386 - val_loss: 0.9370 - val_accuracy: 0.5610\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.9474 - accuracy: 0.5404 - val_loss: 0.9410 - val_accuracy: 0.5590\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.9490 - accuracy: 0.5371 - val_loss: 0.9343 - val_accuracy: 0.5715\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.9466 - accuracy: 0.5437 - val_loss: 0.9322 - val_accuracy: 0.5680\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.9385 - accuracy: 0.5475 - val_loss: 0.9404 - val_accuracy: 0.5690\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.9391 - accuracy: 0.5431 - val_loss: 0.9310 - val_accuracy: 0.5735\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.9361 - accuracy: 0.5434 - val_loss: 0.9271 - val_accuracy: 0.5720\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.9321 - accuracy: 0.5518 - val_loss: 0.9265 - val_accuracy: 0.5700\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.9344 - accuracy: 0.5477 - val_loss: 0.9236 - val_accuracy: 0.5740\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.9283 - accuracy: 0.5543 - val_loss: 0.9253 - val_accuracy: 0.5695\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.9297 - accuracy: 0.5539 - val_loss: 0.9183 - val_accuracy: 0.5785\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.9299 - accuracy: 0.5518 - val_loss: 0.9234 - val_accuracy: 0.5795\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.9221 - accuracy: 0.5556 - val_loss: 0.9184 - val_accuracy: 0.5800\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.9232 - accuracy: 0.5591 - val_loss: 0.9160 - val_accuracy: 0.5845\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.9214 - accuracy: 0.5645 - val_loss: 0.9153 - val_accuracy: 0.5790\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.9184 - accuracy: 0.5627 - val_loss: 0.9210 - val_accuracy: 0.5760\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.9144 - accuracy: 0.5716 - val_loss: 0.9144 - val_accuracy: 0.5750\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.9195 - accuracy: 0.5604 - val_loss: 0.9163 - val_accuracy: 0.5805\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.9112 - accuracy: 0.5665 - val_loss: 0.9152 - val_accuracy: 0.5720\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.9106 - accuracy: 0.5776 - val_loss: 0.9106 - val_accuracy: 0.5830\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.9135 - accuracy: 0.5721 - val_loss: 0.9138 - val_accuracy: 0.5795\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.9070 - accuracy: 0.5782 - val_loss: 0.9087 - val_accuracy: 0.5785\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.9124 - accuracy: 0.5717 - val_loss: 0.9076 - val_accuracy: 0.5760\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.9083 - accuracy: 0.5730 - val_loss: 0.9099 - val_accuracy: 0.5800\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.9065 - accuracy: 0.5789 - val_loss: 0.9058 - val_accuracy: 0.5820\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.9053 - accuracy: 0.5779 - val_loss: 0.9061 - val_accuracy: 0.5790\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.9075 - accuracy: 0.5764 - val_loss: 0.9093 - val_accuracy: 0.5800\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.9060 - accuracy: 0.5766 - val_loss: 0.9058 - val_accuracy: 0.5845\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.9006 - accuracy: 0.5807 - val_loss: 0.9046 - val_accuracy: 0.5825\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.9029 - accuracy: 0.5850 - val_loss: 0.9090 - val_accuracy: 0.5850\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.9026 - accuracy: 0.5800 - val_loss: 0.9061 - val_accuracy: 0.5805\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.9013 - accuracy: 0.5785 - val_loss: 0.9053 - val_accuracy: 0.5790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.8979 - accuracy: 0.5810 - val_loss: 0.9052 - val_accuracy: 0.5765\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.8921 - accuracy: 0.5906 - val_loss: 0.9065 - val_accuracy: 0.5810\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.8959 - accuracy: 0.5856 - val_loss: 0.9031 - val_accuracy: 0.5840\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.8987 - accuracy: 0.5815 - val_loss: 0.9039 - val_accuracy: 0.5830\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.8969 - accuracy: 0.5882 - val_loss: 0.9029 - val_accuracy: 0.5785\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.8959 - accuracy: 0.5864 - val_loss: 0.9039 - val_accuracy: 0.5845\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.8917 - accuracy: 0.5845 - val_loss: 0.9024 - val_accuracy: 0.5785\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.8935 - accuracy: 0.5879 - val_loss: 0.9061 - val_accuracy: 0.5845\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.8953 - accuracy: 0.5857 - val_loss: 0.9049 - val_accuracy: 0.5800\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.8883 - accuracy: 0.5840 - val_loss: 0.8996 - val_accuracy: 0.5880\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.8933 - accuracy: 0.5885 - val_loss: 0.9062 - val_accuracy: 0.5760\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.8901 - accuracy: 0.5867 - val_loss: 0.9057 - val_accuracy: 0.5825\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.8904 - accuracy: 0.5869 - val_loss: 0.9058 - val_accuracy: 0.5780\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.8815 - accuracy: 0.5924 - val_loss: 0.8999 - val_accuracy: 0.5835\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.8834 - accuracy: 0.5905 - val_loss: 0.8946 - val_accuracy: 0.5945\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.8837 - accuracy: 0.5920 - val_loss: 0.8970 - val_accuracy: 0.5810\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.8847 - accuracy: 0.5896 - val_loss: 0.8943 - val_accuracy: 0.5915\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.8841 - accuracy: 0.5882 - val_loss: 0.8971 - val_accuracy: 0.5910\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.8894 - accuracy: 0.5863 - val_loss: 0.8926 - val_accuracy: 0.5895\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.8777 - accuracy: 0.5893 - val_loss: 0.9010 - val_accuracy: 0.5795\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.8812 - accuracy: 0.5978 - val_loss: 0.8984 - val_accuracy: 0.5840\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.8767 - accuracy: 0.5969 - val_loss: 0.9143 - val_accuracy: 0.5700\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.8794 - accuracy: 0.5959 - val_loss: 0.8914 - val_accuracy: 0.5870\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.8747 - accuracy: 0.5975 - val_loss: 0.8960 - val_accuracy: 0.5890\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.8784 - accuracy: 0.5986 - val_loss: 0.8898 - val_accuracy: 0.5880\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.8791 - accuracy: 0.5997 - val_loss: 0.8921 - val_accuracy: 0.5890\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.8742 - accuracy: 0.5972 - val_loss: 0.9029 - val_accuracy: 0.5810\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.8754 - accuracy: 0.5986 - val_loss: 0.8875 - val_accuracy: 0.5915\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.8665 - accuracy: 0.6070 - val_loss: 0.8849 - val_accuracy: 0.5880\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.8699 - accuracy: 0.6025 - val_loss: 0.8919 - val_accuracy: 0.5845\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.8627 - accuracy: 0.6040 - val_loss: 0.8960 - val_accuracy: 0.5850\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.8669 - accuracy: 0.6089 - val_loss: 0.8916 - val_accuracy: 0.5870\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.8673 - accuracy: 0.5994 - val_loss: 0.8913 - val_accuracy: 0.5850\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.8689 - accuracy: 0.6055 - val_loss: 0.8795 - val_accuracy: 0.5975\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.8606 - accuracy: 0.6080 - val_loss: 0.8818 - val_accuracy: 0.5970\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.8583 - accuracy: 0.6137 - val_loss: 0.8825 - val_accuracy: 0.5940\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.8592 - accuracy: 0.6141 - val_loss: 0.8807 - val_accuracy: 0.5955\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.8601 - accuracy: 0.6112 - val_loss: 0.8770 - val_accuracy: 0.5975\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.8604 - accuracy: 0.6143 - val_loss: 0.8755 - val_accuracy: 0.5990\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.8556 - accuracy: 0.6104 - val_loss: 0.8755 - val_accuracy: 0.5995\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.8512 - accuracy: 0.6090 - val_loss: 0.8756 - val_accuracy: 0.6055\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.8576 - accuracy: 0.6100 - val_loss: 0.8854 - val_accuracy: 0.5970\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.8547 - accuracy: 0.6155 - val_loss: 0.8779 - val_accuracy: 0.5945\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.8499 - accuracy: 0.6176 - val_loss: 0.8731 - val_accuracy: 0.5970\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.8444 - accuracy: 0.6154 - val_loss: 0.8717 - val_accuracy: 0.6100\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.8487 - accuracy: 0.6198 - val_loss: 0.8694 - val_accuracy: 0.6045\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.8409 - accuracy: 0.6239 - val_loss: 0.8654 - val_accuracy: 0.6100\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.8434 - accuracy: 0.6183 - val_loss: 0.8654 - val_accuracy: 0.6145\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.8395 - accuracy: 0.6219 - val_loss: 0.8652 - val_accuracy: 0.6080\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.8463 - accuracy: 0.6199 - val_loss: 0.8626 - val_accuracy: 0.6130\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.8424 - accuracy: 0.6143 - val_loss: 0.8603 - val_accuracy: 0.6165\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.8445 - accuracy: 0.6215 - val_loss: 0.8636 - val_accuracy: 0.6100\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.8439 - accuracy: 0.6235 - val_loss: 0.8635 - val_accuracy: 0.6115\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.8388 - accuracy: 0.6225 - val_loss: 0.8569 - val_accuracy: 0.6200\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.8360 - accuracy: 0.6191 - val_loss: 0.8609 - val_accuracy: 0.6120\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.8334 - accuracy: 0.6286 - val_loss: 0.8594 - val_accuracy: 0.6125\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.8321 - accuracy: 0.6299 - val_loss: 0.8584 - val_accuracy: 0.6185\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.8338 - accuracy: 0.6301 - val_loss: 0.8651 - val_accuracy: 0.6080\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.8372 - accuracy: 0.6229 - val_loss: 0.8592 - val_accuracy: 0.6145\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.8335 - accuracy: 0.6301 - val_loss: 0.8514 - val_accuracy: 0.6210\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.8325 - accuracy: 0.6263 - val_loss: 0.8554 - val_accuracy: 0.6120\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.8262 - accuracy: 0.6340 - val_loss: 0.8593 - val_accuracy: 0.6105\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.8257 - accuracy: 0.6332 - val_loss: 0.8483 - val_accuracy: 0.6245\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.8264 - accuracy: 0.6326 - val_loss: 0.8508 - val_accuracy: 0.6240\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.8198 - accuracy: 0.6340 - val_loss: 0.8482 - val_accuracy: 0.6250\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.8248 - accuracy: 0.6334 - val_loss: 0.8465 - val_accuracy: 0.6215\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1032 - accuracy: 0.3219 - val_loss: 1.0992 - val_accuracy: 0.3365\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.1006 - accuracy: 0.3370 - val_loss: 1.0980 - val_accuracy: 0.3480\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0988 - accuracy: 0.3422 - val_loss: 1.0969 - val_accuracy: 0.3480\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0974 - accuracy: 0.3506 - val_loss: 1.0959 - val_accuracy: 0.3680\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0960 - accuracy: 0.3582 - val_loss: 1.0946 - val_accuracy: 0.3700\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3663 - val_loss: 1.0932 - val_accuracy: 0.3780\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0927 - accuracy: 0.3758 - val_loss: 1.0913 - val_accuracy: 0.3840\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0909 - accuracy: 0.3775 - val_loss: 1.0891 - val_accuracy: 0.3940\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0887 - accuracy: 0.3855 - val_loss: 1.0862 - val_accuracy: 0.3960\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0864 - accuracy: 0.3857 - val_loss: 1.0838 - val_accuracy: 0.3960\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0846 - accuracy: 0.3898 - val_loss: 1.0809 - val_accuracy: 0.3970\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0799 - accuracy: 0.4062 - val_loss: 1.0768 - val_accuracy: 0.4020\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0763 - accuracy: 0.4053 - val_loss: 1.0728 - val_accuracy: 0.4035\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0717 - accuracy: 0.4095 - val_loss: 1.0679 - val_accuracy: 0.4120\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0675 - accuracy: 0.4225 - val_loss: 1.0629 - val_accuracy: 0.4200\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0621 - accuracy: 0.4268 - val_loss: 1.0575 - val_accuracy: 0.4160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0574 - accuracy: 0.4338 - val_loss: 1.0504 - val_accuracy: 0.4300\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.0526 - accuracy: 0.4311 - val_loss: 1.0442 - val_accuracy: 0.4385\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.0458 - accuracy: 0.4449 - val_loss: 1.0370 - val_accuracy: 0.4435\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.0430 - accuracy: 0.4412 - val_loss: 1.0293 - val_accuracy: 0.4540\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.0329 - accuracy: 0.4564 - val_loss: 1.0216 - val_accuracy: 0.4640\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.0258 - accuracy: 0.4572 - val_loss: 1.0151 - val_accuracy: 0.4745\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.0159 - accuracy: 0.4669 - val_loss: 1.0067 - val_accuracy: 0.4770\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.0118 - accuracy: 0.4799 - val_loss: 0.9993 - val_accuracy: 0.4805\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.0042 - accuracy: 0.4819 - val_loss: 0.9917 - val_accuracy: 0.4820\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 0.9973 - accuracy: 0.4794 - val_loss: 0.9850 - val_accuracy: 0.4975\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 0.9914 - accuracy: 0.4930 - val_loss: 0.9789 - val_accuracy: 0.4965\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 0.9834 - accuracy: 0.4936 - val_loss: 0.9718 - val_accuracy: 0.5035\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 0.9807 - accuracy: 0.4916 - val_loss: 0.9650 - val_accuracy: 0.5015\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 0.9746 - accuracy: 0.4991 - val_loss: 0.9591 - val_accuracy: 0.5055\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 0.9698 - accuracy: 0.4995 - val_loss: 0.9545 - val_accuracy: 0.5040\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 0.9627 - accuracy: 0.4971 - val_loss: 0.9539 - val_accuracy: 0.5130\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 0.9599 - accuracy: 0.5025 - val_loss: 0.9448 - val_accuracy: 0.5055\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 0.9543 - accuracy: 0.5101 - val_loss: 0.9422 - val_accuracy: 0.5090\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 0.9488 - accuracy: 0.5113 - val_loss: 0.9361 - val_accuracy: 0.5115\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 0.9493 - accuracy: 0.5061 - val_loss: 0.9344 - val_accuracy: 0.5160\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 0.9370 - accuracy: 0.5232 - val_loss: 0.9280 - val_accuracy: 0.5165\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 0.9346 - accuracy: 0.5261 - val_loss: 0.9231 - val_accuracy: 0.5305\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 0.9296 - accuracy: 0.5236 - val_loss: 0.9265 - val_accuracy: 0.5250\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 0.9279 - accuracy: 0.5259 - val_loss: 0.9187 - val_accuracy: 0.5295\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 0.9193 - accuracy: 0.5381 - val_loss: 0.9168 - val_accuracy: 0.5375\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.9155 - accuracy: 0.5389 - val_loss: 0.9102 - val_accuracy: 0.5340\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.9122 - accuracy: 0.5440 - val_loss: 0.9085 - val_accuracy: 0.5350\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.9121 - accuracy: 0.5452 - val_loss: 0.9057 - val_accuracy: 0.5405\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.9001 - accuracy: 0.5493 - val_loss: 0.9046 - val_accuracy: 0.5445\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.8981 - accuracy: 0.5586 - val_loss: 0.8999 - val_accuracy: 0.5455\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.8979 - accuracy: 0.5548 - val_loss: 0.8979 - val_accuracy: 0.5505\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.8935 - accuracy: 0.5586 - val_loss: 0.8977 - val_accuracy: 0.5545\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.8883 - accuracy: 0.5721 - val_loss: 0.8915 - val_accuracy: 0.5650\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.8811 - accuracy: 0.5740 - val_loss: 0.8929 - val_accuracy: 0.5670\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.8811 - accuracy: 0.5723 - val_loss: 0.8868 - val_accuracy: 0.5755\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.8749 - accuracy: 0.5732 - val_loss: 0.8832 - val_accuracy: 0.5760\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.8733 - accuracy: 0.5867 - val_loss: 0.8786 - val_accuracy: 0.5815\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.8682 - accuracy: 0.5913 - val_loss: 0.8750 - val_accuracy: 0.5970\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.8638 - accuracy: 0.5969 - val_loss: 0.8707 - val_accuracy: 0.5980\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.8563 - accuracy: 0.6028 - val_loss: 0.8674 - val_accuracy: 0.6045\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.8550 - accuracy: 0.6040 - val_loss: 0.8688 - val_accuracy: 0.5970\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.8530 - accuracy: 0.6122 - val_loss: 0.8599 - val_accuracy: 0.6155\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.8462 - accuracy: 0.6151 - val_loss: 0.8599 - val_accuracy: 0.6110\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.8369 - accuracy: 0.6259 - val_loss: 0.8490 - val_accuracy: 0.6205\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.8289 - accuracy: 0.6290 - val_loss: 0.8463 - val_accuracy: 0.6220\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.8271 - accuracy: 0.6288 - val_loss: 0.8390 - val_accuracy: 0.6295\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.8215 - accuracy: 0.6379 - val_loss: 0.8305 - val_accuracy: 0.6365\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.8131 - accuracy: 0.6376 - val_loss: 0.8288 - val_accuracy: 0.6315\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.8094 - accuracy: 0.6417 - val_loss: 0.8248 - val_accuracy: 0.6370\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.8068 - accuracy: 0.6453 - val_loss: 0.8200 - val_accuracy: 0.6380\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.7973 - accuracy: 0.6501 - val_loss: 0.8127 - val_accuracy: 0.6495\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.7934 - accuracy: 0.6529 - val_loss: 0.8103 - val_accuracy: 0.6455\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.7908 - accuracy: 0.6514 - val_loss: 0.8048 - val_accuracy: 0.6515\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.7860 - accuracy: 0.6594 - val_loss: 0.8046 - val_accuracy: 0.6490\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.7846 - accuracy: 0.6581 - val_loss: 0.7933 - val_accuracy: 0.6560\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.7771 - accuracy: 0.6637 - val_loss: 0.7883 - val_accuracy: 0.6560\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.7722 - accuracy: 0.6624 - val_loss: 0.7883 - val_accuracy: 0.6560\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.7783 - accuracy: 0.6610 - val_loss: 0.7880 - val_accuracy: 0.6590\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.7638 - accuracy: 0.6679 - val_loss: 0.7803 - val_accuracy: 0.6635\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.7643 - accuracy: 0.6697 - val_loss: 0.7797 - val_accuracy: 0.6650\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.7583 - accuracy: 0.6755 - val_loss: 0.7820 - val_accuracy: 0.6595\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.7538 - accuracy: 0.6710 - val_loss: 0.7851 - val_accuracy: 0.6615\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.7534 - accuracy: 0.6721 - val_loss: 0.7754 - val_accuracy: 0.6650\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.7499 - accuracy: 0.6789 - val_loss: 0.7667 - val_accuracy: 0.6745\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.7455 - accuracy: 0.6759 - val_loss: 0.7705 - val_accuracy: 0.6680\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.7473 - accuracy: 0.6712 - val_loss: 0.7675 - val_accuracy: 0.6705\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.7439 - accuracy: 0.6786 - val_loss: 0.7673 - val_accuracy: 0.6760\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.7448 - accuracy: 0.6793 - val_loss: 0.7667 - val_accuracy: 0.6710\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.7439 - accuracy: 0.6775 - val_loss: 0.7701 - val_accuracy: 0.6725\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.7379 - accuracy: 0.6849 - val_loss: 0.7698 - val_accuracy: 0.6765\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.7421 - accuracy: 0.6780 - val_loss: 0.7701 - val_accuracy: 0.6730\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.7324 - accuracy: 0.6875 - val_loss: 0.7596 - val_accuracy: 0.6765\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.7316 - accuracy: 0.6890 - val_loss: 0.7530 - val_accuracy: 0.6820\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.7265 - accuracy: 0.6925 - val_loss: 0.7538 - val_accuracy: 0.6780\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.7317 - accuracy: 0.6890 - val_loss: 0.7657 - val_accuracy: 0.6700\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.7253 - accuracy: 0.6954 - val_loss: 0.7764 - val_accuracy: 0.6705\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.7280 - accuracy: 0.6948 - val_loss: 0.7511 - val_accuracy: 0.6805\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.7160 - accuracy: 0.7007 - val_loss: 0.7601 - val_accuracy: 0.6745\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.7204 - accuracy: 0.7020 - val_loss: 0.7478 - val_accuracy: 0.6865\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.7151 - accuracy: 0.7045 - val_loss: 0.7505 - val_accuracy: 0.6745\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.7174 - accuracy: 0.6979 - val_loss: 0.7419 - val_accuracy: 0.6840\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.7136 - accuracy: 0.7090 - val_loss: 0.7569 - val_accuracy: 0.6775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.7087 - accuracy: 0.7113 - val_loss: 0.7438 - val_accuracy: 0.6825\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.7056 - accuracy: 0.7106 - val_loss: 0.7431 - val_accuracy: 0.6775\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.7049 - accuracy: 0.7097 - val_loss: 0.7421 - val_accuracy: 0.6865\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.7005 - accuracy: 0.7072 - val_loss: 0.7418 - val_accuracy: 0.6935\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.6975 - accuracy: 0.7150 - val_loss: 0.7368 - val_accuracy: 0.6915\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.6986 - accuracy: 0.7106 - val_loss: 0.7344 - val_accuracy: 0.6900\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.6991 - accuracy: 0.7126 - val_loss: 0.7423 - val_accuracy: 0.6940\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.6971 - accuracy: 0.7131 - val_loss: 0.7389 - val_accuracy: 0.6860\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.6885 - accuracy: 0.7141 - val_loss: 0.7321 - val_accuracy: 0.6915\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.6928 - accuracy: 0.7139 - val_loss: 0.7333 - val_accuracy: 0.6920\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.6913 - accuracy: 0.7107 - val_loss: 0.7423 - val_accuracy: 0.6885\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.6935 - accuracy: 0.7160 - val_loss: 0.7280 - val_accuracy: 0.6985\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.6936 - accuracy: 0.7172 - val_loss: 0.7329 - val_accuracy: 0.6910\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.6843 - accuracy: 0.7190 - val_loss: 0.7358 - val_accuracy: 0.6960\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.6909 - accuracy: 0.7134 - val_loss: 0.7350 - val_accuracy: 0.6995\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.6841 - accuracy: 0.7221 - val_loss: 0.7348 - val_accuracy: 0.6965\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.6834 - accuracy: 0.7206 - val_loss: 0.7330 - val_accuracy: 0.6945\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.6839 - accuracy: 0.7193 - val_loss: 0.7276 - val_accuracy: 0.6945\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.6779 - accuracy: 0.7209 - val_loss: 0.7322 - val_accuracy: 0.6920\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.6758 - accuracy: 0.7284 - val_loss: 0.7227 - val_accuracy: 0.7025\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.6733 - accuracy: 0.7274 - val_loss: 0.7307 - val_accuracy: 0.7020\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.6752 - accuracy: 0.7241 - val_loss: 0.7258 - val_accuracy: 0.7020\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.6787 - accuracy: 0.7260 - val_loss: 0.7290 - val_accuracy: 0.6965\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.6770 - accuracy: 0.7262 - val_loss: 0.7285 - val_accuracy: 0.7045\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.6762 - accuracy: 0.7250 - val_loss: 0.7244 - val_accuracy: 0.6985\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.6743 - accuracy: 0.7259 - val_loss: 0.7196 - val_accuracy: 0.7050\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.6719 - accuracy: 0.7268 - val_loss: 0.7179 - val_accuracy: 0.7015\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.6787 - accuracy: 0.7274 - val_loss: 0.7286 - val_accuracy: 0.7050\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.6691 - accuracy: 0.7266 - val_loss: 0.7194 - val_accuracy: 0.7080\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.6587 - accuracy: 0.7322 - val_loss: 0.7194 - val_accuracy: 0.7035\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.6710 - accuracy: 0.7306 - val_loss: 0.7277 - val_accuracy: 0.7070\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.6673 - accuracy: 0.7331 - val_loss: 0.7208 - val_accuracy: 0.7080\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.6690 - accuracy: 0.7293 - val_loss: 0.7187 - val_accuracy: 0.7020\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.6641 - accuracy: 0.7300 - val_loss: 0.7180 - val_accuracy: 0.7060\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.6695 - accuracy: 0.7236 - val_loss: 0.7233 - val_accuracy: 0.7100\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.6562 - accuracy: 0.7341 - val_loss: 0.7178 - val_accuracy: 0.7075\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.6584 - accuracy: 0.7369 - val_loss: 0.7189 - val_accuracy: 0.7035\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.6528 - accuracy: 0.7336 - val_loss: 0.7155 - val_accuracy: 0.7115\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.6508 - accuracy: 0.7349 - val_loss: 0.7186 - val_accuracy: 0.7065\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.6587 - accuracy: 0.7346 - val_loss: 0.7178 - val_accuracy: 0.7030\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.6560 - accuracy: 0.7318 - val_loss: 0.7191 - val_accuracy: 0.7095\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.6529 - accuracy: 0.7374 - val_loss: 0.7158 - val_accuracy: 0.7110\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.6583 - accuracy: 0.7316 - val_loss: 0.7146 - val_accuracy: 0.7095\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.6536 - accuracy: 0.7320 - val_loss: 0.7121 - val_accuracy: 0.7070\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.6521 - accuracy: 0.7377 - val_loss: 0.7214 - val_accuracy: 0.7010\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.6569 - accuracy: 0.7351 - val_loss: 0.7144 - val_accuracy: 0.7080\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.6552 - accuracy: 0.7299 - val_loss: 0.7170 - val_accuracy: 0.7085\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.6538 - accuracy: 0.7340 - val_loss: 0.7170 - val_accuracy: 0.7065\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.6552 - accuracy: 0.7346 - val_loss: 0.7146 - val_accuracy: 0.7085\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.6489 - accuracy: 0.7352 - val_loss: 0.7192 - val_accuracy: 0.7070\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.6489 - accuracy: 0.7372 - val_loss: 0.7182 - val_accuracy: 0.7080\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.6469 - accuracy: 0.7365 - val_loss: 0.7135 - val_accuracy: 0.7105\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1043 - accuracy: 0.3128 - val_loss: 1.0996 - val_accuracy: 0.3175\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3332 - val_loss: 1.0970 - val_accuracy: 0.3380\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3458 - val_loss: 1.0950 - val_accuracy: 0.3565\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0950 - accuracy: 0.3521 - val_loss: 1.0929 - val_accuracy: 0.3745\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0937 - accuracy: 0.3689 - val_loss: 1.0906 - val_accuracy: 0.4145\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0907 - accuracy: 0.3830 - val_loss: 1.0878 - val_accuracy: 0.4310\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0876 - accuracy: 0.3943 - val_loss: 1.0843 - val_accuracy: 0.4390\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0850 - accuracy: 0.3943 - val_loss: 1.0799 - val_accuracy: 0.4470\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0795 - accuracy: 0.4112 - val_loss: 1.0744 - val_accuracy: 0.4500\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0738 - accuracy: 0.4098 - val_loss: 1.0674 - val_accuracy: 0.4635\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0681 - accuracy: 0.4244 - val_loss: 1.0598 - val_accuracy: 0.4745\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0595 - accuracy: 0.4291 - val_loss: 1.0503 - val_accuracy: 0.4870\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0517 - accuracy: 0.4340 - val_loss: 1.0386 - val_accuracy: 0.4895\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0430 - accuracy: 0.4425 - val_loss: 1.0264 - val_accuracy: 0.5015\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.0287 - accuracy: 0.4527 - val_loss: 1.0120 - val_accuracy: 0.5015\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.0200 - accuracy: 0.4566 - val_loss: 0.9980 - val_accuracy: 0.5085\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.0047 - accuracy: 0.4821 - val_loss: 0.9835 - val_accuracy: 0.5165\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 0.9934 - accuracy: 0.4818 - val_loss: 0.9709 - val_accuracy: 0.5215\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 0.9836 - accuracy: 0.4951 - val_loss: 0.9594 - val_accuracy: 0.5340\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 0.9719 - accuracy: 0.4986 - val_loss: 0.9482 - val_accuracy: 0.5390\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 0.9662 - accuracy: 0.5124 - val_loss: 0.9403 - val_accuracy: 0.5425\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 0.9593 - accuracy: 0.5180 - val_loss: 0.9331 - val_accuracy: 0.5485\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 0.9467 - accuracy: 0.5206 - val_loss: 0.9247 - val_accuracy: 0.5605\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 0.9420 - accuracy: 0.5271 - val_loss: 0.9157 - val_accuracy: 0.5640\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 0.9265 - accuracy: 0.5412 - val_loss: 0.9078 - val_accuracy: 0.5685\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 0.9262 - accuracy: 0.5433 - val_loss: 0.8990 - val_accuracy: 0.5725\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 0.9130 - accuracy: 0.5583 - val_loss: 0.8906 - val_accuracy: 0.5790\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 0.9003 - accuracy: 0.5681 - val_loss: 0.8814 - val_accuracy: 0.5870\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 0.9016 - accuracy: 0.5666 - val_loss: 0.8758 - val_accuracy: 0.6005\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 0.8923 - accuracy: 0.5781 - val_loss: 0.8654 - val_accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 0.8858 - accuracy: 0.5855 - val_loss: 0.8629 - val_accuracy: 0.6005\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 0.8780 - accuracy: 0.5913 - val_loss: 0.8511 - val_accuracy: 0.6235\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 0.8717 - accuracy: 0.5941 - val_loss: 0.8430 - val_accuracy: 0.6235\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 0.8623 - accuracy: 0.6022 - val_loss: 0.8367 - val_accuracy: 0.6315\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 0.8533 - accuracy: 0.6093 - val_loss: 0.8270 - val_accuracy: 0.6360\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 0.8481 - accuracy: 0.6053 - val_loss: 0.8203 - val_accuracy: 0.6415\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 0.8419 - accuracy: 0.6185 - val_loss: 0.8159 - val_accuracy: 0.6430\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 0.8410 - accuracy: 0.6162 - val_loss: 0.8098 - val_accuracy: 0.6495\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 0.8367 - accuracy: 0.6248 - val_loss: 0.8044 - val_accuracy: 0.6495\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 0.8268 - accuracy: 0.6274 - val_loss: 0.7991 - val_accuracy: 0.6545\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 0.8196 - accuracy: 0.6354 - val_loss: 0.7958 - val_accuracy: 0.6555\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.8173 - accuracy: 0.6350 - val_loss: 0.7918 - val_accuracy: 0.6605\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.8101 - accuracy: 0.6354 - val_loss: 0.7856 - val_accuracy: 0.6625\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.8076 - accuracy: 0.6414 - val_loss: 0.7833 - val_accuracy: 0.6650\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.8014 - accuracy: 0.6444 - val_loss: 0.7782 - val_accuracy: 0.6650\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.7988 - accuracy: 0.6461 - val_loss: 0.7778 - val_accuracy: 0.6725\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.7926 - accuracy: 0.6503 - val_loss: 0.7739 - val_accuracy: 0.6680\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.7834 - accuracy: 0.6546 - val_loss: 0.7693 - val_accuracy: 0.6685\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.7948 - accuracy: 0.6475 - val_loss: 0.7702 - val_accuracy: 0.6740\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.7882 - accuracy: 0.6536 - val_loss: 0.7709 - val_accuracy: 0.6725\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.7824 - accuracy: 0.6509 - val_loss: 0.7623 - val_accuracy: 0.6795\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.7813 - accuracy: 0.6559 - val_loss: 0.7653 - val_accuracy: 0.6685\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.7745 - accuracy: 0.6660 - val_loss: 0.7568 - val_accuracy: 0.6800\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.7675 - accuracy: 0.6656 - val_loss: 0.7543 - val_accuracy: 0.6865\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.7737 - accuracy: 0.6670 - val_loss: 0.7580 - val_accuracy: 0.6820\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.7653 - accuracy: 0.6686 - val_loss: 0.7477 - val_accuracy: 0.6820\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.7629 - accuracy: 0.6744 - val_loss: 0.7472 - val_accuracy: 0.6830\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.7646 - accuracy: 0.6660 - val_loss: 0.7438 - val_accuracy: 0.6850\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.7564 - accuracy: 0.6739 - val_loss: 0.7408 - val_accuracy: 0.6880\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.7565 - accuracy: 0.6762 - val_loss: 0.7389 - val_accuracy: 0.6910\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.7524 - accuracy: 0.6793 - val_loss: 0.7372 - val_accuracy: 0.6850\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.7462 - accuracy: 0.6795 - val_loss: 0.7354 - val_accuracy: 0.6885\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.7425 - accuracy: 0.6806 - val_loss: 0.7325 - val_accuracy: 0.6910\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.7446 - accuracy: 0.6808 - val_loss: 0.7281 - val_accuracy: 0.6915\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.7398 - accuracy: 0.6871 - val_loss: 0.7253 - val_accuracy: 0.6930\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.7374 - accuracy: 0.6801 - val_loss: 0.7216 - val_accuracy: 0.6940\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.7319 - accuracy: 0.6856 - val_loss: 0.7170 - val_accuracy: 0.6930\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.7323 - accuracy: 0.6881 - val_loss: 0.7126 - val_accuracy: 0.6935\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.7305 - accuracy: 0.6898 - val_loss: 0.7104 - val_accuracy: 0.6980\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.7303 - accuracy: 0.6886 - val_loss: 0.7184 - val_accuracy: 0.6880\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.7225 - accuracy: 0.6927 - val_loss: 0.7032 - val_accuracy: 0.7035\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.7176 - accuracy: 0.6959 - val_loss: 0.6984 - val_accuracy: 0.7055\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.7169 - accuracy: 0.7016 - val_loss: 0.6937 - val_accuracy: 0.7045\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.7059 - accuracy: 0.7071 - val_loss: 0.6898 - val_accuracy: 0.7095\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.7022 - accuracy: 0.7070 - val_loss: 0.6802 - val_accuracy: 0.7125\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.6973 - accuracy: 0.7121 - val_loss: 0.6768 - val_accuracy: 0.7130\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.6955 - accuracy: 0.7115 - val_loss: 0.6691 - val_accuracy: 0.7230\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.6937 - accuracy: 0.7145 - val_loss: 0.6648 - val_accuracy: 0.7255\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.6813 - accuracy: 0.7216 - val_loss: 0.6578 - val_accuracy: 0.7285\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.6678 - accuracy: 0.7275 - val_loss: 0.6520 - val_accuracy: 0.7340\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.6754 - accuracy: 0.7244 - val_loss: 0.6499 - val_accuracy: 0.7345\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.6665 - accuracy: 0.7295 - val_loss: 0.6426 - val_accuracy: 0.7375\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.6680 - accuracy: 0.7269 - val_loss: 0.6440 - val_accuracy: 0.7370\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.6593 - accuracy: 0.7314 - val_loss: 0.6393 - val_accuracy: 0.7430\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.6531 - accuracy: 0.7369 - val_loss: 0.6285 - val_accuracy: 0.7450\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.6515 - accuracy: 0.7401 - val_loss: 0.6303 - val_accuracy: 0.7485\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.6468 - accuracy: 0.7452 - val_loss: 0.6246 - val_accuracy: 0.7510\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.6438 - accuracy: 0.7400 - val_loss: 0.6212 - val_accuracy: 0.7590\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.6384 - accuracy: 0.7425 - val_loss: 0.6174 - val_accuracy: 0.7580\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.6367 - accuracy: 0.7456 - val_loss: 0.6168 - val_accuracy: 0.7545\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.6351 - accuracy: 0.7471 - val_loss: 0.6171 - val_accuracy: 0.7515\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.6457 - accuracy: 0.7409 - val_loss: 0.6169 - val_accuracy: 0.7570\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.6246 - accuracy: 0.7530 - val_loss: 0.6083 - val_accuracy: 0.7585\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.6186 - accuracy: 0.7556 - val_loss: 0.6077 - val_accuracy: 0.7575\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.6223 - accuracy: 0.7531 - val_loss: 0.6076 - val_accuracy: 0.7600\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.6251 - accuracy: 0.7485 - val_loss: 0.6026 - val_accuracy: 0.7615\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.6195 - accuracy: 0.7544 - val_loss: 0.6033 - val_accuracy: 0.7635\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.6136 - accuracy: 0.7571 - val_loss: 0.6004 - val_accuracy: 0.7635\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.6099 - accuracy: 0.7607 - val_loss: 0.6009 - val_accuracy: 0.7640\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.6149 - accuracy: 0.7576 - val_loss: 0.6004 - val_accuracy: 0.7700\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.6080 - accuracy: 0.7615 - val_loss: 0.5975 - val_accuracy: 0.7695\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.6094 - accuracy: 0.7598 - val_loss: 0.5944 - val_accuracy: 0.7670\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.6049 - accuracy: 0.7616 - val_loss: 0.5919 - val_accuracy: 0.7695\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.6060 - accuracy: 0.7646 - val_loss: 0.5951 - val_accuracy: 0.7610\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.6069 - accuracy: 0.7596 - val_loss: 0.5932 - val_accuracy: 0.7660\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.5970 - accuracy: 0.7646 - val_loss: 0.5883 - val_accuracy: 0.7690\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.5982 - accuracy: 0.7638 - val_loss: 0.5851 - val_accuracy: 0.7735\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.5946 - accuracy: 0.7621 - val_loss: 0.5953 - val_accuracy: 0.7605\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.5948 - accuracy: 0.7666 - val_loss: 0.5866 - val_accuracy: 0.7675\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.5883 - accuracy: 0.7684 - val_loss: 0.5834 - val_accuracy: 0.7685\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.5929 - accuracy: 0.7709 - val_loss: 0.5849 - val_accuracy: 0.7660\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.5976 - accuracy: 0.7657 - val_loss: 0.5773 - val_accuracy: 0.7745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.5883 - accuracy: 0.7720 - val_loss: 0.5777 - val_accuracy: 0.7760\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.5859 - accuracy: 0.7715 - val_loss: 0.5760 - val_accuracy: 0.7745\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.5848 - accuracy: 0.7731 - val_loss: 0.5768 - val_accuracy: 0.7650\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.5896 - accuracy: 0.7725 - val_loss: 0.5759 - val_accuracy: 0.7715\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.5793 - accuracy: 0.7759 - val_loss: 0.5716 - val_accuracy: 0.7685\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.5790 - accuracy: 0.7740 - val_loss: 0.5751 - val_accuracy: 0.7715\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.5816 - accuracy: 0.7729 - val_loss: 0.5729 - val_accuracy: 0.7765\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.5782 - accuracy: 0.7775 - val_loss: 0.5715 - val_accuracy: 0.7740\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.5777 - accuracy: 0.7745 - val_loss: 0.5712 - val_accuracy: 0.7775\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.5776 - accuracy: 0.7771 - val_loss: 0.5683 - val_accuracy: 0.7705\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.5799 - accuracy: 0.7699 - val_loss: 0.5682 - val_accuracy: 0.7730\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.5814 - accuracy: 0.7785 - val_loss: 0.5671 - val_accuracy: 0.7745\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.5740 - accuracy: 0.7780 - val_loss: 0.5657 - val_accuracy: 0.7730\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.5679 - accuracy: 0.7784 - val_loss: 0.5628 - val_accuracy: 0.7745\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.5764 - accuracy: 0.7801 - val_loss: 0.5622 - val_accuracy: 0.7770\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.5717 - accuracy: 0.7797 - val_loss: 0.5622 - val_accuracy: 0.7760\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.5720 - accuracy: 0.7801 - val_loss: 0.5623 - val_accuracy: 0.7765\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.5699 - accuracy: 0.7776 - val_loss: 0.5616 - val_accuracy: 0.7800\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.5739 - accuracy: 0.7770 - val_loss: 0.5625 - val_accuracy: 0.7765\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.5612 - accuracy: 0.7860 - val_loss: 0.5591 - val_accuracy: 0.7780\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.5702 - accuracy: 0.7779 - val_loss: 0.5599 - val_accuracy: 0.7775\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.5661 - accuracy: 0.7804 - val_loss: 0.5587 - val_accuracy: 0.7770\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.5617 - accuracy: 0.7797 - val_loss: 0.5614 - val_accuracy: 0.7770\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.5661 - accuracy: 0.7779 - val_loss: 0.5568 - val_accuracy: 0.7785\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.5668 - accuracy: 0.7793 - val_loss: 0.5623 - val_accuracy: 0.7810\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.5624 - accuracy: 0.7844 - val_loss: 0.5548 - val_accuracy: 0.7785\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.5641 - accuracy: 0.7807 - val_loss: 0.5709 - val_accuracy: 0.7740\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.5613 - accuracy: 0.7799 - val_loss: 0.5547 - val_accuracy: 0.7800\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.5633 - accuracy: 0.7790 - val_loss: 0.5538 - val_accuracy: 0.7760\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.5617 - accuracy: 0.7815 - val_loss: 0.5542 - val_accuracy: 0.7795\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.5590 - accuracy: 0.7846 - val_loss: 0.5544 - val_accuracy: 0.7790\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.5594 - accuracy: 0.7812 - val_loss: 0.5530 - val_accuracy: 0.7815\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.5604 - accuracy: 0.7844 - val_loss: 0.5534 - val_accuracy: 0.7820\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.5675 - accuracy: 0.7861 - val_loss: 0.5532 - val_accuracy: 0.7810\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.5564 - accuracy: 0.7820 - val_loss: 0.5534 - val_accuracy: 0.7855\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.5500 - accuracy: 0.7851 - val_loss: 0.5552 - val_accuracy: 0.7795\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.5580 - accuracy: 0.7865 - val_loss: 0.5586 - val_accuracy: 0.7800\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.5479 - accuracy: 0.7887 - val_loss: 0.5519 - val_accuracy: 0.7825\n",
      "Epoch 1/150\n",
      "32/32 - 0s - loss: 1.1030 - accuracy: 0.3285 - val_loss: 1.1017 - val_accuracy: 0.3135\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3329 - val_loss: 1.0974 - val_accuracy: 0.3365\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.0956 - accuracy: 0.3566 - val_loss: 1.0935 - val_accuracy: 0.3775\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.0917 - accuracy: 0.3775 - val_loss: 1.0891 - val_accuracy: 0.4060\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.0891 - accuracy: 0.3814 - val_loss: 1.0849 - val_accuracy: 0.4280\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.0838 - accuracy: 0.3997 - val_loss: 1.0797 - val_accuracy: 0.4390\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.0792 - accuracy: 0.4062 - val_loss: 1.0734 - val_accuracy: 0.4490\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.0737 - accuracy: 0.4187 - val_loss: 1.0652 - val_accuracy: 0.4675\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.0667 - accuracy: 0.4248 - val_loss: 1.0554 - val_accuracy: 0.4880\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.0565 - accuracy: 0.4394 - val_loss: 1.0429 - val_accuracy: 0.4935\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.0453 - accuracy: 0.4400 - val_loss: 1.0283 - val_accuracy: 0.5030\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.0331 - accuracy: 0.4559 - val_loss: 1.0116 - val_accuracy: 0.5090\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.0214 - accuracy: 0.4616 - val_loss: 0.9954 - val_accuracy: 0.5225\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.0098 - accuracy: 0.4616 - val_loss: 0.9784 - val_accuracy: 0.5260\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 0.9943 - accuracy: 0.4793 - val_loss: 0.9632 - val_accuracy: 0.5280\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 0.9837 - accuracy: 0.4881 - val_loss: 0.9470 - val_accuracy: 0.5375\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 0.9769 - accuracy: 0.4865 - val_loss: 0.9350 - val_accuracy: 0.5365\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 0.9701 - accuracy: 0.4918 - val_loss: 0.9250 - val_accuracy: 0.5450\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 0.9579 - accuracy: 0.5082 - val_loss: 0.9131 - val_accuracy: 0.5465\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 0.9458 - accuracy: 0.5149 - val_loss: 0.9010 - val_accuracy: 0.5670\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 0.9408 - accuracy: 0.5318 - val_loss: 0.8898 - val_accuracy: 0.5755\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 0.9309 - accuracy: 0.5418 - val_loss: 0.8795 - val_accuracy: 0.5835\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 0.9263 - accuracy: 0.5343 - val_loss: 0.8699 - val_accuracy: 0.5875\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 0.9150 - accuracy: 0.5466 - val_loss: 0.8584 - val_accuracy: 0.6030\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 0.9074 - accuracy: 0.5470 - val_loss: 0.8508 - val_accuracy: 0.6130\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 0.9017 - accuracy: 0.5515 - val_loss: 0.8378 - val_accuracy: 0.6195\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 0.8923 - accuracy: 0.5626 - val_loss: 0.8281 - val_accuracy: 0.6335\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 0.8790 - accuracy: 0.5754 - val_loss: 0.8156 - val_accuracy: 0.6395\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 0.8685 - accuracy: 0.5804 - val_loss: 0.8031 - val_accuracy: 0.6470\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 0.8582 - accuracy: 0.5922 - val_loss: 0.7936 - val_accuracy: 0.6605\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 0.8512 - accuracy: 0.6019 - val_loss: 0.7811 - val_accuracy: 0.6790\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 0.8383 - accuracy: 0.6091 - val_loss: 0.7702 - val_accuracy: 0.6745\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 0.8306 - accuracy: 0.6191 - val_loss: 0.7601 - val_accuracy: 0.6945\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 0.8206 - accuracy: 0.6215 - val_loss: 0.7502 - val_accuracy: 0.6970\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 0.8115 - accuracy: 0.6313 - val_loss: 0.7381 - val_accuracy: 0.7050\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 0.8030 - accuracy: 0.6345 - val_loss: 0.7274 - val_accuracy: 0.7070\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 0.7917 - accuracy: 0.6450 - val_loss: 0.7257 - val_accuracy: 0.7080\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 0.7865 - accuracy: 0.6480 - val_loss: 0.7097 - val_accuracy: 0.7220\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 0.7751 - accuracy: 0.6534 - val_loss: 0.7008 - val_accuracy: 0.7215\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 0.7714 - accuracy: 0.6612 - val_loss: 0.6954 - val_accuracy: 0.7200\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 0.7621 - accuracy: 0.6616 - val_loss: 0.6876 - val_accuracy: 0.7225\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.7506 - accuracy: 0.6653 - val_loss: 0.6817 - val_accuracy: 0.7315\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.7481 - accuracy: 0.6695 - val_loss: 0.6762 - val_accuracy: 0.7355\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.7441 - accuracy: 0.6768 - val_loss: 0.6819 - val_accuracy: 0.7235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.7329 - accuracy: 0.6810 - val_loss: 0.6613 - val_accuracy: 0.7435\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.7176 - accuracy: 0.6956 - val_loss: 0.6495 - val_accuracy: 0.7460\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.7156 - accuracy: 0.6941 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.7094 - accuracy: 0.6921 - val_loss: 0.6404 - val_accuracy: 0.7500\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.6968 - accuracy: 0.6982 - val_loss: 0.6357 - val_accuracy: 0.7520\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.6980 - accuracy: 0.7028 - val_loss: 0.6276 - val_accuracy: 0.7580\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.6875 - accuracy: 0.7105 - val_loss: 0.6236 - val_accuracy: 0.7560\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.6815 - accuracy: 0.7154 - val_loss: 0.6167 - val_accuracy: 0.7630\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.6679 - accuracy: 0.7258 - val_loss: 0.6065 - val_accuracy: 0.7685\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.6632 - accuracy: 0.7268 - val_loss: 0.6024 - val_accuracy: 0.7655\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.6483 - accuracy: 0.7312 - val_loss: 0.5888 - val_accuracy: 0.7790\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.6379 - accuracy: 0.7362 - val_loss: 0.5831 - val_accuracy: 0.7760\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.6399 - accuracy: 0.7389 - val_loss: 0.5788 - val_accuracy: 0.7775\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.6271 - accuracy: 0.7489 - val_loss: 0.5703 - val_accuracy: 0.7855\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.6263 - accuracy: 0.7418 - val_loss: 0.5695 - val_accuracy: 0.7835\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.6198 - accuracy: 0.7500 - val_loss: 0.5617 - val_accuracy: 0.7870\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.6124 - accuracy: 0.7549 - val_loss: 0.5540 - val_accuracy: 0.7940\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.6101 - accuracy: 0.7549 - val_loss: 0.5541 - val_accuracy: 0.7940\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.6041 - accuracy: 0.7569 - val_loss: 0.5453 - val_accuracy: 0.8005\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.5863 - accuracy: 0.7666 - val_loss: 0.5411 - val_accuracy: 0.7940\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.5906 - accuracy: 0.7701 - val_loss: 0.5363 - val_accuracy: 0.8000\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.5906 - accuracy: 0.7690 - val_loss: 0.5351 - val_accuracy: 0.8060\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.5756 - accuracy: 0.7735 - val_loss: 0.5341 - val_accuracy: 0.8065\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.5807 - accuracy: 0.7728 - val_loss: 0.5302 - val_accuracy: 0.8060\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.5708 - accuracy: 0.7770 - val_loss: 0.5240 - val_accuracy: 0.8060\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.5791 - accuracy: 0.7713 - val_loss: 0.5222 - val_accuracy: 0.8070\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.5743 - accuracy: 0.7772 - val_loss: 0.5224 - val_accuracy: 0.8035\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.5674 - accuracy: 0.7789 - val_loss: 0.5200 - val_accuracy: 0.8110\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.5575 - accuracy: 0.7826 - val_loss: 0.5147 - val_accuracy: 0.8120\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.5601 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.8115\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.5585 - accuracy: 0.7815 - val_loss: 0.5129 - val_accuracy: 0.8080\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.5532 - accuracy: 0.7837 - val_loss: 0.5065 - val_accuracy: 0.8125\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.5548 - accuracy: 0.7870 - val_loss: 0.5063 - val_accuracy: 0.8135\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.5529 - accuracy: 0.7843 - val_loss: 0.5073 - val_accuracy: 0.8120\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.5459 - accuracy: 0.7856 - val_loss: 0.5050 - val_accuracy: 0.8170\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.5479 - accuracy: 0.7860 - val_loss: 0.5023 - val_accuracy: 0.8185\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.5413 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.8175\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.5416 - accuracy: 0.7914 - val_loss: 0.4971 - val_accuracy: 0.8165\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.5333 - accuracy: 0.7944 - val_loss: 0.4952 - val_accuracy: 0.8210\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.5399 - accuracy: 0.7903 - val_loss: 0.4937 - val_accuracy: 0.8180\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.5353 - accuracy: 0.7912 - val_loss: 0.4906 - val_accuracy: 0.8175\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.5283 - accuracy: 0.7952 - val_loss: 0.4898 - val_accuracy: 0.8225\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.5228 - accuracy: 0.7962 - val_loss: 0.4861 - val_accuracy: 0.8265\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.5295 - accuracy: 0.7987 - val_loss: 0.4864 - val_accuracy: 0.8225\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.5275 - accuracy: 0.7955 - val_loss: 0.4915 - val_accuracy: 0.8210\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.5229 - accuracy: 0.7984 - val_loss: 0.4824 - val_accuracy: 0.8250\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.5241 - accuracy: 0.7994 - val_loss: 0.4846 - val_accuracy: 0.8230\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.5209 - accuracy: 0.8002 - val_loss: 0.4786 - val_accuracy: 0.8250\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.5142 - accuracy: 0.8052 - val_loss: 0.4763 - val_accuracy: 0.8245\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.5146 - accuracy: 0.8075 - val_loss: 0.4771 - val_accuracy: 0.8280\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.5116 - accuracy: 0.8030 - val_loss: 0.4743 - val_accuracy: 0.8295\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.5142 - accuracy: 0.8045 - val_loss: 0.4721 - val_accuracy: 0.8290\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.5120 - accuracy: 0.8058 - val_loss: 0.4704 - val_accuracy: 0.8280\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.5103 - accuracy: 0.8095 - val_loss: 0.4707 - val_accuracy: 0.8310\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.5072 - accuracy: 0.8071 - val_loss: 0.4727 - val_accuracy: 0.8315\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.5089 - accuracy: 0.8064 - val_loss: 0.4682 - val_accuracy: 0.8330\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.5035 - accuracy: 0.8131 - val_loss: 0.4670 - val_accuracy: 0.8330\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.4980 - accuracy: 0.8136 - val_loss: 0.4666 - val_accuracy: 0.8340\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.5014 - accuracy: 0.8131 - val_loss: 0.4695 - val_accuracy: 0.8370\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.4993 - accuracy: 0.8120 - val_loss: 0.4650 - val_accuracy: 0.8370\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.4903 - accuracy: 0.8189 - val_loss: 0.4628 - val_accuracy: 0.8355\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.4952 - accuracy: 0.8121 - val_loss: 0.4628 - val_accuracy: 0.8315\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.4901 - accuracy: 0.8185 - val_loss: 0.4629 - val_accuracy: 0.8360\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.4946 - accuracy: 0.8167 - val_loss: 0.4602 - val_accuracy: 0.8330\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.4947 - accuracy: 0.8156 - val_loss: 0.4624 - val_accuracy: 0.8350\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.4846 - accuracy: 0.8227 - val_loss: 0.4597 - val_accuracy: 0.8345\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.4875 - accuracy: 0.8155 - val_loss: 0.4574 - val_accuracy: 0.8330\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.4844 - accuracy: 0.8163 - val_loss: 0.4546 - val_accuracy: 0.8330\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.4830 - accuracy: 0.8201 - val_loss: 0.4594 - val_accuracy: 0.8330\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.4939 - accuracy: 0.8165 - val_loss: 0.4615 - val_accuracy: 0.8315\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.4797 - accuracy: 0.8202 - val_loss: 0.4535 - val_accuracy: 0.8395\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.4862 - accuracy: 0.8200 - val_loss: 0.4556 - val_accuracy: 0.8325\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.4852 - accuracy: 0.8194 - val_loss: 0.4571 - val_accuracy: 0.8370\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.4851 - accuracy: 0.8151 - val_loss: 0.4579 - val_accuracy: 0.8415\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.4799 - accuracy: 0.8223 - val_loss: 0.4564 - val_accuracy: 0.8360\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.4754 - accuracy: 0.8245 - val_loss: 0.4521 - val_accuracy: 0.8370\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.4774 - accuracy: 0.8215 - val_loss: 0.4501 - val_accuracy: 0.8380\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.4767 - accuracy: 0.8224 - val_loss: 0.4527 - val_accuracy: 0.8360\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.4721 - accuracy: 0.8253 - val_loss: 0.4517 - val_accuracy: 0.8390\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.4725 - accuracy: 0.8244 - val_loss: 0.4482 - val_accuracy: 0.8385\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.4717 - accuracy: 0.8217 - val_loss: 0.4513 - val_accuracy: 0.8365\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.4716 - accuracy: 0.8280 - val_loss: 0.4503 - val_accuracy: 0.8355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.4646 - accuracy: 0.8265 - val_loss: 0.4517 - val_accuracy: 0.8330\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.4728 - accuracy: 0.8244 - val_loss: 0.4510 - val_accuracy: 0.8335\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.4637 - accuracy: 0.8273 - val_loss: 0.4540 - val_accuracy: 0.8410\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.4690 - accuracy: 0.8280 - val_loss: 0.4497 - val_accuracy: 0.8430\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.4712 - accuracy: 0.8261 - val_loss: 0.4479 - val_accuracy: 0.8400\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.4654 - accuracy: 0.8254 - val_loss: 0.4484 - val_accuracy: 0.8420\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.4574 - accuracy: 0.8290 - val_loss: 0.4492 - val_accuracy: 0.8395\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.4628 - accuracy: 0.8289 - val_loss: 0.4471 - val_accuracy: 0.8410\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.4599 - accuracy: 0.8284 - val_loss: 0.4493 - val_accuracy: 0.8420\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.4571 - accuracy: 0.8301 - val_loss: 0.4465 - val_accuracy: 0.8355\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.4605 - accuracy: 0.8291 - val_loss: 0.4470 - val_accuracy: 0.8390\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.4617 - accuracy: 0.8286 - val_loss: 0.4487 - val_accuracy: 0.8400\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.4612 - accuracy: 0.8260 - val_loss: 0.4462 - val_accuracy: 0.8380\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.4567 - accuracy: 0.8295 - val_loss: 0.4522 - val_accuracy: 0.8360\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.4560 - accuracy: 0.8313 - val_loss: 0.4451 - val_accuracy: 0.8420\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.4474 - accuracy: 0.8317 - val_loss: 0.4429 - val_accuracy: 0.8390\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.4542 - accuracy: 0.8317 - val_loss: 0.4437 - val_accuracy: 0.8360\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.4518 - accuracy: 0.8372 - val_loss: 0.4454 - val_accuracy: 0.8405\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.4508 - accuracy: 0.8344 - val_loss: 0.4424 - val_accuracy: 0.8395\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.4529 - accuracy: 0.8313 - val_loss: 0.4502 - val_accuracy: 0.8335\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.4524 - accuracy: 0.8328 - val_loss: 0.4428 - val_accuracy: 0.8395\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.4487 - accuracy: 0.8305 - val_loss: 0.4435 - val_accuracy: 0.8380\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.4577 - accuracy: 0.8310 - val_loss: 0.4464 - val_accuracy: 0.8410\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.4462 - accuracy: 0.8335 - val_loss: 0.4422 - val_accuracy: 0.8365\n"
     ]
    }
   ],
   "source": [
    "As = np.linspace(50,500,10)\n",
    "res = []\n",
    "y_predicted_list = []\n",
    "y_list = []\n",
    "for A in As:\n",
    "    str0 = f\"ts_L60_Z12_A{A}_DX50_bias5_N10000\"\n",
    "    fnamex = \"DATA/x_\" + str0 + \".csv\"\n",
    "    fnamey = \"DATA/y_\" + str0 + \".csv\"\n",
    "\n",
    "    x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "    x_std =  scaler.fit_transform(x.T).T\n",
    "\n",
    "    categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "    \n",
    "    y = to_categorical(categ)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_std, y, test_size=0.2)\n",
    "    x_train = x_train.reshape(x_train.shape[0],L,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],L,1)\n",
    "    \n",
    "    model.load_weights(\"Original_Weights_CNN1.h5\")\n",
    "    \n",
    "    hist = model.fit(x_train, y_train, batch_size = 250, epochs = 150, \n",
    "                 validation_data = (x_test, y_test), \n",
    "                verbose = 2, shuffle = True)\n",
    "    res.append(pd.DataFrame(hist.history).iloc[:,-1])\n",
    "    y_list.append(np.argmax(y_test, axis = 1))\n",
    "    y_predicted_list.append(np.argmax(model.predict(x_test), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Better visualization of confusion matrices\n",
    "fig, ax1 = plt.subplots(nrows=3, ncols=3, figsize = (15, 8))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        c_matrix = confusion_matrix(y_list[3*i+j],y_predicted_list[3*i+j],  normalize = 'true')\n",
    "        ax1[i,j].matshow(c_matrix, cmap = plt.cm.YlGn, alpha = 0.5)\n",
    "        ax1[i,j].set_xticks(np.arange(3))\n",
    "        ax1[i,j].set_yticks(np.arange(3))\n",
    "        for l in range(3):\n",
    "            for m in range(3):\n",
    "                ax1[i,j].text(x=l, y=m, s=round(c_matrix[m, l],2), ha=\"center\", va=\"center\")\n",
    "        ax1[i,j].xaxis.set_ticks_position('bottom')\n",
    "        ax1[i,j].set_xlabel('predicted label')\n",
    "        ax1[i,j].set_ylabel('true label')\n",
    "        ax1[i,j].set_title(f\"AmplitudeToNoiseRatio: {As[3*i+j]/50} \")\n",
    "        fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"DATA/Results_Discrimination_new.csv\",np.asarray(res))\n",
    "np.savetxt(\"DATA/Results_YPredicted.csv_new\",np.asarray(y_predicted_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "Now we consider three different networks, using a single convolution layer, as suggested. Performances will be in general slightly worse with respect to the network trained with two convoultional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt(\"DATA/x_ts_comp_N10000.csv\", delimiter =\",\")\n",
    "categ_y = np.loadtxt(\"DATA/y_ts_comp_N10000.csv\", delimiter =\",\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x =  scaler.fit_transform(x.T).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(categ_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(x[0])\n",
    "input_shape = (len(x[0]),1)\n",
    "N_categ = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2)\n",
    "x_train = x_train.reshape(x_train.shape[0],L,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model. Conv(4 filters, kernel_size = 10); AvgPool; 2x Dense(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_19 (Conv1D)           (None, 51, 4)             44        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 597\n",
      "Trainable params: 597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "model = compile_model( fil = [4], k_size = [10], PoolSize = 5, dense = [10,10], learn_rate = 0.001, dout_rate = 0.2)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 15ms/step - loss: 1.1010 - accuracy: 0.3275 - val_loss: 1.0946 - val_accuracy: 0.3665\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0934 - accuracy: 0.3735 - val_loss: 1.0895 - val_accuracy: 0.3935\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0888 - accuracy: 0.3833 - val_loss: 1.0800 - val_accuracy: 0.4215\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0804 - accuracy: 0.3943 - val_loss: 1.0629 - val_accuracy: 0.4610\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0602 - accuracy: 0.4230 - val_loss: 1.0398 - val_accuracy: 0.4925\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0357 - accuracy: 0.4582 - val_loss: 1.0086 - val_accuracy: 0.5035\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0106 - accuracy: 0.4596 - val_loss: 0.9791 - val_accuracy: 0.5265\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9844 - accuracy: 0.4759 - val_loss: 0.9460 - val_accuracy: 0.5480\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9504 - accuracy: 0.5089 - val_loss: 0.9164 - val_accuracy: 0.5620\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9223 - accuracy: 0.5313 - val_loss: 0.8854 - val_accuracy: 0.5810\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8965 - accuracy: 0.5574 - val_loss: 0.8611 - val_accuracy: 0.5885\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8701 - accuracy: 0.5707 - val_loss: 0.8397 - val_accuracy: 0.6070\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8604 - accuracy: 0.5839 - val_loss: 0.8231 - val_accuracy: 0.6175\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8304 - accuracy: 0.5983 - val_loss: 0.8056 - val_accuracy: 0.6495\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8178 - accuracy: 0.6256 - val_loss: 0.7810 - val_accuracy: 0.6675\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8084 - accuracy: 0.6407 - val_loss: 0.7592 - val_accuracy: 0.6785\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7926 - accuracy: 0.6484 - val_loss: 0.7317 - val_accuracy: 0.6965\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7675 - accuracy: 0.6682 - val_loss: 0.7185 - val_accuracy: 0.7060\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7507 - accuracy: 0.6694 - val_loss: 0.7093 - val_accuracy: 0.7105\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7379 - accuracy: 0.6889 - val_loss: 0.6890 - val_accuracy: 0.7215\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7487 - accuracy: 0.6886 - val_loss: 0.6766 - val_accuracy: 0.7275\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7257 - accuracy: 0.6919 - val_loss: 0.6638 - val_accuracy: 0.7330\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7201 - accuracy: 0.6980 - val_loss: 0.6577 - val_accuracy: 0.7385\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7260 - accuracy: 0.6933 - val_loss: 0.6517 - val_accuracy: 0.7405\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6937 - accuracy: 0.7070 - val_loss: 0.6342 - val_accuracy: 0.7505\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.7171 - val_loss: 0.6290 - val_accuracy: 0.7435\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6869 - accuracy: 0.7208 - val_loss: 0.6185 - val_accuracy: 0.7560\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6748 - accuracy: 0.7245 - val_loss: 0.6128 - val_accuracy: 0.7570\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6679 - accuracy: 0.7296 - val_loss: 0.6080 - val_accuracy: 0.7570\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6681 - accuracy: 0.7272 - val_loss: 0.5942 - val_accuracy: 0.7640\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6453 - accuracy: 0.7367 - val_loss: 0.5890 - val_accuracy: 0.7680\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6481 - accuracy: 0.7446 - val_loss: 0.5830 - val_accuracy: 0.7670\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.7398 - val_loss: 0.5767 - val_accuracy: 0.7720\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6368 - accuracy: 0.7438 - val_loss: 0.5727 - val_accuracy: 0.7760\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.7350 - val_loss: 0.5699 - val_accuracy: 0.7785\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6181 - accuracy: 0.7573 - val_loss: 0.5638 - val_accuracy: 0.7840\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.7545 - val_loss: 0.5636 - val_accuracy: 0.7840\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6136 - accuracy: 0.7559 - val_loss: 0.5576 - val_accuracy: 0.7885\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6167 - accuracy: 0.7518 - val_loss: 0.5582 - val_accuracy: 0.7800\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.7641 - val_loss: 0.5529 - val_accuracy: 0.7860\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5967 - accuracy: 0.7654 - val_loss: 0.5525 - val_accuracy: 0.7825\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5946 - accuracy: 0.7686 - val_loss: 0.5490 - val_accuracy: 0.7835\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.7651 - val_loss: 0.5496 - val_accuracy: 0.7810\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.7655 - val_loss: 0.5471 - val_accuracy: 0.7850\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.7716 - val_loss: 0.5430 - val_accuracy: 0.7825\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.7611 - val_loss: 0.5446 - val_accuracy: 0.7865\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.7639 - val_loss: 0.5456 - val_accuracy: 0.7815\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.7785 - val_loss: 0.5392 - val_accuracy: 0.7870\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5846 - accuracy: 0.7660 - val_loss: 0.5371 - val_accuracy: 0.7860\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5827 - accuracy: 0.7723 - val_loss: 0.5365 - val_accuracy: 0.7895\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5993 - accuracy: 0.7665 - val_loss: 0.5371 - val_accuracy: 0.7870\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.7648 - val_loss: 0.5350 - val_accuracy: 0.7895\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.7757 - val_loss: 0.5346 - val_accuracy: 0.7890\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5779 - accuracy: 0.7745 - val_loss: 0.5396 - val_accuracy: 0.7840\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7813 - val_loss: 0.5315 - val_accuracy: 0.7860\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7807 - val_loss: 0.5319 - val_accuracy: 0.7920\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.7768 - val_loss: 0.5322 - val_accuracy: 0.7860\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5712 - accuracy: 0.7771 - val_loss: 0.5300 - val_accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5649 - accuracy: 0.7804 - val_loss: 0.5304 - val_accuracy: 0.7820\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7799 - val_loss: 0.5273 - val_accuracy: 0.7870\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5561 - accuracy: 0.7821 - val_loss: 0.5271 - val_accuracy: 0.7885\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5624 - accuracy: 0.7776 - val_loss: 0.5275 - val_accuracy: 0.7890\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5566 - accuracy: 0.7869 - val_loss: 0.5275 - val_accuracy: 0.7870\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5666 - accuracy: 0.7796 - val_loss: 0.5246 - val_accuracy: 0.7955\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5574 - accuracy: 0.7847 - val_loss: 0.5259 - val_accuracy: 0.7885\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5521 - accuracy: 0.7889 - val_loss: 0.5239 - val_accuracy: 0.7900\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5497 - accuracy: 0.7841 - val_loss: 0.5260 - val_accuracy: 0.7905\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5449 - accuracy: 0.7881 - val_loss: 0.5261 - val_accuracy: 0.7895\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5566 - accuracy: 0.7889 - val_loss: 0.5223 - val_accuracy: 0.7885\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5538 - accuracy: 0.7871 - val_loss: 0.5213 - val_accuracy: 0.7945\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5434 - accuracy: 0.7959 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5465 - accuracy: 0.7907 - val_loss: 0.5203 - val_accuracy: 0.7950\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5411 - accuracy: 0.7926 - val_loss: 0.5172 - val_accuracy: 0.7925\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5359 - accuracy: 0.7919 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5443 - accuracy: 0.7851 - val_loss: 0.5216 - val_accuracy: 0.7930\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5407 - accuracy: 0.7888 - val_loss: 0.5194 - val_accuracy: 0.7970\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5375 - accuracy: 0.7905 - val_loss: 0.5194 - val_accuracy: 0.7945\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7893 - val_loss: 0.5167 - val_accuracy: 0.7960\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.7965 - val_loss: 0.5152 - val_accuracy: 0.7910\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5273 - accuracy: 0.7962 - val_loss: 0.5151 - val_accuracy: 0.7925\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.7918 - val_loss: 0.5170 - val_accuracy: 0.7940\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.7872 - val_loss: 0.5193 - val_accuracy: 0.7970\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5521 - accuracy: 0.7864 - val_loss: 0.5164 - val_accuracy: 0.7940\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5323 - accuracy: 0.7910 - val_loss: 0.5152 - val_accuracy: 0.7915\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5350 - accuracy: 0.7924 - val_loss: 0.5127 - val_accuracy: 0.7960\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.7922 - val_loss: 0.5159 - val_accuracy: 0.7955\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.7979 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5441 - accuracy: 0.7901 - val_loss: 0.5143 - val_accuracy: 0.7960\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.7938 - val_loss: 0.5125 - val_accuracy: 0.7970\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.7980 - val_loss: 0.5115 - val_accuracy: 0.7945\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.7897 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7957 - val_loss: 0.5099 - val_accuracy: 0.7960\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.7961 - val_loss: 0.5102 - val_accuracy: 0.7950\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.7958 - val_loss: 0.5099 - val_accuracy: 0.7960\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5242 - accuracy: 0.7947 - val_loss: 0.5107 - val_accuracy: 0.7950\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.7977 - val_loss: 0.5110 - val_accuracy: 0.7955\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5399 - accuracy: 0.7973 - val_loss: 0.5086 - val_accuracy: 0.7980\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7972 - val_loss: 0.5090 - val_accuracy: 0.7970\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5272 - accuracy: 0.7979 - val_loss: 0.5063 - val_accuracy: 0.7985\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.8010 - val_loss: 0.5070 - val_accuracy: 0.7940\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7980 - val_loss: 0.5138 - val_accuracy: 0.7955\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.7948 - val_loss: 0.5059 - val_accuracy: 0.8015\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5250 - accuracy: 0.7977 - val_loss: 0.5050 - val_accuracy: 0.8010\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.7998 - val_loss: 0.5060 - val_accuracy: 0.7990\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.8004 - val_loss: 0.5099 - val_accuracy: 0.7950\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7988 - val_loss: 0.5057 - val_accuracy: 0.7980\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.8007 - val_loss: 0.5045 - val_accuracy: 0.8025\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5067 - accuracy: 0.8029 - val_loss: 0.5057 - val_accuracy: 0.7975\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.8024 - val_loss: 0.5052 - val_accuracy: 0.7990\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7987 - val_loss: 0.5068 - val_accuracy: 0.7940\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.8060 - val_loss: 0.5088 - val_accuracy: 0.8015\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5132 - accuracy: 0.8041 - val_loss: 0.5054 - val_accuracy: 0.8015\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5106 - accuracy: 0.8070 - val_loss: 0.5136 - val_accuracy: 0.7955\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7989 - val_loss: 0.5091 - val_accuracy: 0.7995\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.8012 - val_loss: 0.5036 - val_accuracy: 0.7985\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5252 - accuracy: 0.7989 - val_loss: 0.5068 - val_accuracy: 0.8005\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.8103 - val_loss: 0.5104 - val_accuracy: 0.8005\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7972 - val_loss: 0.5132 - val_accuracy: 0.7980\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.8115 - val_loss: 0.5038 - val_accuracy: 0.8010\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7988 - val_loss: 0.5062 - val_accuracy: 0.7975\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7935 - val_loss: 0.5051 - val_accuracy: 0.8055\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.7925 - val_loss: 0.5074 - val_accuracy: 0.7995\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5206 - accuracy: 0.8067 - val_loss: 0.5054 - val_accuracy: 0.7995\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.8044 - val_loss: 0.5049 - val_accuracy: 0.8000\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5089 - accuracy: 0.8074 - val_loss: 0.5060 - val_accuracy: 0.8025\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5072 - accuracy: 0.8087 - val_loss: 0.5077 - val_accuracy: 0.7945\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5206 - accuracy: 0.8010 - val_loss: 0.5050 - val_accuracy: 0.8005\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7987 - val_loss: 0.5112 - val_accuracy: 0.7960\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.8069 - val_loss: 0.5047 - val_accuracy: 0.7980\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.8007 - val_loss: 0.5049 - val_accuracy: 0.8025\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4970 - accuracy: 0.8098 - val_loss: 0.5051 - val_accuracy: 0.8005\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5064 - accuracy: 0.8047 - val_loss: 0.5054 - val_accuracy: 0.7980\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5071 - accuracy: 0.8090 - val_loss: 0.5047 - val_accuracy: 0.8015\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.8059 - val_loss: 0.5035 - val_accuracy: 0.7995\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.8053 - val_loss: 0.5042 - val_accuracy: 0.8030\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5088 - accuracy: 0.8080 - val_loss: 0.5061 - val_accuracy: 0.7980\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.8174 - val_loss: 0.5044 - val_accuracy: 0.8030\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5070 - accuracy: 0.8056 - val_loss: 0.5048 - val_accuracy: 0.8010\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.8101 - val_loss: 0.5100 - val_accuracy: 0.7995\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.8098 - val_loss: 0.5051 - val_accuracy: 0.7990\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.8112 - val_loss: 0.5056 - val_accuracy: 0.8040\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.8126 - val_loss: 0.5072 - val_accuracy: 0.7955\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.8081 - val_loss: 0.5040 - val_accuracy: 0.8015\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5132 - accuracy: 0.8046 - val_loss: 0.5115 - val_accuracy: 0.8000\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5181 - accuracy: 0.8060 - val_loss: 0.5034 - val_accuracy: 0.8025\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.8098 - val_loss: 0.5029 - val_accuracy: 0.8060\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.8158 - val_loss: 0.5058 - val_accuracy: 0.8035\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5068 - accuracy: 0.8103 - val_loss: 0.5044 - val_accuracy: 0.8055\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5025 - accuracy: 0.8080 - val_loss: 0.5088 - val_accuracy: 0.7965\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5090 - accuracy: 0.8095 - val_loss: 0.5043 - val_accuracy: 0.8065\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.8069 - val_loss: 0.5072 - val_accuracy: 0.8060\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.8109 - val_loss: 0.5048 - val_accuracy: 0.8040\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.8188 - val_loss: 0.5056 - val_accuracy: 0.8010\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.8154 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.8168 - val_loss: 0.5032 - val_accuracy: 0.8075\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.8142 - val_loss: 0.5032 - val_accuracy: 0.8060\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.8170 - val_loss: 0.5026 - val_accuracy: 0.8070\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5132 - accuracy: 0.8080 - val_loss: 0.5062 - val_accuracy: 0.8000\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.8140 - val_loss: 0.5036 - val_accuracy: 0.8045\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5008 - accuracy: 0.8068 - val_loss: 0.5033 - val_accuracy: 0.8050\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.8083 - val_loss: 0.5023 - val_accuracy: 0.8070\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4943 - accuracy: 0.8092 - val_loss: 0.5023 - val_accuracy: 0.8045\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.8104 - val_loss: 0.5034 - val_accuracy: 0.7985\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.8154 - val_loss: 0.5054 - val_accuracy: 0.8070\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.8120 - val_loss: 0.5013 - val_accuracy: 0.8030\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.8150 - val_loss: 0.5053 - val_accuracy: 0.8060\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.8058 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4819 - accuracy: 0.8205 - val_loss: 0.5018 - val_accuracy: 0.8035\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.8110 - val_loss: 0.5015 - val_accuracy: 0.8020\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.8138 - val_loss: 0.5028 - val_accuracy: 0.8030\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4958 - accuracy: 0.8156 - val_loss: 0.5027 - val_accuracy: 0.8020\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.8131 - val_loss: 0.5000 - val_accuracy: 0.8050\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.8153 - val_loss: 0.5049 - val_accuracy: 0.8070\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.8043 - val_loss: 0.5017 - val_accuracy: 0.8045\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.8098 - val_loss: 0.5038 - val_accuracy: 0.8015\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.8105 - val_loss: 0.5004 - val_accuracy: 0.8050\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.8107 - val_loss: 0.5015 - val_accuracy: 0.8020\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4983 - accuracy: 0.8139 - val_loss: 0.5002 - val_accuracy: 0.8055\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4864 - accuracy: 0.8186 - val_loss: 0.5001 - val_accuracy: 0.8020\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4973 - accuracy: 0.8097 - val_loss: 0.5008 - val_accuracy: 0.8030\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.8220 - val_loss: 0.5006 - val_accuracy: 0.8040\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.8213 - val_loss: 0.5000 - val_accuracy: 0.8095\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4854 - accuracy: 0.8194 - val_loss: 0.4995 - val_accuracy: 0.8035\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5223 - accuracy: 0.7954 - val_loss: 0.4995 - val_accuracy: 0.8055\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.4991 - accuracy: 0.8157 - val_loss: 0.5011 - val_accuracy: 0.8045\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.4935 - accuracy: 0.8075 - val_loss: 0.5005 - val_accuracy: 0.8045\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.8135 - val_loss: 0.4982 - val_accuracy: 0.8005\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4876 - accuracy: 0.8161 - val_loss: 0.5009 - val_accuracy: 0.8070\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4947 - accuracy: 0.8174 - val_loss: 0.5019 - val_accuracy: 0.8090\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4973 - accuracy: 0.8080 - val_loss: 0.5038 - val_accuracy: 0.8055\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4928 - accuracy: 0.8202 - val_loss: 0.4984 - val_accuracy: 0.8055\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4970 - accuracy: 0.8136 - val_loss: 0.5012 - val_accuracy: 0.8070\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4945 - accuracy: 0.8164 - val_loss: 0.5018 - val_accuracy: 0.7970\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.8082 - val_loss: 0.4985 - val_accuracy: 0.8065\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.8109 - val_loss: 0.5011 - val_accuracy: 0.8050\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.8098 - val_loss: 0.4972 - val_accuracy: 0.8030\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.8169 - val_loss: 0.4998 - val_accuracy: 0.8055\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.4977 - accuracy: 0.8100 - val_loss: 0.5013 - val_accuracy: 0.8005\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.8121 - val_loss: 0.4980 - val_accuracy: 0.8085\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.8237 - val_loss: 0.4992 - val_accuracy: 0.8055\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4866 - accuracy: 0.8134 - val_loss: 0.4984 - val_accuracy: 0.8055\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5012 - accuracy: 0.8114 - val_loss: 0.4991 - val_accuracy: 0.8045\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5071 - accuracy: 0.8154 - val_loss: 0.5013 - val_accuracy: 0.8065\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5013 - accuracy: 0.8107 - val_loss: 0.5004 - val_accuracy: 0.8040\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4928 - accuracy: 0.8101 - val_loss: 0.4991 - val_accuracy: 0.8045\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.8155 - val_loss: 0.5031 - val_accuracy: 0.8025\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4795 - accuracy: 0.8187 - val_loss: 0.4995 - val_accuracy: 0.8050\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5014 - accuracy: 0.8113 - val_loss: 0.5015 - val_accuracy: 0.8065\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.8133 - val_loss: 0.5011 - val_accuracy: 0.8035\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4849 - accuracy: 0.8207 - val_loss: 0.4992 - val_accuracy: 0.8055\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.8104 - val_loss: 0.4991 - val_accuracy: 0.8075\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.8146 - val_loss: 0.5024 - val_accuracy: 0.8020\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4911 - accuracy: 0.8119 - val_loss: 0.5021 - val_accuracy: 0.8010\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.8134 - val_loss: 0.5024 - val_accuracy: 0.8070\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.8187 - val_loss: 0.5008 - val_accuracy: 0.8040\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4967 - accuracy: 0.8162 - val_loss: 0.5002 - val_accuracy: 0.8065\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.8190 - val_loss: 0.5016 - val_accuracy: 0.8050\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4872 - accuracy: 0.8145 - val_loss: 0.5025 - val_accuracy: 0.8050\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4839 - accuracy: 0.8174 - val_loss: 0.5009 - val_accuracy: 0.8050\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.8212 - val_loss: 0.5001 - val_accuracy: 0.8060\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4816 - accuracy: 0.8193 - val_loss: 0.4993 - val_accuracy: 0.8025\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.8118 - val_loss: 0.4983 - val_accuracy: 0.8075\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.8228 - val_loss: 0.5001 - val_accuracy: 0.8005\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.8163 - val_loss: 0.5010 - val_accuracy: 0.8045\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4781 - accuracy: 0.8205 - val_loss: 0.5005 - val_accuracy: 0.8040\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.8170 - val_loss: 0.4991 - val_accuracy: 0.8045\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4830 - accuracy: 0.8162 - val_loss: 0.5004 - val_accuracy: 0.8035\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.8163 - val_loss: 0.5020 - val_accuracy: 0.8050\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.8226 - val_loss: 0.5004 - val_accuracy: 0.7965\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.8181 - val_loss: 0.5008 - val_accuracy: 0.8035\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4854 - accuracy: 0.8173 - val_loss: 0.4975 - val_accuracy: 0.8055\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.81 - 0s 9ms/step - loss: 0.4933 - accuracy: 0.8182 - val_loss: 0.5018 - val_accuracy: 0.8080\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.8219 - val_loss: 0.4996 - val_accuracy: 0.8065\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.8160 - val_loss: 0.4990 - val_accuracy: 0.8070\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4819 - accuracy: 0.8156 - val_loss: 0.5011 - val_accuracy: 0.8050\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.8185 - val_loss: 0.4988 - val_accuracy: 0.8030\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.8291 - val_loss: 0.4991 - val_accuracy: 0.8070\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4753 - accuracy: 0.8268 - val_loss: 0.5027 - val_accuracy: 0.8040\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.8252 - val_loss: 0.5009 - val_accuracy: 0.8060\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4825 - accuracy: 0.8247 - val_loss: 0.4985 - val_accuracy: 0.8045\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.8202 - val_loss: 0.4997 - val_accuracy: 0.7980\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4785 - accuracy: 0.8143 - val_loss: 0.4986 - val_accuracy: 0.8050\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4785 - accuracy: 0.8262 - val_loss: 0.4958 - val_accuracy: 0.8015\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4655 - accuracy: 0.8291 - val_loss: 0.4991 - val_accuracy: 0.8055\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4733 - accuracy: 0.8194 - val_loss: 0.4988 - val_accuracy: 0.8020\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4823 - accuracy: 0.8182 - val_loss: 0.5002 - val_accuracy: 0.8035\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4732 - accuracy: 0.8256 - val_loss: 0.5006 - val_accuracy: 0.8035\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.8217 - val_loss: 0.4975 - val_accuracy: 0.8020\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4764 - accuracy: 0.8244 - val_loss: 0.4997 - val_accuracy: 0.8050\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.8222 - val_loss: 0.4976 - val_accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $2^{nd}$ Model. Conv(3 filters, kernel_size = 5); AvgPool; Dense(12); Dropout(0.2); Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 56, 3)             18        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 11, 3)             0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 12)                408       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "model = compile_model( fil = [3], k_size = [5], PoolSize = 5, dense = [12], learn_rate = 0.001, dout_rate = 0.2)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 14ms/step - loss: 1.0977 - accuracy: 0.3479 - val_loss: 1.0892 - val_accuracy: 0.3965\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0870 - accuracy: 0.3962 - val_loss: 1.0729 - val_accuracy: 0.4430\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0712 - accuracy: 0.4189 - val_loss: 1.0484 - val_accuracy: 0.4790\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0497 - accuracy: 0.4521 - val_loss: 1.0206 - val_accuracy: 0.5100\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0303 - accuracy: 0.4741 - val_loss: 0.9967 - val_accuracy: 0.5215\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0095 - accuracy: 0.4869 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9913 - accuracy: 0.5094 - val_loss: 0.9567 - val_accuracy: 0.5595\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9755 - accuracy: 0.5137 - val_loss: 0.9405 - val_accuracy: 0.5685\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9559 - accuracy: 0.5313 - val_loss: 0.9263 - val_accuracy: 0.5745\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9502 - accuracy: 0.5352 - val_loss: 0.9166 - val_accuracy: 0.5875\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9392 - accuracy: 0.5394 - val_loss: 0.9010 - val_accuracy: 0.5910\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9195 - accuracy: 0.5582 - val_loss: 0.8906 - val_accuracy: 0.5985\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9095 - accuracy: 0.5658 - val_loss: 0.8802 - val_accuracy: 0.6060\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9015 - accuracy: 0.5744 - val_loss: 0.8729 - val_accuracy: 0.6075\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8887 - accuracy: 0.5852 - val_loss: 0.8648 - val_accuracy: 0.6175\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8960 - accuracy: 0.5756 - val_loss: 0.8562 - val_accuracy: 0.6205\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8790 - accuracy: 0.5872 - val_loss: 0.8495 - val_accuracy: 0.6225\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8777 - accuracy: 0.5876 - val_loss: 0.8456 - val_accuracy: 0.6235\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8732 - accuracy: 0.5814 - val_loss: 0.8421 - val_accuracy: 0.6310\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8570 - accuracy: 0.6048 - val_loss: 0.8353 - val_accuracy: 0.6275\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8591 - accuracy: 0.6036 - val_loss: 0.8316 - val_accuracy: 0.6260\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8560 - accuracy: 0.5932 - val_loss: 0.8273 - val_accuracy: 0.6330\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8540 - accuracy: 0.6010 - val_loss: 0.8237 - val_accuracy: 0.6375\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8498 - accuracy: 0.6032 - val_loss: 0.8209 - val_accuracy: 0.6380\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8353 - accuracy: 0.6199 - val_loss: 0.8173 - val_accuracy: 0.6375\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8465 - accuracy: 0.6065 - val_loss: 0.8129 - val_accuracy: 0.6360\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8332 - accuracy: 0.6157 - val_loss: 0.8120 - val_accuracy: 0.6380\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8503 - accuracy: 0.6030 - val_loss: 0.8087 - val_accuracy: 0.6345\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8372 - accuracy: 0.6191 - val_loss: 0.8072 - val_accuracy: 0.6450\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8326 - accuracy: 0.6220 - val_loss: 0.8038 - val_accuracy: 0.6395\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8334 - accuracy: 0.6043 - val_loss: 0.8012 - val_accuracy: 0.6435\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8308 - accuracy: 0.6180 - val_loss: 0.7994 - val_accuracy: 0.6470\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8264 - accuracy: 0.6220 - val_loss: 0.8003 - val_accuracy: 0.6470\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8282 - accuracy: 0.6203 - val_loss: 0.7956 - val_accuracy: 0.6455\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8238 - accuracy: 0.6222 - val_loss: 0.7932 - val_accuracy: 0.6550\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8266 - accuracy: 0.6162 - val_loss: 0.7959 - val_accuracy: 0.6410\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8237 - accuracy: 0.6136 - val_loss: 0.7913 - val_accuracy: 0.6535\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8096 - accuracy: 0.6234 - val_loss: 0.7900 - val_accuracy: 0.6545\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8099 - accuracy: 0.6274 - val_loss: 0.7922 - val_accuracy: 0.6495\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8262 - accuracy: 0.6205 - val_loss: 0.7871 - val_accuracy: 0.6530\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8288 - accuracy: 0.6126 - val_loss: 0.7863 - val_accuracy: 0.6535\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8146 - accuracy: 0.6211 - val_loss: 0.7893 - val_accuracy: 0.6425\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8159 - accuracy: 0.6257 - val_loss: 0.7848 - val_accuracy: 0.6535\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8159 - accuracy: 0.6287 - val_loss: 0.7851 - val_accuracy: 0.6595\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8050 - accuracy: 0.6414 - val_loss: 0.7854 - val_accuracy: 0.6575\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8136 - accuracy: 0.6297 - val_loss: 0.7831 - val_accuracy: 0.6575\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8127 - accuracy: 0.6325 - val_loss: 0.7820 - val_accuracy: 0.6535\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8164 - accuracy: 0.6326 - val_loss: 0.7791 - val_accuracy: 0.6590\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8101 - accuracy: 0.6242 - val_loss: 0.7801 - val_accuracy: 0.6575\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8055 - accuracy: 0.6388 - val_loss: 0.7778 - val_accuracy: 0.6570\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8087 - accuracy: 0.6290 - val_loss: 0.7775 - val_accuracy: 0.6610\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8017 - accuracy: 0.6369 - val_loss: 0.7775 - val_accuracy: 0.6625\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8113 - accuracy: 0.6297 - val_loss: 0.7757 - val_accuracy: 0.6610\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8065 - accuracy: 0.6297 - val_loss: 0.7746 - val_accuracy: 0.6625\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8018 - accuracy: 0.6348 - val_loss: 0.7741 - val_accuracy: 0.6605\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8041 - accuracy: 0.6284 - val_loss: 0.7749 - val_accuracy: 0.6635\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7968 - accuracy: 0.6396 - val_loss: 0.7723 - val_accuracy: 0.6645\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8040 - accuracy: 0.6311 - val_loss: 0.7718 - val_accuracy: 0.6655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8127 - accuracy: 0.6303 - val_loss: 0.7726 - val_accuracy: 0.6665\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8172 - accuracy: 0.6259 - val_loss: 0.7727 - val_accuracy: 0.6635\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7945 - accuracy: 0.6345 - val_loss: 0.7754 - val_accuracy: 0.6570\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8138 - accuracy: 0.6248 - val_loss: 0.7693 - val_accuracy: 0.6655\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8019 - accuracy: 0.6292 - val_loss: 0.7722 - val_accuracy: 0.6630\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8008 - accuracy: 0.6338 - val_loss: 0.7700 - val_accuracy: 0.6720\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8074 - accuracy: 0.6231 - val_loss: 0.7701 - val_accuracy: 0.6665\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8099 - accuracy: 0.6247 - val_loss: 0.7669 - val_accuracy: 0.6670\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7898 - accuracy: 0.6342 - val_loss: 0.7679 - val_accuracy: 0.6640\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7856 - accuracy: 0.6426 - val_loss: 0.7668 - val_accuracy: 0.6650\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7953 - accuracy: 0.6357 - val_loss: 0.7699 - val_accuracy: 0.6605\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7870 - accuracy: 0.6443 - val_loss: 0.7652 - val_accuracy: 0.6640\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8076 - accuracy: 0.6279 - val_loss: 0.7643 - val_accuracy: 0.6670\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8040 - accuracy: 0.6288 - val_loss: 0.7644 - val_accuracy: 0.6675\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7871 - accuracy: 0.6454 - val_loss: 0.7636 - val_accuracy: 0.6685\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7889 - accuracy: 0.6434 - val_loss: 0.7643 - val_accuracy: 0.6710\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7924 - accuracy: 0.6409 - val_loss: 0.7638 - val_accuracy: 0.6675\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7908 - accuracy: 0.6379 - val_loss: 0.7611 - val_accuracy: 0.6680\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7782 - accuracy: 0.6439 - val_loss: 0.7638 - val_accuracy: 0.6645\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7861 - accuracy: 0.6421 - val_loss: 0.7620 - val_accuracy: 0.6690\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7768 - accuracy: 0.6446 - val_loss: 0.7612 - val_accuracy: 0.6690\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7862 - accuracy: 0.6405 - val_loss: 0.7602 - val_accuracy: 0.6715\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8083 - accuracy: 0.6352 - val_loss: 0.7626 - val_accuracy: 0.6610\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7916 - accuracy: 0.6397 - val_loss: 0.7589 - val_accuracy: 0.6740\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8000 - accuracy: 0.6343 - val_loss: 0.7565 - val_accuracy: 0.6700\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7748 - accuracy: 0.6504 - val_loss: 0.7606 - val_accuracy: 0.6660\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7686 - accuracy: 0.6563 - val_loss: 0.7561 - val_accuracy: 0.6690\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7786 - accuracy: 0.6484 - val_loss: 0.7594 - val_accuracy: 0.6650\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7922 - accuracy: 0.6396 - val_loss: 0.7608 - val_accuracy: 0.6655\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7838 - accuracy: 0.6432 - val_loss: 0.7582 - val_accuracy: 0.6705\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7911 - accuracy: 0.6350 - val_loss: 0.7578 - val_accuracy: 0.6725\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7769 - accuracy: 0.6531 - val_loss: 0.7568 - val_accuracy: 0.6735\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7873 - accuracy: 0.6426 - val_loss: 0.7552 - val_accuracy: 0.6720\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7888 - accuracy: 0.6391 - val_loss: 0.7549 - val_accuracy: 0.6710\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7827 - accuracy: 0.6398 - val_loss: 0.7576 - val_accuracy: 0.6690\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7819 - accuracy: 0.6385 - val_loss: 0.7567 - val_accuracy: 0.6695\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7884 - accuracy: 0.6396 - val_loss: 0.7560 - val_accuracy: 0.6740\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7752 - accuracy: 0.6590 - val_loss: 0.7525 - val_accuracy: 0.6725\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7959 - accuracy: 0.6395 - val_loss: 0.7559 - val_accuracy: 0.6710\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7810 - accuracy: 0.6423 - val_loss: 0.7554 - val_accuracy: 0.6705\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7613 - accuracy: 0.6523 - val_loss: 0.7564 - val_accuracy: 0.6700\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7810 - accuracy: 0.6385 - val_loss: 0.7514 - val_accuracy: 0.6730\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7816 - accuracy: 0.6422 - val_loss: 0.7499 - val_accuracy: 0.6740\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7887 - accuracy: 0.6391 - val_loss: 0.7510 - val_accuracy: 0.6735\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7721 - accuracy: 0.6464 - val_loss: 0.7500 - val_accuracy: 0.6715\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7860 - accuracy: 0.6413 - val_loss: 0.7512 - val_accuracy: 0.6760\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7776 - accuracy: 0.6414 - val_loss: 0.7501 - val_accuracy: 0.6735\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7663 - accuracy: 0.6599 - val_loss: 0.7502 - val_accuracy: 0.6730\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7843 - accuracy: 0.6421 - val_loss: 0.7508 - val_accuracy: 0.6720\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7806 - accuracy: 0.6477 - val_loss: 0.7491 - val_accuracy: 0.6750\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7792 - accuracy: 0.6508 - val_loss: 0.7515 - val_accuracy: 0.6665\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7785 - accuracy: 0.6473 - val_loss: 0.7488 - val_accuracy: 0.6725\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7828 - accuracy: 0.6455 - val_loss: 0.7469 - val_accuracy: 0.6735\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7848 - accuracy: 0.6461 - val_loss: 0.7469 - val_accuracy: 0.6770\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7659 - accuracy: 0.6593 - val_loss: 0.7552 - val_accuracy: 0.6640\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7862 - accuracy: 0.6402 - val_loss: 0.7515 - val_accuracy: 0.6760\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7805 - accuracy: 0.6460 - val_loss: 0.7450 - val_accuracy: 0.6765\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7753 - accuracy: 0.6534 - val_loss: 0.7479 - val_accuracy: 0.6790\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7582 - accuracy: 0.6611 - val_loss: 0.7448 - val_accuracy: 0.6755\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7694 - accuracy: 0.6528 - val_loss: 0.7438 - val_accuracy: 0.6755\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7695 - accuracy: 0.6580 - val_loss: 0.7420 - val_accuracy: 0.6780\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7711 - accuracy: 0.6458 - val_loss: 0.7419 - val_accuracy: 0.6755\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7686 - accuracy: 0.6497 - val_loss: 0.7419 - val_accuracy: 0.6800\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7634 - accuracy: 0.6582 - val_loss: 0.7433 - val_accuracy: 0.6730\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7593 - accuracy: 0.6642 - val_loss: 0.7431 - val_accuracy: 0.6735\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7717 - accuracy: 0.6452 - val_loss: 0.7419 - val_accuracy: 0.6770\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7731 - accuracy: 0.6503 - val_loss: 0.7416 - val_accuracy: 0.6760\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7734 - accuracy: 0.6479 - val_loss: 0.7429 - val_accuracy: 0.6720\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7547 - accuracy: 0.6635 - val_loss: 0.7449 - val_accuracy: 0.6765\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7513 - accuracy: 0.6634 - val_loss: 0.7416 - val_accuracy: 0.6720\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7736 - accuracy: 0.6478 - val_loss: 0.7393 - val_accuracy: 0.6760\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7645 - accuracy: 0.6482 - val_loss: 0.7400 - val_accuracy: 0.6760\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7683 - accuracy: 0.6542 - val_loss: 0.7386 - val_accuracy: 0.6765\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7898 - accuracy: 0.6355 - val_loss: 0.7414 - val_accuracy: 0.6785\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7579 - accuracy: 0.6620 - val_loss: 0.7409 - val_accuracy: 0.6815\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7726 - accuracy: 0.6450 - val_loss: 0.7379 - val_accuracy: 0.6785\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7621 - accuracy: 0.6553 - val_loss: 0.7380 - val_accuracy: 0.6790\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7671 - accuracy: 0.6529 - val_loss: 0.7371 - val_accuracy: 0.6750\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7495 - accuracy: 0.6606 - val_loss: 0.7380 - val_accuracy: 0.6780\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7532 - accuracy: 0.6560 - val_loss: 0.7378 - val_accuracy: 0.6755\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7578 - accuracy: 0.6534 - val_loss: 0.7392 - val_accuracy: 0.6790\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7690 - accuracy: 0.6505 - val_loss: 0.7362 - val_accuracy: 0.6775\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7772 - accuracy: 0.6449 - val_loss: 0.7354 - val_accuracy: 0.6780\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7503 - accuracy: 0.6683 - val_loss: 0.7344 - val_accuracy: 0.6765\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7495 - accuracy: 0.6644 - val_loss: 0.7393 - val_accuracy: 0.6785\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7658 - accuracy: 0.6505 - val_loss: 0.7351 - val_accuracy: 0.6785\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7655 - accuracy: 0.6523 - val_loss: 0.7352 - val_accuracy: 0.6765\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.7655 - accuracy: 0.6564 - val_loss: 0.7342 - val_accuracy: 0.6725\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7649 - accuracy: 0.6649 - val_loss: 0.7341 - val_accuracy: 0.6835\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7508 - accuracy: 0.6612 - val_loss: 0.7330 - val_accuracy: 0.6845\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7537 - accuracy: 0.6633 - val_loss: 0.7395 - val_accuracy: 0.6705\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7585 - accuracy: 0.6575 - val_loss: 0.7340 - val_accuracy: 0.6815\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7548 - accuracy: 0.6634 - val_loss: 0.7338 - val_accuracy: 0.6765\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7555 - accuracy: 0.6557 - val_loss: 0.7311 - val_accuracy: 0.6860\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7451 - accuracy: 0.6690 - val_loss: 0.7315 - val_accuracy: 0.6790\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7589 - accuracy: 0.6603 - val_loss: 0.7302 - val_accuracy: 0.6810\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7709 - accuracy: 0.6558 - val_loss: 0.7303 - val_accuracy: 0.6855\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7408 - accuracy: 0.6776 - val_loss: 0.7300 - val_accuracy: 0.6870\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.65 - 0s 9ms/step - loss: 0.7665 - accuracy: 0.6539 - val_loss: 0.7301 - val_accuracy: 0.6840\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7574 - accuracy: 0.6577 - val_loss: 0.7275 - val_accuracy: 0.6820\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7713 - accuracy: 0.6572 - val_loss: 0.7280 - val_accuracy: 0.6845\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7574 - accuracy: 0.6579 - val_loss: 0.7276 - val_accuracy: 0.6865\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7569 - accuracy: 0.6658 - val_loss: 0.7263 - val_accuracy: 0.6845\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7577 - accuracy: 0.6540 - val_loss: 0.7271 - val_accuracy: 0.6815\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7430 - accuracy: 0.6735 - val_loss: 0.7291 - val_accuracy: 0.6890\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7399 - accuracy: 0.6726 - val_loss: 0.7305 - val_accuracy: 0.6770\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7537 - accuracy: 0.6579 - val_loss: 0.7293 - val_accuracy: 0.6835\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7572 - accuracy: 0.6711 - val_loss: 0.7262 - val_accuracy: 0.6860\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7437 - accuracy: 0.6798 - val_loss: 0.7253 - val_accuracy: 0.6870\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7538 - accuracy: 0.6594 - val_loss: 0.7237 - val_accuracy: 0.6895\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7563 - accuracy: 0.6689 - val_loss: 0.7248 - val_accuracy: 0.6925\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7539 - accuracy: 0.6655 - val_loss: 0.7222 - val_accuracy: 0.6890\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7481 - accuracy: 0.6658 - val_loss: 0.7229 - val_accuracy: 0.6870\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7433 - accuracy: 0.6672 - val_loss: 0.7228 - val_accuracy: 0.6855\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7473 - accuracy: 0.6772 - val_loss: 0.7262 - val_accuracy: 0.6800\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7356 - accuracy: 0.6717 - val_loss: 0.7246 - val_accuracy: 0.6885\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7458 - accuracy: 0.6687 - val_loss: 0.7235 - val_accuracy: 0.6865\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7406 - accuracy: 0.6717 - val_loss: 0.7283 - val_accuracy: 0.6825\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7502 - accuracy: 0.6739 - val_loss: 0.7225 - val_accuracy: 0.6865\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7528 - accuracy: 0.6691 - val_loss: 0.7294 - val_accuracy: 0.6835\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7538 - accuracy: 0.6623 - val_loss: 0.7209 - val_accuracy: 0.6870\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7541 - accuracy: 0.6627 - val_loss: 0.7199 - val_accuracy: 0.6885\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7532 - accuracy: 0.6692 - val_loss: 0.7234 - val_accuracy: 0.6900\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7455 - accuracy: 0.6705 - val_loss: 0.7235 - val_accuracy: 0.6895\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7521 - accuracy: 0.6715 - val_loss: 0.7227 - val_accuracy: 0.6865\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7483 - accuracy: 0.6654 - val_loss: 0.7180 - val_accuracy: 0.6885\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7554 - accuracy: 0.6645 - val_loss: 0.7220 - val_accuracy: 0.6880\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7483 - accuracy: 0.6636 - val_loss: 0.7181 - val_accuracy: 0.6905\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7493 - accuracy: 0.6594 - val_loss: 0.7199 - val_accuracy: 0.6880\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7394 - accuracy: 0.6725 - val_loss: 0.7186 - val_accuracy: 0.6910\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7429 - accuracy: 0.6718 - val_loss: 0.7291 - val_accuracy: 0.6860\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7531 - accuracy: 0.6644 - val_loss: 0.7170 - val_accuracy: 0.6855\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7328 - accuracy: 0.6780 - val_loss: 0.7186 - val_accuracy: 0.6945\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.6676 - val_loss: 0.7174 - val_accuracy: 0.6860\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.7541 - accuracy: 0.6650 - val_loss: 0.7175 - val_accuracy: 0.6905\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7480 - accuracy: 0.6639 - val_loss: 0.7208 - val_accuracy: 0.6910\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7456 - accuracy: 0.6694 - val_loss: 0.7165 - val_accuracy: 0.6910\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7410 - accuracy: 0.6765 - val_loss: 0.7176 - val_accuracy: 0.6845\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7516 - accuracy: 0.6587 - val_loss: 0.7159 - val_accuracy: 0.6880\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7584 - accuracy: 0.6752 - val_loss: 0.7163 - val_accuracy: 0.6905\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7475 - accuracy: 0.6712 - val_loss: 0.7150 - val_accuracy: 0.6870\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7608 - accuracy: 0.6670 - val_loss: 0.7148 - val_accuracy: 0.6885\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7432 - accuracy: 0.6726 - val_loss: 0.7148 - val_accuracy: 0.6905\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7397 - accuracy: 0.6766 - val_loss: 0.7141 - val_accuracy: 0.6895\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7428 - accuracy: 0.6805 - val_loss: 0.7150 - val_accuracy: 0.6925\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7287 - accuracy: 0.6802 - val_loss: 0.7163 - val_accuracy: 0.6890\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7284 - accuracy: 0.6827 - val_loss: 0.7179 - val_accuracy: 0.6885\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7366 - accuracy: 0.6771 - val_loss: 0.7140 - val_accuracy: 0.6950\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7385 - accuracy: 0.6824 - val_loss: 0.7139 - val_accuracy: 0.6885\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7367 - accuracy: 0.6713 - val_loss: 0.7119 - val_accuracy: 0.6905\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7472 - accuracy: 0.6685 - val_loss: 0.7130 - val_accuracy: 0.6890\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7256 - accuracy: 0.6871 - val_loss: 0.7112 - val_accuracy: 0.6900\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7320 - accuracy: 0.6791 - val_loss: 0.7153 - val_accuracy: 0.6920\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7273 - accuracy: 0.6919 - val_loss: 0.7173 - val_accuracy: 0.6870\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7327 - accuracy: 0.6838 - val_loss: 0.7103 - val_accuracy: 0.6920\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7306 - accuracy: 0.6821 - val_loss: 0.7129 - val_accuracy: 0.6935\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7294 - accuracy: 0.6771 - val_loss: 0.7099 - val_accuracy: 0.6925\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7335 - accuracy: 0.6781 - val_loss: 0.7096 - val_accuracy: 0.6915\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7348 - accuracy: 0.6755 - val_loss: 0.7105 - val_accuracy: 0.6935\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7363 - accuracy: 0.6783 - val_loss: 0.7087 - val_accuracy: 0.6890\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7337 - accuracy: 0.6831 - val_loss: 0.7076 - val_accuracy: 0.6940\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7160 - accuracy: 0.6911 - val_loss: 0.7106 - val_accuracy: 0.6925\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7306 - accuracy: 0.6765 - val_loss: 0.7123 - val_accuracy: 0.6940\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7185 - accuracy: 0.6848 - val_loss: 0.7076 - val_accuracy: 0.6930\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7209 - accuracy: 0.6884 - val_loss: 0.7088 - val_accuracy: 0.6975\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7299 - accuracy: 0.6821 - val_loss: 0.7079 - val_accuracy: 0.6940\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7273 - accuracy: 0.6778 - val_loss: 0.7076 - val_accuracy: 0.6945\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7338 - accuracy: 0.6810 - val_loss: 0.7063 - val_accuracy: 0.6920\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7297 - accuracy: 0.6793 - val_loss: 0.7065 - val_accuracy: 0.6965\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7306 - accuracy: 0.6818 - val_loss: 0.7049 - val_accuracy: 0.6975\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7387 - accuracy: 0.6796 - val_loss: 0.7057 - val_accuracy: 0.6945\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7227 - accuracy: 0.6873 - val_loss: 0.7058 - val_accuracy: 0.6945\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7362 - accuracy: 0.6778 - val_loss: 0.7048 - val_accuracy: 0.6935\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7234 - accuracy: 0.6816 - val_loss: 0.7115 - val_accuracy: 0.6940\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7240 - accuracy: 0.6832 - val_loss: 0.7050 - val_accuracy: 0.6960\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7169 - accuracy: 0.6927 - val_loss: 0.7050 - val_accuracy: 0.6975\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7297 - accuracy: 0.6885 - val_loss: 0.7019 - val_accuracy: 0.6965\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7268 - accuracy: 0.6892 - val_loss: 0.7019 - val_accuracy: 0.6985\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7196 - accuracy: 0.6852 - val_loss: 0.7039 - val_accuracy: 0.6955\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7263 - accuracy: 0.6880 - val_loss: 0.7027 - val_accuracy: 0.6985\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7399 - accuracy: 0.6750 - val_loss: 0.7045 - val_accuracy: 0.6960\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7212 - accuracy: 0.6919 - val_loss: 0.7005 - val_accuracy: 0.6960\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7308 - accuracy: 0.6906 - val_loss: 0.7003 - val_accuracy: 0.6980\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7208 - accuracy: 0.6894 - val_loss: 0.7011 - val_accuracy: 0.7000\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7243 - accuracy: 0.6886 - val_loss: 0.6994 - val_accuracy: 0.6980\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7250 - accuracy: 0.6864 - val_loss: 0.7006 - val_accuracy: 0.6985\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7155 - accuracy: 0.6872 - val_loss: 0.7038 - val_accuracy: 0.7005\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7324 - accuracy: 0.6868 - val_loss: 0.7010 - val_accuracy: 0.6970\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7251 - accuracy: 0.6847 - val_loss: 0.7001 - val_accuracy: 0.7010\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7265 - accuracy: 0.6796 - val_loss: 0.6982 - val_accuracy: 0.7020\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7271 - accuracy: 0.6859 - val_loss: 0.6956 - val_accuracy: 0.7020\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7303 - accuracy: 0.6854 - val_loss: 0.7014 - val_accuracy: 0.7030\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $3^{rd}$ Model: Conv(13 filters, kernel_size 23), AvgPool\n",
    "Not expected to work best.. and so it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 38, 13)            312       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 7, 13)             0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 276       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_26 (Conv1D)           (None, 38, 13)            312       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_14 (Averag (None, 7, 13)             0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 276       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = compile_model( fil = [13], k_size = [23], PoolSize = 5, dense = [3], learn_rate = 0.001, dout_rate = 0.2)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=13, kernel_size = 23,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 1.0972 - accuracy: 0.3638 - val_loss: 1.0828 - val_accuracy: 0.4005\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0806 - accuracy: 0.4018 - val_loss: 1.0705 - val_accuracy: 0.4325\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0677 - accuracy: 0.4248 - val_loss: 1.0585 - val_accuracy: 0.4330\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0533 - accuracy: 0.4418 - val_loss: 1.0449 - val_accuracy: 0.4655\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0461 - accuracy: 0.4616 - val_loss: 1.0305 - val_accuracy: 0.4835\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0326 - accuracy: 0.4761 - val_loss: 1.0174 - val_accuracy: 0.4880\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0268 - accuracy: 0.4793 - val_loss: 1.0080 - val_accuracy: 0.5130\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0179 - accuracy: 0.4886 - val_loss: 0.9941 - val_accuracy: 0.5155\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9979 - accuracy: 0.5122 - val_loss: 0.9814 - val_accuracy: 0.5360\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9903 - accuracy: 0.5197 - val_loss: 0.9716 - val_accuracy: 0.5350\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9856 - accuracy: 0.5133 - val_loss: 0.9569 - val_accuracy: 0.5615\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9784 - accuracy: 0.5239 - val_loss: 0.9445 - val_accuracy: 0.5730\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9580 - accuracy: 0.5442 - val_loss: 0.9299 - val_accuracy: 0.5855\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9441 - accuracy: 0.5561 - val_loss: 0.9174 - val_accuracy: 0.5820\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9274 - accuracy: 0.5726 - val_loss: 0.9020 - val_accuracy: 0.6005\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9139 - accuracy: 0.5801 - val_loss: 0.8903 - val_accuracy: 0.6225\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9036 - accuracy: 0.5857 - val_loss: 0.8730 - val_accuracy: 0.6195\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8834 - accuracy: 0.5946 - val_loss: 0.8591 - val_accuracy: 0.6315\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8730 - accuracy: 0.6064 - val_loss: 0.8438 - val_accuracy: 0.6455\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8779 - accuracy: 0.6025 - val_loss: 0.8315 - val_accuracy: 0.6575\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8561 - accuracy: 0.6198 - val_loss: 0.8149 - val_accuracy: 0.6650\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8399 - accuracy: 0.6323 - val_loss: 0.8052 - val_accuracy: 0.6625\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8317 - accuracy: 0.6399 - val_loss: 0.7898 - val_accuracy: 0.6750\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8181 - accuracy: 0.6328 - val_loss: 0.7774 - val_accuracy: 0.6830\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8014 - accuracy: 0.6530 - val_loss: 0.7664 - val_accuracy: 0.6865\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7960 - accuracy: 0.6572 - val_loss: 0.7558 - val_accuracy: 0.6910\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7967 - accuracy: 0.6574 - val_loss: 0.7466 - val_accuracy: 0.6905\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7864 - accuracy: 0.6594 - val_loss: 0.7349 - val_accuracy: 0.7120\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.7765 - accuracy: 0.6618 - val_loss: 0.7276 - val_accuracy: 0.7095\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7532 - accuracy: 0.6827 - val_loss: 0.7169 - val_accuracy: 0.7145\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7414 - accuracy: 0.6909 - val_loss: 0.7124 - val_accuracy: 0.7215\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7430 - accuracy: 0.6887 - val_loss: 0.7030 - val_accuracy: 0.7240\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7421 - accuracy: 0.6901 - val_loss: 0.6932 - val_accuracy: 0.7260\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.6942 - val_loss: 0.6872 - val_accuracy: 0.7305\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7215 - accuracy: 0.7008 - val_loss: 0.6823 - val_accuracy: 0.7345\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7113 - accuracy: 0.7018 - val_loss: 0.6747 - val_accuracy: 0.7375\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7118 - accuracy: 0.6972 - val_loss: 0.6674 - val_accuracy: 0.7435\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7113 - accuracy: 0.7046 - val_loss: 0.6688 - val_accuracy: 0.7435\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7021 - accuracy: 0.7070 - val_loss: 0.6590 - val_accuracy: 0.7480\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6964 - accuracy: 0.7105 - val_loss: 0.6514 - val_accuracy: 0.7530\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.7117 - val_loss: 0.6513 - val_accuracy: 0.7515\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6943 - accuracy: 0.7108 - val_loss: 0.6389 - val_accuracy: 0.7575\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.6875 - accuracy: 0.7182 - val_loss: 0.6396 - val_accuracy: 0.7670\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.7189 - val_loss: 0.6338 - val_accuracy: 0.7615\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6881 - accuracy: 0.7173 - val_loss: 0.6285 - val_accuracy: 0.7620\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6738 - accuracy: 0.7251 - val_loss: 0.6263 - val_accuracy: 0.7680\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6717 - accuracy: 0.7274 - val_loss: 0.6227 - val_accuracy: 0.7720\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6723 - accuracy: 0.7305 - val_loss: 0.6212 - val_accuracy: 0.7785\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6653 - accuracy: 0.7226 - val_loss: 0.6185 - val_accuracy: 0.7755\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6622 - accuracy: 0.7316 - val_loss: 0.6112 - val_accuracy: 0.7750\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6669 - accuracy: 0.7261 - val_loss: 0.6077 - val_accuracy: 0.7725\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6606 - accuracy: 0.7271 - val_loss: 0.6060 - val_accuracy: 0.7705\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6562 - accuracy: 0.7331 - val_loss: 0.6031 - val_accuracy: 0.7750\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.7348 - val_loss: 0.5987 - val_accuracy: 0.7785\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.7433 - val_loss: 0.5992 - val_accuracy: 0.7820\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6407 - accuracy: 0.7336 - val_loss: 0.5951 - val_accuracy: 0.7810\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6504 - accuracy: 0.7313 - val_loss: 0.5917 - val_accuracy: 0.7820\n",
      "Epoch 58/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6472 - accuracy: 0.7354 - val_loss: 0.5895 - val_accuracy: 0.7815\n",
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.7418 - val_loss: 0.5880 - val_accuracy: 0.7850\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6243 - accuracy: 0.7499 - val_loss: 0.5954 - val_accuracy: 0.7820\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.7391 - val_loss: 0.5849 - val_accuracy: 0.7835\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.6293 - accuracy: 0.7489 - val_loss: 0.5935 - val_accuracy: 0.7765\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.6418 - accuracy: 0.7433 - val_loss: 0.5814 - val_accuracy: 0.7855\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6415 - accuracy: 0.7468 - val_loss: 0.5801 - val_accuracy: 0.7905\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6291 - accuracy: 0.7515 - val_loss: 0.5800 - val_accuracy: 0.7840\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6221 - accuracy: 0.7491 - val_loss: 0.5762 - val_accuracy: 0.7925\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6191 - accuracy: 0.7456 - val_loss: 0.5748 - val_accuracy: 0.7950\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6175 - accuracy: 0.7486 - val_loss: 0.5771 - val_accuracy: 0.7810\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6195 - accuracy: 0.7563 - val_loss: 0.5759 - val_accuracy: 0.7895\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6172 - accuracy: 0.7527 - val_loss: 0.5708 - val_accuracy: 0.7860\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6106 - accuracy: 0.7532 - val_loss: 0.5710 - val_accuracy: 0.7860\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6097 - accuracy: 0.7561 - val_loss: 0.5641 - val_accuracy: 0.7970\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.7688 - val_loss: 0.5637 - val_accuracy: 0.7950\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 0.7572 - val_loss: 0.5650 - val_accuracy: 0.7975\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6197 - accuracy: 0.7559 - val_loss: 0.5597 - val_accuracy: 0.7995\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.7566 - val_loss: 0.5630 - val_accuracy: 0.7950\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6021 - accuracy: 0.7616 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.7579 - val_loss: 0.5587 - val_accuracy: 0.7955\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5962 - accuracy: 0.7574 - val_loss: 0.5563 - val_accuracy: 0.7935\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5978 - accuracy: 0.7615 - val_loss: 0.5590 - val_accuracy: 0.7960\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6004 - accuracy: 0.7597 - val_loss: 0.5532 - val_accuracy: 0.8115\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.7607 - val_loss: 0.5560 - val_accuracy: 0.8000\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5907 - accuracy: 0.7738 - val_loss: 0.5558 - val_accuracy: 0.8005\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5894 - accuracy: 0.7746 - val_loss: 0.5510 - val_accuracy: 0.7970\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5756 - accuracy: 0.7752 - val_loss: 0.5516 - val_accuracy: 0.7995\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5799 - accuracy: 0.7699 - val_loss: 0.5472 - val_accuracy: 0.8055\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5988 - accuracy: 0.7669 - val_loss: 0.5445 - val_accuracy: 0.8105\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5842 - accuracy: 0.7759 - val_loss: 0.5428 - val_accuracy: 0.8125\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5861 - accuracy: 0.7695 - val_loss: 0.5397 - val_accuracy: 0.8135\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.76 - 0s 9ms/step - loss: 0.5908 - accuracy: 0.7645 - val_loss: 0.5410 - val_accuracy: 0.7935\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.7675 - val_loss: 0.5373 - val_accuracy: 0.8095\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5631 - accuracy: 0.7798 - val_loss: 0.5375 - val_accuracy: 0.8105\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5738 - accuracy: 0.7768 - val_loss: 0.5345 - val_accuracy: 0.8085\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5736 - accuracy: 0.7730 - val_loss: 0.5333 - val_accuracy: 0.8135\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5720 - accuracy: 0.7725 - val_loss: 0.5363 - val_accuracy: 0.8085\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5831 - accuracy: 0.7723 - val_loss: 0.5365 - val_accuracy: 0.8045\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5858 - accuracy: 0.7774 - val_loss: 0.5307 - val_accuracy: 0.8090\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5807 - accuracy: 0.7742 - val_loss: 0.5276 - val_accuracy: 0.8160\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5692 - accuracy: 0.7813 - val_loss: 0.5253 - val_accuracy: 0.8205\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5633 - accuracy: 0.7843 - val_loss: 0.5258 - val_accuracy: 0.8105\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5599 - accuracy: 0.7848 - val_loss: 0.5301 - val_accuracy: 0.8135\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5668 - accuracy: 0.7806 - val_loss: 0.5226 - val_accuracy: 0.8135\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5672 - accuracy: 0.7753 - val_loss: 0.5199 - val_accuracy: 0.8205\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5653 - accuracy: 0.7792 - val_loss: 0.5210 - val_accuracy: 0.8210\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5623 - accuracy: 0.7833 - val_loss: 0.5193 - val_accuracy: 0.8200\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5577 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.8220\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.5481 - accuracy: 0.7848 - val_loss: 0.5184 - val_accuracy: 0.8225\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5548 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.8220\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5524 - accuracy: 0.7835 - val_loss: 0.5192 - val_accuracy: 0.8120\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.7866 - val_loss: 0.5161 - val_accuracy: 0.8175\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5753 - accuracy: 0.7785 - val_loss: 0.5158 - val_accuracy: 0.8200\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5493 - accuracy: 0.7920 - val_loss: 0.5175 - val_accuracy: 0.8180\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5516 - accuracy: 0.7843 - val_loss: 0.5090 - val_accuracy: 0.8170\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5482 - accuracy: 0.7833 - val_loss: 0.5117 - val_accuracy: 0.8200\n",
      "Epoch 115/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5378 - accuracy: 0.7967 - val_loss: 0.5106 - val_accuracy: 0.8185\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.7787 - val_loss: 0.5079 - val_accuracy: 0.8235\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5402 - accuracy: 0.7936 - val_loss: 0.5102 - val_accuracy: 0.8210\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5474 - accuracy: 0.7843 - val_loss: 0.5220 - val_accuracy: 0.8025\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5556 - accuracy: 0.7899 - val_loss: 0.5233 - val_accuracy: 0.8065\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5764 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.8180\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5376 - accuracy: 0.7974 - val_loss: 0.5087 - val_accuracy: 0.8210\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.5487 - accuracy: 0.7837 - val_loss: 0.5040 - val_accuracy: 0.8215\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5428 - accuracy: 0.7941 - val_loss: 0.5024 - val_accuracy: 0.8235\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5457 - accuracy: 0.7897 - val_loss: 0.5047 - val_accuracy: 0.8190\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5489 - accuracy: 0.7816 - val_loss: 0.5050 - val_accuracy: 0.8220\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5535 - accuracy: 0.7826 - val_loss: 0.5058 - val_accuracy: 0.8160\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.8005 - val_loss: 0.5022 - val_accuracy: 0.8225\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5454 - accuracy: 0.7946 - val_loss: 0.5022 - val_accuracy: 0.8235\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5407 - accuracy: 0.7990 - val_loss: 0.4996 - val_accuracy: 0.8260\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.7953 - val_loss: 0.4977 - val_accuracy: 0.8260\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5462 - accuracy: 0.7903 - val_loss: 0.5048 - val_accuracy: 0.8165\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5385 - accuracy: 0.7908 - val_loss: 0.5037 - val_accuracy: 0.8175\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5327 - accuracy: 0.7904 - val_loss: 0.5034 - val_accuracy: 0.8195\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7863 - val_loss: 0.5013 - val_accuracy: 0.8165\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5449 - accuracy: 0.7839 - val_loss: 0.5034 - val_accuracy: 0.8200\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5367 - accuracy: 0.7889 - val_loss: 0.4986 - val_accuracy: 0.8160\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5495 - accuracy: 0.7876 - val_loss: 0.4953 - val_accuracy: 0.8270\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5224 - accuracy: 0.8031 - val_loss: 0.5016 - val_accuracy: 0.8185\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5383 - accuracy: 0.7923 - val_loss: 0.4967 - val_accuracy: 0.8240\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5271 - accuracy: 0.7947 - val_loss: 0.4937 - val_accuracy: 0.8215\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5354 - accuracy: 0.7926 - val_loss: 0.4981 - val_accuracy: 0.8255\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5341 - accuracy: 0.7959 - val_loss: 0.4981 - val_accuracy: 0.8190\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5396 - accuracy: 0.7918 - val_loss: 0.4938 - val_accuracy: 0.8215\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5444 - accuracy: 0.7861 - val_loss: 0.4946 - val_accuracy: 0.8235\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5307 - accuracy: 0.7890 - val_loss: 0.4942 - val_accuracy: 0.8300\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5429 - accuracy: 0.7941 - val_loss: 0.4947 - val_accuracy: 0.8185\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5214 - accuracy: 0.7952 - val_loss: 0.4920 - val_accuracy: 0.8215\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5381 - accuracy: 0.7945 - val_loss: 0.4986 - val_accuracy: 0.8235\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.8054 - val_loss: 0.4950 - val_accuracy: 0.8225\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5333 - accuracy: 0.7929 - val_loss: 0.4891 - val_accuracy: 0.8260\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5319 - accuracy: 0.7937 - val_loss: 0.4923 - val_accuracy: 0.8225\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5289 - accuracy: 0.7931 - val_loss: 0.4909 - val_accuracy: 0.8240\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5445 - accuracy: 0.7955 - val_loss: 0.4913 - val_accuracy: 0.8195\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.8067 - val_loss: 0.4887 - val_accuracy: 0.8225\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5341 - accuracy: 0.7946 - val_loss: 0.4881 - val_accuracy: 0.8265\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5423 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.8225\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7980 - val_loss: 0.4931 - val_accuracy: 0.8205\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5282 - accuracy: 0.8047 - val_loss: 0.4960 - val_accuracy: 0.8210\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.7927 - val_loss: 0.4906 - val_accuracy: 0.8245\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5300 - accuracy: 0.7920 - val_loss: 0.4900 - val_accuracy: 0.8180\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.8041 - val_loss: 0.4874 - val_accuracy: 0.8245\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5361 - accuracy: 0.7966 - val_loss: 0.4874 - val_accuracy: 0.8255\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5227 - accuracy: 0.7988 - val_loss: 0.4862 - val_accuracy: 0.8265\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5305 - accuracy: 0.8025 - val_loss: 0.4858 - val_accuracy: 0.8255\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.7978 - val_loss: 0.4866 - val_accuracy: 0.8250\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5175 - accuracy: 0.8065 - val_loss: 0.4843 - val_accuracy: 0.8260\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.7966 - val_loss: 0.4892 - val_accuracy: 0.8190\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5306 - accuracy: 0.8016 - val_loss: 0.4859 - val_accuracy: 0.8245\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7948 - val_loss: 0.4841 - val_accuracy: 0.8210\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5270 - accuracy: 0.7968 - val_loss: 0.4832 - val_accuracy: 0.8285\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5303 - accuracy: 0.7943 - val_loss: 0.4873 - val_accuracy: 0.8285\n",
      "Epoch 172/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5213 - accuracy: 0.7993 - val_loss: 0.4912 - val_accuracy: 0.8250\n",
      "Epoch 173/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.7996 - val_loss: 0.4815 - val_accuracy: 0.8290\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.8036 - val_loss: 0.4823 - val_accuracy: 0.8310\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5385 - accuracy: 0.8061 - val_loss: 0.4815 - val_accuracy: 0.8325\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5273 - accuracy: 0.8024 - val_loss: 0.4822 - val_accuracy: 0.8280\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5282 - accuracy: 0.8027 - val_loss: 0.4806 - val_accuracy: 0.8310\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5145 - accuracy: 0.8074 - val_loss: 0.4807 - val_accuracy: 0.8310\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7994 - val_loss: 0.4863 - val_accuracy: 0.8250\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.8002 - val_loss: 0.4833 - val_accuracy: 0.8275\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5206 - accuracy: 0.8049 - val_loss: 0.4827 - val_accuracy: 0.8225\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5178 - accuracy: 0.8000 - val_loss: 0.4863 - val_accuracy: 0.8280\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5350 - accuracy: 0.7956 - val_loss: 0.4818 - val_accuracy: 0.8240\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5342 - accuracy: 0.8016 - val_loss: 0.4785 - val_accuracy: 0.8300\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5183 - accuracy: 0.8058 - val_loss: 0.4789 - val_accuracy: 0.8250\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5285 - accuracy: 0.7978 - val_loss: 0.4823 - val_accuracy: 0.8360\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.8002 - val_loss: 0.4803 - val_accuracy: 0.8275\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.8004 - val_loss: 0.4859 - val_accuracy: 0.8220\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8061 - val_loss: 0.4865 - val_accuracy: 0.8235\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5315 - accuracy: 0.7968 - val_loss: 0.4812 - val_accuracy: 0.8280\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.8082 - val_loss: 0.4771 - val_accuracy: 0.8280\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5059 - accuracy: 0.8084 - val_loss: 0.4770 - val_accuracy: 0.8240\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5125 - accuracy: 0.8069 - val_loss: 0.4876 - val_accuracy: 0.8210\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5194 - accuracy: 0.7984 - val_loss: 0.4821 - val_accuracy: 0.8260\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5287 - accuracy: 0.8028 - val_loss: 0.4843 - val_accuracy: 0.8205\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5169 - accuracy: 0.8014 - val_loss: 0.4806 - val_accuracy: 0.8375\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5108 - accuracy: 0.7993 - val_loss: 0.4857 - val_accuracy: 0.8245\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.7955 - val_loss: 0.4786 - val_accuracy: 0.8315\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5167 - accuracy: 0.8029 - val_loss: 0.4793 - val_accuracy: 0.8290\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5189 - accuracy: 0.7961 - val_loss: 0.4783 - val_accuracy: 0.8280\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5287 - accuracy: 0.8016 - val_loss: 0.4753 - val_accuracy: 0.8310\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5143 - accuracy: 0.8012 - val_loss: 0.4811 - val_accuracy: 0.8240\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5223 - accuracy: 0.8015 - val_loss: 0.4753 - val_accuracy: 0.8345\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.7985 - val_loss: 0.4802 - val_accuracy: 0.8290\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.7989 - val_loss: 0.4735 - val_accuracy: 0.8365\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5120 - accuracy: 0.8002 - val_loss: 0.4710 - val_accuracy: 0.8355\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.8043 - val_loss: 0.4731 - val_accuracy: 0.8350\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5295 - accuracy: 0.7976 - val_loss: 0.4723 - val_accuracy: 0.8335\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.8051 - val_loss: 0.4762 - val_accuracy: 0.8280\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.8036 - val_loss: 0.4717 - val_accuracy: 0.8370\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5167 - accuracy: 0.8098 - val_loss: 0.4713 - val_accuracy: 0.8310\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5178 - accuracy: 0.8054 - val_loss: 0.4746 - val_accuracy: 0.8250\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5131 - accuracy: 0.8074 - val_loss: 0.4720 - val_accuracy: 0.8320\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.8071 - val_loss: 0.4731 - val_accuracy: 0.8325\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5253 - accuracy: 0.7921 - val_loss: 0.4723 - val_accuracy: 0.8375\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8066 - val_loss: 0.4707 - val_accuracy: 0.8325\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5177 - accuracy: 0.8074 - val_loss: 0.4711 - val_accuracy: 0.8320\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5236 - accuracy: 0.7999 - val_loss: 0.4808 - val_accuracy: 0.8330\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.8034 - val_loss: 0.4745 - val_accuracy: 0.8335\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5039 - accuracy: 0.8085 - val_loss: 0.4726 - val_accuracy: 0.8245\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.8028 - val_loss: 0.4734 - val_accuracy: 0.8300\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7990 - val_loss: 0.4803 - val_accuracy: 0.8300\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5238 - accuracy: 0.7990 - val_loss: 0.4737 - val_accuracy: 0.8355\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.8076 - val_loss: 0.4772 - val_accuracy: 0.8315\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.8110 - val_loss: 0.4768 - val_accuracy: 0.8355\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5105 - accuracy: 0.8046 - val_loss: 0.4742 - val_accuracy: 0.8310\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5207 - accuracy: 0.8074 - val_loss: 0.4726 - val_accuracy: 0.8360\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.8033 - val_loss: 0.4763 - val_accuracy: 0.8350\n",
      "Epoch 229/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5344 - accuracy: 0.7990 - val_loss: 0.4704 - val_accuracy: 0.8365\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5005 - accuracy: 0.8132 - val_loss: 0.4702 - val_accuracy: 0.8370\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5207 - accuracy: 0.8089 - val_loss: 0.4745 - val_accuracy: 0.8325\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5181 - accuracy: 0.7991 - val_loss: 0.4689 - val_accuracy: 0.8350\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.7979 - val_loss: 0.4707 - val_accuracy: 0.8275\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5068 - accuracy: 0.8079 - val_loss: 0.4715 - val_accuracy: 0.8405\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.8087 - val_loss: 0.4689 - val_accuracy: 0.8355\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.8126 - val_loss: 0.4685 - val_accuracy: 0.8275\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4999 - accuracy: 0.8102 - val_loss: 0.4679 - val_accuracy: 0.8360\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5114 - accuracy: 0.8080 - val_loss: 0.4707 - val_accuracy: 0.8330\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5102 - accuracy: 0.8069 - val_loss: 0.4743 - val_accuracy: 0.8330\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5205 - accuracy: 0.8045 - val_loss: 0.4680 - val_accuracy: 0.8305\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.8087 - val_loss: 0.4714 - val_accuracy: 0.8270\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8139 - val_loss: 0.4673 - val_accuracy: 0.8350\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5084 - accuracy: 0.8093 - val_loss: 0.4756 - val_accuracy: 0.8400\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5153 - accuracy: 0.8092 - val_loss: 0.4694 - val_accuracy: 0.8340\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.7989 - val_loss: 0.4720 - val_accuracy: 0.8325\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.7998 - val_loss: 0.4687 - val_accuracy: 0.8290\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4974 - accuracy: 0.8121 - val_loss: 0.4685 - val_accuracy: 0.8350\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8126 - val_loss: 0.4677 - val_accuracy: 0.8345\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5085 - accuracy: 0.8097 - val_loss: 0.4732 - val_accuracy: 0.8345\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5290 - accuracy: 0.7996 - val_loss: 0.4727 - val_accuracy: 0.8335\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result is achieved by the combination of a strong Convolutional neural network and one dense layer. We can also appreciate how the number of parameters increases a lot with the number of filters, while the kernel size has a minimum effect. In practice if we change the kernel size or the number of nodes in the dense layer we obtain approximately the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same model we used in lessons to evaluate how regulations values change the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# # call Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn = compile_model)\n",
    "\n",
    "\n",
    "# define parameter dictionary\n",
    "reg = [regularizers.l1, regularizers.l2, regularizers.l1_l2]\n",
    "l= [0.1,0.01,0.001,0.0001]\n",
    "param_grid = dict(reg = reg , l=l)\n",
    "# # call scikit grid search module\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=1, cv=4)\n",
    "grid_result = grid.fit(x_train,y_train, epochs=250, batch_size = 250, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_l</th>\n",
       "      <th>param_reg</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.743135</td>\n",
       "      <td>0.396809</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.1, 'reg': &lt;class 'tensorflow.python.ke...</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.555042</td>\n",
       "      <td>4.664063</td>\n",
       "      <td>0.180385</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.1, 'reg': &lt;function l1_l2 at 0x7fa2bbc...</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.651340</td>\n",
       "      <td>4.081976</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.040384</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.01, 'reg': &lt;class 'tensorflow.python.k...</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>0.065722</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.346722</td>\n",
       "      <td>4.184644</td>\n",
       "      <td>0.158263</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.0001, 'reg': &lt;class 'tensorflow.python...</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.673250</td>\n",
       "      <td>0.076202</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.771484</td>\n",
       "      <td>4.224691</td>\n",
       "      <td>0.172961</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.01, 'reg': &lt;function l1_l2 at 0x7fa2bb...</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.674750</td>\n",
       "      <td>0.072110</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.804894</td>\n",
       "      <td>0.155126</td>\n",
       "      <td>0.144236</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.1, 'reg': &lt;class 'tensorflow.python.ke...</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.702375</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.286934</td>\n",
       "      <td>3.832132</td>\n",
       "      <td>0.168695</td>\n",
       "      <td>0.035507</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.001, 'reg': &lt;class 'tensorflow.python....</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.704625</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.200689</td>\n",
       "      <td>4.584406</td>\n",
       "      <td>0.182908</td>\n",
       "      <td>0.044824</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.0001, 'reg': &lt;function l1_l2 at 0x7fa2...</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.7170</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.526269</td>\n",
       "      <td>4.302998</td>\n",
       "      <td>0.192493</td>\n",
       "      <td>0.048365</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.001, 'reg': &lt;function l1_l2 at 0x7fa2b...</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.712125</td>\n",
       "      <td>0.020879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.064559</td>\n",
       "      <td>1.456055</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>0.031747</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.01, 'reg': &lt;class 'tensorflow.python.k...</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.999654</td>\n",
       "      <td>3.616142</td>\n",
       "      <td>0.187711</td>\n",
       "      <td>0.062828</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.001, 'reg': &lt;class 'tensorflow.python....</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.714125</td>\n",
       "      <td>0.022714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.789652</td>\n",
       "      <td>3.290008</td>\n",
       "      <td>0.172440</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.0001, 'reg': &lt;class 'tensorflow.python...</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>0.723875</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_l  \\\n",
       "0       11.743135      0.396809         0.144392        0.006275   0.1000   \n",
       "2       15.555042      4.664063         0.180385        0.043716   0.1000   \n",
       "3       15.651340      4.081976         0.188800        0.040384   0.0100   \n",
       "10      15.346722      4.184644         0.158263        0.033479   0.0001   \n",
       "5       14.771484      4.224691         0.172961        0.031725   0.0100   \n",
       "1       11.804894      0.155126         0.144236        0.008223   0.1000   \n",
       "6       16.286934      3.832132         0.168695        0.035507   0.0010   \n",
       "11      16.200689      4.584406         0.182908        0.044824   0.0001   \n",
       "8       14.526269      4.302998         0.192493        0.048365   0.0010   \n",
       "4       12.064559      1.456055         0.162866        0.031747   0.0100   \n",
       "7       15.999654      3.616142         0.187711        0.062828   0.0010   \n",
       "9       13.789652      3.290008         0.172440        0.036120   0.0001   \n",
       "\n",
       "                                            param_reg  \\\n",
       "0   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "2                  <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "3   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "10  <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "5                  <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "1   <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "6   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "11                 <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "8                  <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "4   <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "7   <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "9   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'l': 0.1, 'reg': <class 'tensorflow.python.ke...             0.3205   \n",
       "2   {'l': 0.1, 'reg': <function l1_l2 at 0x7fa2bbc...             0.3205   \n",
       "3   {'l': 0.01, 'reg': <class 'tensorflow.python.k...             0.6730   \n",
       "10  {'l': 0.0001, 'reg': <class 'tensorflow.python...             0.5415   \n",
       "5   {'l': 0.01, 'reg': <function l1_l2 at 0x7fa2bb...             0.7050   \n",
       "1   {'l': 0.1, 'reg': <class 'tensorflow.python.ke...             0.7130   \n",
       "6   {'l': 0.001, 'reg': <class 'tensorflow.python....             0.6950   \n",
       "11  {'l': 0.0001, 'reg': <function l1_l2 at 0x7fa2...             0.6950   \n",
       "8   {'l': 0.001, 'reg': <function l1_l2 at 0x7fa2b...             0.6930   \n",
       "4   {'l': 0.01, 'reg': <class 'tensorflow.python.k...             0.6880   \n",
       "7   {'l': 0.001, 'reg': <class 'tensorflow.python....             0.6885   \n",
       "9   {'l': 0.0001, 'reg': <class 'tensorflow.python...             0.6845   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0              0.3360             0.3140             0.3305         0.325250   \n",
       "2              0.3360             0.3140             0.3305         0.325250   \n",
       "3              0.5395             0.6810             0.5525         0.611500   \n",
       "10             0.7125             0.7245             0.7145         0.673250   \n",
       "5              0.5505             0.7255             0.7180         0.674750   \n",
       "1              0.6915             0.6825             0.7225         0.702375   \n",
       "6              0.6920             0.7335             0.6980         0.704625   \n",
       "11             0.7170             0.7315             0.6980         0.710375   \n",
       "8              0.7165             0.6945             0.7445         0.712125   \n",
       "4              0.7120             0.7180             0.7320         0.712500   \n",
       "7              0.7255             0.6970             0.7455         0.714125   \n",
       "9              0.7125             0.7195             0.7790         0.723875   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.008548               11  \n",
       "2         0.008548               11  \n",
       "3         0.065722               10  \n",
       "10        0.076202                9  \n",
       "5         0.072110                8  \n",
       "1         0.016056                7  \n",
       "6         0.016805                6  \n",
       "11        0.014830                5  \n",
       "8         0.020879                4  \n",
       "4         0.015898                3  \n",
       "7         0.022714                2  \n",
       "9         0.034415                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GridSearch = pd.read_csv(\"DATA/Regularization_results.csv\", index_col = False)\n",
    "df_GridSearch = df_GridSearch.iloc[:,1:]\n",
    "df_GridSearch.sort_values(by = \"rank_test_score\", ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr = df_GridSearch.pivot(index = \"param_l\", columns = \"param_reg\", values = \"mean_test_score\")\n",
    "g = sns.heatmap(pr, cmap=\"mako\")\n",
    "g.set(xticklabels=[\"L1\", \"L2\", \"L1_L2\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best fits are achieved by regularizers with small parameters: L1 and L1_L2 perform best with a parameter = 0.0001. Also L2 allows brings similar results with an higher parameter (0.001). Definitely using a too strong regularization (L1 with 0.1 for example) gives poor results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-315f987edcd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5ed6bd22e872>\u001b[0m in \u001b[0;36mcompile_model\u001b[0;34m(reg, PoolType, PoolSize, learn_rate, fil, k_size, dout_rate, dense)\u001b[0m\n\u001b[1;32m      3\u001b[0m                dout_rate = 0.2, dense = [10]):\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# create the mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPoolType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoolSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c42e242a8b4b>\u001b[0m in \u001b[0;36mcreate_CNN\u001b[0;34m(reg, PoolType, PoolSize, learn_rate, fil, k_size, dout_rate, dense)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         ))\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPoolType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPoolSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "model1 = compile_model( regularizers.l2,  0.1)\n",
    "model2 = compile_model( regularizers.l2,  0.001)\n",
    "\n",
    "model1.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)\n",
    "model2.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-77775824a8e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"#D81B60\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#1E88E5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#FFC107\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#004D40\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}° filter\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(20,5), sharey=True)\n",
    "colors = [\"#D81B60\", \"#1E88E5\", \"#FFC107\", \"#004D40\"]\n",
    "\n",
    "filters, biases = model1.layers[0].get_weights()\n",
    "axes[0].imgshow(filters, color = colors[i],label = \"{}° filter\".format(i+1), lw =2.5)\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"Strong regularization\")\n",
    "\n",
    "filters, biases = model2.layers[0].get_weights()\n",
    "axes[1].imgshow(filters, color = colors[i], label = f\"{i+1}° filter\", lw =2.5)\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Weak regularization\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for strong regularization is 0.71, while for weak regularization is 0.72\n"
     ]
    }
   ],
   "source": [
    "results1 = model1.evaluate(x_test, y_test, verbose = 0)\n",
    "results2 = model2.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "print(f\"Validation loss for strong regularization is {results1[1]:1.2}, while for weak regularization is {results2[1]:1.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily see how strong regularization give weights of almost zero value, while pattern recognition is not visible. Results are also similar in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 50, 8)             96        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_11 (Averag (None, 10, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 4, 5)              285       \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 624\n",
      "Trainable params: 624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "ini = initializers.RandomNormal(mean=0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 8, kernel_size = 11,\n",
    "                 kernel_regularizer = reg,\n",
    "                 kernel_initializer = ini,\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape \n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Conv1D(filters = 5, kernel_size = 7, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation = 'softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "from keras import optimizers\n",
    "opt = optimizers.SGD(lr = 0.01, momentum = 0.9, nesterov = True, decay = 1e-6)\n",
    "model.compile(loss =keras.losses.categorical_crossentropy, \n",
    "             optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9952 - accuracy: 0.5408 - val_loss: 0.7590 - val_accuracy: 0.5615\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7601 - accuracy: 0.5809 - val_loss: 0.7197 - val_accuracy: 0.6030\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7410 - accuracy: 0.5934 - val_loss: 0.7038 - val_accuracy: 0.6190\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7340 - accuracy: 0.5966 - val_loss: 0.6966 - val_accuracy: 0.6230\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7270 - accuracy: 0.6051 - val_loss: 0.6910 - val_accuracy: 0.6310\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7244 - accuracy: 0.6055 - val_loss: 0.6872 - val_accuracy: 0.6380\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7188 - accuracy: 0.6152 - val_loss: 0.6874 - val_accuracy: 0.6360\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7175 - accuracy: 0.6173 - val_loss: 0.6815 - val_accuracy: 0.6475\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7101 - accuracy: 0.6195 - val_loss: 0.6779 - val_accuracy: 0.6485\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7079 - accuracy: 0.6176 - val_loss: 0.6769 - val_accuracy: 0.6530\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7048 - accuracy: 0.6251 - val_loss: 0.6734 - val_accuracy: 0.6570\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7005 - accuracy: 0.6285 - val_loss: 0.6753 - val_accuracy: 0.6580\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6993 - accuracy: 0.6403 - val_loss: 0.6677 - val_accuracy: 0.6600\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7000 - accuracy: 0.6315 - val_loss: 0.6696 - val_accuracy: 0.6615\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.6391 - val_loss: 0.6660 - val_accuracy: 0.6705\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.6390 - val_loss: 0.6609 - val_accuracy: 0.6695\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.6404 - val_loss: 0.6589 - val_accuracy: 0.6780\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.6420 - val_loss: 0.6593 - val_accuracy: 0.6810\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.6491 - val_loss: 0.6565 - val_accuracy: 0.6745\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.6430 - val_loss: 0.6568 - val_accuracy: 0.6715\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6530 - val_loss: 0.6525 - val_accuracy: 0.6770\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6520 - val_loss: 0.6530 - val_accuracy: 0.6855\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.6507 - val_loss: 0.6475 - val_accuracy: 0.6890\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.6541 - val_loss: 0.6486 - val_accuracy: 0.6840\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6547 - val_loss: 0.6473 - val_accuracy: 0.6835\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.6536 - val_loss: 0.6549 - val_accuracy: 0.6800\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6571 - val_loss: 0.6408 - val_accuracy: 0.6950\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.6654 - val_loss: 0.6383 - val_accuracy: 0.6950\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.6647 - val_loss: 0.6431 - val_accuracy: 0.6870\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6628 - val_loss: 0.6430 - val_accuracy: 0.6975\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.6624 - val_loss: 0.6349 - val_accuracy: 0.7025\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6681 - val_loss: 0.6348 - val_accuracy: 0.6990\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6722 - val_loss: 0.6311 - val_accuracy: 0.7030\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6722 - val_loss: 0.6328 - val_accuracy: 0.6980\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6715 - val_loss: 0.6332 - val_accuracy: 0.7095\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6739 - val_loss: 0.6345 - val_accuracy: 0.7025\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6731 - val_loss: 0.6270 - val_accuracy: 0.7100\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.6752 - val_loss: 0.6281 - val_accuracy: 0.7095\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6746 - val_loss: 0.6241 - val_accuracy: 0.7080\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6823 - val_loss: 0.6228 - val_accuracy: 0.7190\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.6785 - val_loss: 0.6227 - val_accuracy: 0.7065\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6854 - val_loss: 0.6218 - val_accuracy: 0.7130\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.6839 - val_loss: 0.6211 - val_accuracy: 0.7205\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6864 - val_loss: 0.6218 - val_accuracy: 0.7050\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6810 - val_loss: 0.6169 - val_accuracy: 0.7175\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6836 - val_loss: 0.6177 - val_accuracy: 0.7130\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6873 - val_loss: 0.6146 - val_accuracy: 0.7180\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6825 - val_loss: 0.6142 - val_accuracy: 0.7270\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6859 - val_loss: 0.6170 - val_accuracy: 0.7145\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6876 - val_loss: 0.6159 - val_accuracy: 0.7200\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6913 - val_loss: 0.6160 - val_accuracy: 0.7245\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6914 - val_loss: 0.6136 - val_accuracy: 0.7275\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6935 - val_loss: 0.6118 - val_accuracy: 0.7230\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6899 - val_loss: 0.6111 - val_accuracy: 0.7120\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6892 - val_loss: 0.6091 - val_accuracy: 0.7325\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6988 - val_loss: 0.6071 - val_accuracy: 0.7265\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.7009 - val_loss: 0.6085 - val_accuracy: 0.7165\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6939 - val_loss: 0.6085 - val_accuracy: 0.7290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6933 - val_loss: 0.6074 - val_accuracy: 0.7285\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6938 - val_loss: 0.6033 - val_accuracy: 0.7310\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7003 - val_loss: 0.6180 - val_accuracy: 0.7250\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6945 - val_loss: 0.6027 - val_accuracy: 0.7300\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7064 - val_loss: 0.6059 - val_accuracy: 0.7315\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7009 - val_loss: 0.6051 - val_accuracy: 0.7290\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.7032 - val_loss: 0.6058 - val_accuracy: 0.7285\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6994 - val_loss: 0.5993 - val_accuracy: 0.7300\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7049 - val_loss: 0.5986 - val_accuracy: 0.7365\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7041 - val_loss: 0.5981 - val_accuracy: 0.7350\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7086 - val_loss: 0.5964 - val_accuracy: 0.7380\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.7028 - val_loss: 0.5995 - val_accuracy: 0.7345\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7040 - val_loss: 0.5967 - val_accuracy: 0.7290\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7061 - val_loss: 0.5944 - val_accuracy: 0.7380\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7075 - val_loss: 0.5942 - val_accuracy: 0.7395\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7094 - val_loss: 0.6027 - val_accuracy: 0.7350\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.7055 - val_loss: 0.5910 - val_accuracy: 0.7445\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.7120 - val_loss: 0.5895 - val_accuracy: 0.7475\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.7124 - val_loss: 0.5884 - val_accuracy: 0.7405\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.7124 - val_loss: 0.5866 - val_accuracy: 0.7465\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7163 - val_loss: 0.5878 - val_accuracy: 0.7390\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7149 - val_loss: 0.5846 - val_accuracy: 0.7370\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.7153 - val_loss: 0.5883 - val_accuracy: 0.7465\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7199 - val_loss: 0.5862 - val_accuracy: 0.7475\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.7176 - val_loss: 0.5820 - val_accuracy: 0.7505\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7206 - val_loss: 0.5796 - val_accuracy: 0.7545\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7230 - val_loss: 0.5770 - val_accuracy: 0.7505\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.7184 - val_loss: 0.5746 - val_accuracy: 0.7545\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7264 - val_loss: 0.5731 - val_accuracy: 0.7615\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7291 - val_loss: 0.5740 - val_accuracy: 0.7620\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7294 - val_loss: 0.5664 - val_accuracy: 0.7600\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.7286 - val_loss: 0.5604 - val_accuracy: 0.7605\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7308 - val_loss: 0.5629 - val_accuracy: 0.7625\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7398 - val_loss: 0.5614 - val_accuracy: 0.7610\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7381 - val_loss: 0.5587 - val_accuracy: 0.7680\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7423 - val_loss: 0.5602 - val_accuracy: 0.7630\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7350 - val_loss: 0.5537 - val_accuracy: 0.7675\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7418 - val_loss: 0.5519 - val_accuracy: 0.7655\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7473 - val_loss: 0.5537 - val_accuracy: 0.7645\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7429 - val_loss: 0.5500 - val_accuracy: 0.7660\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7446 - val_loss: 0.5488 - val_accuracy: 0.7670\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7471 - val_loss: 0.5525 - val_accuracy: 0.7615\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7485 - val_loss: 0.5484 - val_accuracy: 0.7650\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7473 - val_loss: 0.5499 - val_accuracy: 0.7710\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7505 - val_loss: 0.5441 - val_accuracy: 0.7715\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7519 - val_loss: 0.5461 - val_accuracy: 0.7695\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7542 - val_loss: 0.5455 - val_accuracy: 0.7635\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7549 - val_loss: 0.5400 - val_accuracy: 0.7730\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7585 - val_loss: 0.5455 - val_accuracy: 0.7675\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7539 - val_loss: 0.5386 - val_accuracy: 0.7795\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7546 - val_loss: 0.5421 - val_accuracy: 0.7670\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7552 - val_loss: 0.5478 - val_accuracy: 0.7700\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7596 - val_loss: 0.5375 - val_accuracy: 0.7760\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7538 - val_loss: 0.5373 - val_accuracy: 0.7775\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7598 - val_loss: 0.5399 - val_accuracy: 0.7715\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7607 - val_loss: 0.5374 - val_accuracy: 0.7780\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7590 - val_loss: 0.5384 - val_accuracy: 0.7735\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7601 - val_loss: 0.5408 - val_accuracy: 0.7685\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7632 - val_loss: 0.5329 - val_accuracy: 0.7810\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7650 - val_loss: 0.5361 - val_accuracy: 0.7695\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7641 - val_loss: 0.5324 - val_accuracy: 0.7810\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7626 - val_loss: 0.5316 - val_accuracy: 0.7790\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7729 - val_loss: 0.5332 - val_accuracy: 0.7740\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7638 - val_loss: 0.5304 - val_accuracy: 0.7800\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7635 - val_loss: 0.5301 - val_accuracy: 0.7825\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7705 - val_loss: 0.5317 - val_accuracy: 0.7780\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7626 - val_loss: 0.5281 - val_accuracy: 0.7785\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7697 - val_loss: 0.5272 - val_accuracy: 0.7835\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7681 - val_loss: 0.5309 - val_accuracy: 0.7705\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7725 - val_loss: 0.5289 - val_accuracy: 0.7765\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7673 - val_loss: 0.5242 - val_accuracy: 0.7865\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7663 - val_loss: 0.5274 - val_accuracy: 0.7780\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7706 - val_loss: 0.5226 - val_accuracy: 0.7860\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7719 - val_loss: 0.5227 - val_accuracy: 0.7835\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7695 - val_loss: 0.5234 - val_accuracy: 0.7800\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7719 - val_loss: 0.5297 - val_accuracy: 0.7770\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7741 - val_loss: 0.5230 - val_accuracy: 0.7810\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7688 - val_loss: 0.5257 - val_accuracy: 0.7785\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7717 - val_loss: 0.5248 - val_accuracy: 0.7810\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7720 - val_loss: 0.5199 - val_accuracy: 0.7845\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7684 - val_loss: 0.5234 - val_accuracy: 0.7825\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7732 - val_loss: 0.5187 - val_accuracy: 0.7875\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7742 - val_loss: 0.5236 - val_accuracy: 0.7840\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7703 - val_loss: 0.5237 - val_accuracy: 0.7755\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7745 - val_loss: 0.5247 - val_accuracy: 0.7770\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7757 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7738 - val_loss: 0.5220 - val_accuracy: 0.7835\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7759 - val_loss: 0.5284 - val_accuracy: 0.7780\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7794 - val_loss: 0.5169 - val_accuracy: 0.7900\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7775 - val_loss: 0.5215 - val_accuracy: 0.7825\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7740 - val_loss: 0.5255 - val_accuracy: 0.7835\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7768 - val_loss: 0.5201 - val_accuracy: 0.7850\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7744 - val_loss: 0.5196 - val_accuracy: 0.7835\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7735 - val_loss: 0.5161 - val_accuracy: 0.7865\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7759 - val_loss: 0.5203 - val_accuracy: 0.7825\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7782 - val_loss: 0.5235 - val_accuracy: 0.7830\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7800 - val_loss: 0.5172 - val_accuracy: 0.7875\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7770 - val_loss: 0.5169 - val_accuracy: 0.7835\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7791 - val_loss: 0.5188 - val_accuracy: 0.7835\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7797 - val_loss: 0.5226 - val_accuracy: 0.7875\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7772 - val_loss: 0.5155 - val_accuracy: 0.7875\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7772 - val_loss: 0.5166 - val_accuracy: 0.7835\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7794 - val_loss: 0.5160 - val_accuracy: 0.7850\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7801 - val_loss: 0.5195 - val_accuracy: 0.7860\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7784 - val_loss: 0.5217 - val_accuracy: 0.7855\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7781 - val_loss: 0.5171 - val_accuracy: 0.7855\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7826 - val_loss: 0.5153 - val_accuracy: 0.7840\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7791 - val_loss: 0.5210 - val_accuracy: 0.7855\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7791 - val_loss: 0.5183 - val_accuracy: 0.7835\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7828 - val_loss: 0.5155 - val_accuracy: 0.7865\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7818 - val_loss: 0.5151 - val_accuracy: 0.7880\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7794 - val_loss: 0.5188 - val_accuracy: 0.7835\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7807 - val_loss: 0.5182 - val_accuracy: 0.7870\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7810 - val_loss: 0.5148 - val_accuracy: 0.7875\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7819 - val_loss: 0.5144 - val_accuracy: 0.7835\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7859 - val_loss: 0.5201 - val_accuracy: 0.7835\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7874 - val_loss: 0.5168 - val_accuracy: 0.7865\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7841 - val_loss: 0.5253 - val_accuracy: 0.7820\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7819 - val_loss: 0.5150 - val_accuracy: 0.7855\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7786 - val_loss: 0.5139 - val_accuracy: 0.7855\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7803 - val_loss: 0.5185 - val_accuracy: 0.7815\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7886 - val_loss: 0.5183 - val_accuracy: 0.7830\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7851 - val_loss: 0.5154 - val_accuracy: 0.7840\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7826 - val_loss: 0.5165 - val_accuracy: 0.7820\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7803 - val_loss: 0.5153 - val_accuracy: 0.7835\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7855 - val_loss: 0.5119 - val_accuracy: 0.7855\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7905\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7851 - val_loss: 0.5135 - val_accuracy: 0.7850\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7811 - val_loss: 0.5174 - val_accuracy: 0.7850\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7818 - val_loss: 0.5228 - val_accuracy: 0.7865\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7843 - val_loss: 0.5147 - val_accuracy: 0.7875\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7872 - val_loss: 0.5126 - val_accuracy: 0.7865\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7791 - val_loss: 0.5108 - val_accuracy: 0.7855\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7846 - val_loss: 0.5130 - val_accuracy: 0.7870\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7837 - val_loss: 0.5222 - val_accuracy: 0.7835\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7864 - val_loss: 0.5161 - val_accuracy: 0.7810\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7834 - val_loss: 0.5169 - val_accuracy: 0.7850\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7850 - val_loss: 0.5157 - val_accuracy: 0.7805\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7846 - val_loss: 0.5151 - val_accuracy: 0.7835\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7894 - val_loss: 0.5116 - val_accuracy: 0.7860\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7824 - val_loss: 0.5141 - val_accuracy: 0.7860\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7828 - val_loss: 0.5201 - val_accuracy: 0.7845\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7872 - val_loss: 0.5126 - val_accuracy: 0.7885\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7918 - val_loss: 0.5142 - val_accuracy: 0.7870\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7843 - val_loss: 0.5125 - val_accuracy: 0.7835\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7855 - val_loss: 0.5176 - val_accuracy: 0.7870\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7854 - val_loss: 0.5135 - val_accuracy: 0.7850\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7865 - val_loss: 0.5181 - val_accuracy: 0.7835\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7843 - val_loss: 0.5149 - val_accuracy: 0.7845\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7904 - val_loss: 0.5137 - val_accuracy: 0.7875\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7850 - val_loss: 0.5150 - val_accuracy: 0.7845\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7872 - val_loss: 0.5152 - val_accuracy: 0.7845\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7845 - val_loss: 0.5185 - val_accuracy: 0.7810\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7854 - val_loss: 0.5191 - val_accuracy: 0.7850\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7820 - val_loss: 0.5142 - val_accuracy: 0.7855\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7870 - val_loss: 0.5132 - val_accuracy: 0.7825\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7916 - val_loss: 0.5121 - val_accuracy: 0.7815\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7889 - val_loss: 0.5163 - val_accuracy: 0.7835\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7890 - val_loss: 0.5135 - val_accuracy: 0.7840\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7883 - val_loss: 0.5265 - val_accuracy: 0.7845\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7869 - val_loss: 0.5131 - val_accuracy: 0.7865\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7871 - val_loss: 0.5128 - val_accuracy: 0.7860\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7883 - val_loss: 0.5172 - val_accuracy: 0.7860\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7886 - val_loss: 0.5113 - val_accuracy: 0.7860\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7870 - val_loss: 0.5231 - val_accuracy: 0.7845\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7820\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7866 - val_loss: 0.5136 - val_accuracy: 0.7825\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7915 - val_loss: 0.5159 - val_accuracy: 0.7840\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7878 - val_loss: 0.5117 - val_accuracy: 0.7865\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7884 - val_loss: 0.5118 - val_accuracy: 0.7865\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7872 - val_loss: 0.5151 - val_accuracy: 0.7875\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7846 - val_loss: 0.5201 - val_accuracy: 0.7855\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7899 - val_loss: 0.5131 - val_accuracy: 0.7845\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7906 - val_loss: 0.5149 - val_accuracy: 0.7845\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7869 - val_loss: 0.5111 - val_accuracy: 0.7805\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7885 - val_loss: 0.5126 - val_accuracy: 0.7870\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7871 - val_loss: 0.5186 - val_accuracy: 0.7815\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7843 - val_loss: 0.5184 - val_accuracy: 0.7860\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7850 - val_loss: 0.5160 - val_accuracy: 0.7895\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7916 - val_loss: 0.5160 - val_accuracy: 0.7825\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7868 - val_loss: 0.5148 - val_accuracy: 0.7890\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7901 - val_loss: 0.5154 - val_accuracy: 0.7840\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7853 - val_loss: 0.5110 - val_accuracy: 0.7880\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7929 - val_loss: 0.5133 - val_accuracy: 0.7885\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7893 - val_loss: 0.5166 - val_accuracy: 0.7850\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7891 - val_loss: 0.5181 - val_accuracy: 0.7850\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7879 - val_loss: 0.5118 - val_accuracy: 0.7845\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7906 - val_loss: 0.5212 - val_accuracy: 0.7835\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7881 - val_loss: 0.5129 - val_accuracy: 0.7855\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7901 - val_loss: 0.5189 - val_accuracy: 0.7855\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7918 - val_loss: 0.5147 - val_accuracy: 0.7850\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7909 - val_loss: 0.5176 - val_accuracy: 0.7870\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 50, 8)             96        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_12 (Averag (None, 10, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 4, 5)              285       \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 624\n",
      "Trainable params: 624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "ini = initializers.RandomNormal(mean=0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 8, kernel_size = 11,\n",
    "                 kernel_regularizer = reg,\n",
    "                 kernel_initializer = ini,\n",
    "                 bias_regularizer = reg,\n",
    "                 bias_initializer = ini,\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape \n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Conv1D(filters = 5, kernel_size = 7, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation = 'softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "from keras import optimizers\n",
    "opt = optimizers.SGD(lr = 0.01, momentum = 0.9, nesterov = True, decay = 1e-6)\n",
    "model.compile(loss =keras.losses.categorical_crossentropy, \n",
    "             optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1006 - accuracy: 0.3251 - val_loss: 1.0976 - val_accuracy: 0.3610\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0966 - accuracy: 0.3744 - val_loss: 1.0935 - val_accuracy: 0.4030\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0928 - accuracy: 0.3849 - val_loss: 1.0854 - val_accuracy: 0.4020\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0825 - accuracy: 0.3936 - val_loss: 1.0657 - val_accuracy: 0.4370\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0609 - accuracy: 0.4214 - val_loss: 1.0370 - val_accuracy: 0.4705\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0330 - accuracy: 0.4454 - val_loss: 1.0068 - val_accuracy: 0.4865\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0127 - accuracy: 0.4614 - val_loss: 0.9846 - val_accuracy: 0.4855\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9825 - accuracy: 0.4816 - val_loss: 0.9711 - val_accuracy: 0.4990\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9735 - accuracy: 0.4880 - val_loss: 0.9563 - val_accuracy: 0.5030\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9667 - accuracy: 0.4878 - val_loss: 0.9395 - val_accuracy: 0.5145\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9506 - accuracy: 0.4930 - val_loss: 0.9291 - val_accuracy: 0.5115\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9353 - accuracy: 0.5048 - val_loss: 0.9149 - val_accuracy: 0.5145\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9240 - accuracy: 0.5136 - val_loss: 0.9058 - val_accuracy: 0.5355\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9164 - accuracy: 0.5078 - val_loss: 0.8922 - val_accuracy: 0.5325\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9105 - accuracy: 0.5195 - val_loss: 0.8803 - val_accuracy: 0.5385\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8966 - accuracy: 0.5328 - val_loss: 0.8720 - val_accuracy: 0.5490\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8756 - accuracy: 0.5489 - val_loss: 0.8646 - val_accuracy: 0.5405\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8645 - accuracy: 0.5510 - val_loss: 0.8542 - val_accuracy: 0.5465\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8620 - accuracy: 0.5487 - val_loss: 0.8488 - val_accuracy: 0.5490\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8601 - accuracy: 0.5393 - val_loss: 0.8407 - val_accuracy: 0.5425\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.5531 - val_loss: 0.8311 - val_accuracy: 0.5450\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.5547 - val_loss: 0.8247 - val_accuracy: 0.5545\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8331 - accuracy: 0.5594 - val_loss: 0.8291 - val_accuracy: 0.5475\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.5557 - val_loss: 0.8171 - val_accuracy: 0.5525\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8249 - accuracy: 0.5605 - val_loss: 0.8187 - val_accuracy: 0.5520\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8248 - accuracy: 0.5564 - val_loss: 0.8136 - val_accuracy: 0.5530\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.5657 - val_loss: 0.8096 - val_accuracy: 0.5545\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8102 - accuracy: 0.5634 - val_loss: 0.8064 - val_accuracy: 0.5610\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7979 - accuracy: 0.5756 - val_loss: 0.8034 - val_accuracy: 0.5635\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7986 - accuracy: 0.5735 - val_loss: 0.7980 - val_accuracy: 0.5695\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8014 - accuracy: 0.5764 - val_loss: 0.8131 - val_accuracy: 0.5515\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8055 - accuracy: 0.5618 - val_loss: 0.7982 - val_accuracy: 0.5705\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.5776 - val_loss: 0.7921 - val_accuracy: 0.5695\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.5818 - val_loss: 0.7924 - val_accuracy: 0.5685\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.5886 - val_loss: 0.7902 - val_accuracy: 0.5645\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7723 - accuracy: 0.5936 - val_loss: 0.7951 - val_accuracy: 0.5710\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7811 - accuracy: 0.5716 - val_loss: 0.7892 - val_accuracy: 0.5735\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7809 - accuracy: 0.5754 - val_loss: 0.7870 - val_accuracy: 0.5660\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7767 - accuracy: 0.5836 - val_loss: 0.7847 - val_accuracy: 0.5705\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7684 - accuracy: 0.5942 - val_loss: 0.7814 - val_accuracy: 0.5735\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7675 - accuracy: 0.5853 - val_loss: 0.7801 - val_accuracy: 0.5710\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7597 - accuracy: 0.5919 - val_loss: 0.7817 - val_accuracy: 0.5710\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7669 - accuracy: 0.5823 - val_loss: 0.7788 - val_accuracy: 0.5675\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.5897 - val_loss: 0.7769 - val_accuracy: 0.5755\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7647 - accuracy: 0.5901 - val_loss: 0.7717 - val_accuracy: 0.5820\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.6008 - val_loss: 0.7734 - val_accuracy: 0.5865\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7633 - accuracy: 0.5895 - val_loss: 0.7705 - val_accuracy: 0.5845\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7747 - accuracy: 0.5837 - val_loss: 0.7708 - val_accuracy: 0.5910\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.5921 - val_loss: 0.7643 - val_accuracy: 0.5875\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7609 - accuracy: 0.5911 - val_loss: 0.7637 - val_accuracy: 0.5860\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.5996 - val_loss: 0.7612 - val_accuracy: 0.5885\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.6005 - val_loss: 0.7609 - val_accuracy: 0.5930\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.5988 - val_loss: 0.7589 - val_accuracy: 0.5865\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.5946 - val_loss: 0.7557 - val_accuracy: 0.5900\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.6072 - val_loss: 0.7540 - val_accuracy: 0.5885\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.6077 - val_loss: 0.7540 - val_accuracy: 0.5965\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.6042 - val_loss: 0.7575 - val_accuracy: 0.5940\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.6091 - val_loss: 0.7468 - val_accuracy: 0.5895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.6026 - val_loss: 0.7472 - val_accuracy: 0.6040\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.6064 - val_loss: 0.7488 - val_accuracy: 0.6035\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7337 - accuracy: 0.6131 - val_loss: 0.7431 - val_accuracy: 0.6150\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.6108 - val_loss: 0.7390 - val_accuracy: 0.6090\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7251 - accuracy: 0.6229 - val_loss: 0.7350 - val_accuracy: 0.6130\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7209 - accuracy: 0.6189 - val_loss: 0.7330 - val_accuracy: 0.6145\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7192 - accuracy: 0.6210 - val_loss: 0.7338 - val_accuracy: 0.6255\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.6243 - val_loss: 0.7294 - val_accuracy: 0.6220\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7240 - accuracy: 0.6261 - val_loss: 0.7291 - val_accuracy: 0.6230\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7224 - accuracy: 0.6215 - val_loss: 0.7181 - val_accuracy: 0.6395\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7102 - accuracy: 0.6399 - val_loss: 0.7186 - val_accuracy: 0.6430\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.6329 - val_loss: 0.7180 - val_accuracy: 0.6455\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.6402 - val_loss: 0.7144 - val_accuracy: 0.6355\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.6409 - val_loss: 0.7091 - val_accuracy: 0.6500\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.6484 - val_loss: 0.7039 - val_accuracy: 0.6485\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.6521 - val_loss: 0.7001 - val_accuracy: 0.6485\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.6391 - val_loss: 0.6998 - val_accuracy: 0.6565\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.6506 - val_loss: 0.7048 - val_accuracy: 0.6480\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.6504 - val_loss: 0.6950 - val_accuracy: 0.6555\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.6548 - val_loss: 0.6938 - val_accuracy: 0.6585\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6658 - val_loss: 0.6883 - val_accuracy: 0.6620\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.6663 - val_loss: 0.6808 - val_accuracy: 0.6650\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.6730 - val_loss: 0.6835 - val_accuracy: 0.6670\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6734 - val_loss: 0.6776 - val_accuracy: 0.6695\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6719 - val_loss: 0.6752 - val_accuracy: 0.6695\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6733 - val_loss: 0.6872 - val_accuracy: 0.6720\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6711 - val_loss: 0.6770 - val_accuracy: 0.6800\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6760 - val_loss: 0.6676 - val_accuracy: 0.6780\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.6760 - val_loss: 0.6677 - val_accuracy: 0.6750\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6840 - val_loss: 0.6622 - val_accuracy: 0.6775\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.6694 - val_loss: 0.6718 - val_accuracy: 0.6760\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6716 - val_loss: 0.6644 - val_accuracy: 0.6825\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.6887 - val_loss: 0.6637 - val_accuracy: 0.6820\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.6842 - val_loss: 0.6578 - val_accuracy: 0.6875\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6856 - val_loss: 0.6569 - val_accuracy: 0.6890\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6881 - val_loss: 0.6602 - val_accuracy: 0.6880\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6828 - val_loss: 0.6539 - val_accuracy: 0.6915\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6919 - val_loss: 0.6528 - val_accuracy: 0.6920\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6881 - val_loss: 0.6506 - val_accuracy: 0.6910\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6847 - val_loss: 0.6502 - val_accuracy: 0.6900\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6861 - val_loss: 0.6456 - val_accuracy: 0.6955\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6940 - val_loss: 0.6495 - val_accuracy: 0.6960\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.7001 - val_loss: 0.6461 - val_accuracy: 0.6950\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6961 - val_loss: 0.6457 - val_accuracy: 0.6950\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7001 - val_loss: 0.6512 - val_accuracy: 0.6940\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6942 - val_loss: 0.6453 - val_accuracy: 0.6945\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6978 - val_loss: 0.6495 - val_accuracy: 0.6920\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7034 - val_loss: 0.6419 - val_accuracy: 0.7010\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6999 - val_loss: 0.6383 - val_accuracy: 0.7005\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7005 - val_loss: 0.6404 - val_accuracy: 0.6995\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7032 - val_loss: 0.6385 - val_accuracy: 0.6950\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6967 - val_loss: 0.6349 - val_accuracy: 0.7020\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7028 - val_loss: 0.6561 - val_accuracy: 0.6875\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7042 - val_loss: 0.6359 - val_accuracy: 0.7025\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7005 - val_loss: 0.6338 - val_accuracy: 0.7040\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7026 - val_loss: 0.6337 - val_accuracy: 0.7070\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7084 - val_loss: 0.6440 - val_accuracy: 0.6960\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6982 - val_loss: 0.6331 - val_accuracy: 0.7070\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7038 - val_loss: 0.6365 - val_accuracy: 0.7000\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6988 - val_loss: 0.6338 - val_accuracy: 0.7030\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6922 - val_loss: 0.6315 - val_accuracy: 0.7065\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7026 - val_loss: 0.6304 - val_accuracy: 0.7120\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7016 - val_loss: 0.6347 - val_accuracy: 0.6990\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7035 - val_loss: 0.6354 - val_accuracy: 0.6950\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7019 - val_loss: 0.6313 - val_accuracy: 0.7075\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7020 - val_loss: 0.6309 - val_accuracy: 0.7030\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7057 - val_loss: 0.6302 - val_accuracy: 0.7045\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7002 - val_loss: 0.6330 - val_accuracy: 0.6995\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7049 - val_loss: 0.6281 - val_accuracy: 0.7140\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6993 - val_loss: 0.6373 - val_accuracy: 0.7050\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7097 - val_loss: 0.6262 - val_accuracy: 0.7095\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.7120 - val_loss: 0.6262 - val_accuracy: 0.7145\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7009 - val_loss: 0.6251 - val_accuracy: 0.7135\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.7158 - val_loss: 0.6346 - val_accuracy: 0.7000\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7067 - val_loss: 0.6415 - val_accuracy: 0.6990\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7033 - val_loss: 0.6220 - val_accuracy: 0.7160\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7072 - val_loss: 0.6244 - val_accuracy: 0.7145\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7151 - val_loss: 0.6258 - val_accuracy: 0.7055\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7158 - val_loss: 0.6275 - val_accuracy: 0.7105\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7076 - val_loss: 0.6226 - val_accuracy: 0.7170\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.7075 - val_loss: 0.6221 - val_accuracy: 0.7125\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7020 - val_loss: 0.6240 - val_accuracy: 0.7115\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.7067 - val_loss: 0.6241 - val_accuracy: 0.7155\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7123 - val_loss: 0.6195 - val_accuracy: 0.7180\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7059 - val_loss: 0.6200 - val_accuracy: 0.7160\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7097 - val_loss: 0.6197 - val_accuracy: 0.7170\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7125 - val_loss: 0.6202 - val_accuracy: 0.7135\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7039 - val_loss: 0.6232 - val_accuracy: 0.7120\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7160 - val_loss: 0.6180 - val_accuracy: 0.7155\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7202 - val_loss: 0.6207 - val_accuracy: 0.7130\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7101 - val_loss: 0.6232 - val_accuracy: 0.7125\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7133 - val_loss: 0.6174 - val_accuracy: 0.7160\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.7217 - val_loss: 0.6188 - val_accuracy: 0.7165\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7191 - val_loss: 0.6200 - val_accuracy: 0.7130\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7178 - val_loss: 0.6125 - val_accuracy: 0.7185\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7110 - val_loss: 0.6141 - val_accuracy: 0.7220\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7255 - val_loss: 0.6168 - val_accuracy: 0.7185\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7119 - val_loss: 0.6135 - val_accuracy: 0.7195\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7168 - val_loss: 0.6133 - val_accuracy: 0.7210\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7169 - val_loss: 0.6129 - val_accuracy: 0.7180\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7178 - val_loss: 0.6124 - val_accuracy: 0.7230\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.7233 - val_loss: 0.6091 - val_accuracy: 0.7175\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.7135 - val_loss: 0.6110 - val_accuracy: 0.7170\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7205 - val_loss: 0.6116 - val_accuracy: 0.7220\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7279 - val_loss: 0.6102 - val_accuracy: 0.7220\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.7144 - val_loss: 0.6229 - val_accuracy: 0.7125\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7168 - val_loss: 0.6081 - val_accuracy: 0.7215\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.7246 - val_loss: 0.6120 - val_accuracy: 0.7170\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7104 - val_loss: 0.6089 - val_accuracy: 0.7200\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7162 - val_loss: 0.6081 - val_accuracy: 0.7200\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7193 - val_loss: 0.6093 - val_accuracy: 0.7200\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7202 - val_loss: 0.6071 - val_accuracy: 0.7200\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7169 - val_loss: 0.6101 - val_accuracy: 0.7215\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7226 - val_loss: 0.6099 - val_accuracy: 0.7235\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.7193 - val_loss: 0.6202 - val_accuracy: 0.7065\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7249 - val_loss: 0.6071 - val_accuracy: 0.7200\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7227 - val_loss: 0.6132 - val_accuracy: 0.7190\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.7181 - val_loss: 0.6053 - val_accuracy: 0.7230\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7239 - val_loss: 0.6053 - val_accuracy: 0.7265\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7228 - val_loss: 0.6063 - val_accuracy: 0.7220\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7213 - val_loss: 0.6039 - val_accuracy: 0.7200\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.7254 - val_loss: 0.6057 - val_accuracy: 0.7215\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7271 - val_loss: 0.6040 - val_accuracy: 0.7250\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7183 - val_loss: 0.6112 - val_accuracy: 0.7230\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.7219 - val_loss: 0.6015 - val_accuracy: 0.7230\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7341 - val_loss: 0.6060 - val_accuracy: 0.7255\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7176 - val_loss: 0.6020 - val_accuracy: 0.7230\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7250 - val_loss: 0.6015 - val_accuracy: 0.7205\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7304 - val_loss: 0.6050 - val_accuracy: 0.7290\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7328 - val_loss: 0.6004 - val_accuracy: 0.7315\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7370 - val_loss: 0.6073 - val_accuracy: 0.7310\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7371 - val_loss: 0.6010 - val_accuracy: 0.7215\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7343 - val_loss: 0.6016 - val_accuracy: 0.7255\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7235 - val_loss: 0.6004 - val_accuracy: 0.7260\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7274 - val_loss: 0.6015 - val_accuracy: 0.7250\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7214 - val_loss: 0.6065 - val_accuracy: 0.7210\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.7228 - val_loss: 0.6011 - val_accuracy: 0.7290\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7232 - val_loss: 0.5983 - val_accuracy: 0.7260\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7261 - val_loss: 0.5992 - val_accuracy: 0.7290\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7265 - val_loss: 0.5971 - val_accuracy: 0.7265\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7235 - val_loss: 0.6003 - val_accuracy: 0.7260\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7200 - val_loss: 0.5999 - val_accuracy: 0.7315\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7351 - val_loss: 0.5996 - val_accuracy: 0.7240\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7307 - val_loss: 0.5983 - val_accuracy: 0.7325\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7312 - val_loss: 0.6010 - val_accuracy: 0.7270\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7327 - val_loss: 0.5991 - val_accuracy: 0.7245\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7318 - val_loss: 0.6012 - val_accuracy: 0.7245\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7312 - val_loss: 0.6054 - val_accuracy: 0.7245\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7258 - val_loss: 0.5999 - val_accuracy: 0.7285\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7387 - val_loss: 0.5961 - val_accuracy: 0.7315\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7347 - val_loss: 0.5940 - val_accuracy: 0.7265\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7307 - val_loss: 0.5962 - val_accuracy: 0.7310\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7265 - val_loss: 0.5947 - val_accuracy: 0.7300\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7342 - val_loss: 0.6022 - val_accuracy: 0.7280\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7294 - val_loss: 0.5975 - val_accuracy: 0.7295\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.7395 - val_loss: 0.5968 - val_accuracy: 0.7290\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7260 - val_loss: 0.5988 - val_accuracy: 0.7320\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7288 - val_loss: 0.5946 - val_accuracy: 0.7270\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7311 - val_loss: 0.5991 - val_accuracy: 0.7280\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7401 - val_loss: 0.5930 - val_accuracy: 0.7325\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7373 - val_loss: 0.6020 - val_accuracy: 0.7240\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.7327 - val_loss: 0.5988 - val_accuracy: 0.7220\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7371 - val_loss: 0.5915 - val_accuracy: 0.7345\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7266 - val_loss: 0.5909 - val_accuracy: 0.7355\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7332 - val_loss: 0.5932 - val_accuracy: 0.7360\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7202 - val_loss: 0.5958 - val_accuracy: 0.7260\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7356 - val_loss: 0.5935 - val_accuracy: 0.7290\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7407 - val_loss: 0.5984 - val_accuracy: 0.7275\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7286 - val_loss: 0.5943 - val_accuracy: 0.7305\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7319 - val_loss: 0.5893 - val_accuracy: 0.7325\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7427 - val_loss: 0.5904 - val_accuracy: 0.7315\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7338 - val_loss: 0.5904 - val_accuracy: 0.7340\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7405 - val_loss: 0.5928 - val_accuracy: 0.7325\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7453 - val_loss: 0.5915 - val_accuracy: 0.7315\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7388 - val_loss: 0.5913 - val_accuracy: 0.7315\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7327 - val_loss: 0.5896 - val_accuracy: 0.7320\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7325 - val_loss: 0.5889 - val_accuracy: 0.7370\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7390 - val_loss: 0.5869 - val_accuracy: 0.7350\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7364 - val_loss: 0.5989 - val_accuracy: 0.7275\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7374 - val_loss: 0.5909 - val_accuracy: 0.7305\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7378 - val_loss: 0.5894 - val_accuracy: 0.7295\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7417 - val_loss: 0.5953 - val_accuracy: 0.7305\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7389 - val_loss: 0.5924 - val_accuracy: 0.7300\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7435 - val_loss: 0.5910 - val_accuracy: 0.7330\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7378 - val_loss: 0.5864 - val_accuracy: 0.7335\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7308 - val_loss: 0.5925 - val_accuracy: 0.7320\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7429 - val_loss: 0.5890 - val_accuracy: 0.7325\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7345 - val_loss: 0.5896 - val_accuracy: 0.7315\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7410 - val_loss: 0.6000 - val_accuracy: 0.7285\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7372 - val_loss: 0.5841 - val_accuracy: 0.7385\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.7391 - val_loss: 0.5880 - val_accuracy: 0.7370\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7436 - val_loss: 0.5881 - val_accuracy: 0.7320\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 50, 8)             96        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_14 (Averag (None, 10, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 4, 5)              285       \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 624\n",
      "Trainable params: 624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "ini = initializers.RandomNormal(mean=0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 8, kernel_size = 11,\n",
    "                 kernel_regularizer = reg,\n",
    "                 kernel_initializer = ini,\n",
    "                 activity_regularizer = reg,\n",
    "                 activation = 'relu',\n",
    "                 input_shape = input_shape \n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Conv1D(filters = 5, kernel_size = 7, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation = 'softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "from keras import optimizers\n",
    "opt = optimizers.SGD(lr = 0.01, momentum = 0.9, nesterov = True, decay = 1e-6)\n",
    "model.compile(loss =keras.losses.categorical_crossentropy, \n",
    "             optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.1016 - accuracy: 0.3263 - val_loss: 1.0979 - val_accuracy: 0.3670\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0966 - accuracy: 0.3715 - val_loss: 1.0933 - val_accuracy: 0.3660\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0882 - accuracy: 0.3820 - val_loss: 1.0845 - val_accuracy: 0.4215\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0773 - accuracy: 0.4178 - val_loss: 1.0680 - val_accuracy: 0.4555\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0571 - accuracy: 0.4538 - val_loss: 1.0410 - val_accuracy: 0.4365\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0292 - accuracy: 0.4638 - val_loss: 1.0015 - val_accuracy: 0.4920\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9883 - accuracy: 0.5024 - val_loss: 0.9523 - val_accuracy: 0.5195\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9361 - accuracy: 0.5243 - val_loss: 0.8939 - val_accuracy: 0.5360\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8799 - accuracy: 0.5581 - val_loss: 0.8532 - val_accuracy: 0.5460\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8591 - accuracy: 0.5518 - val_loss: 0.8328 - val_accuracy: 0.5565\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.5656 - val_loss: 0.7961 - val_accuracy: 0.5780\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8064 - accuracy: 0.5791 - val_loss: 0.7777 - val_accuracy: 0.6020\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7822 - accuracy: 0.5958 - val_loss: 0.7659 - val_accuracy: 0.6140\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7722 - accuracy: 0.5937 - val_loss: 0.7679 - val_accuracy: 0.5970\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7674 - accuracy: 0.5940 - val_loss: 0.7391 - val_accuracy: 0.6320\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.6160 - val_loss: 0.7307 - val_accuracy: 0.6430\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.6204 - val_loss: 0.7195 - val_accuracy: 0.6460\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7140 - accuracy: 0.6470 - val_loss: 0.7108 - val_accuracy: 0.6530\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.6520 - val_loss: 0.7038 - val_accuracy: 0.6580\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.6485 - val_loss: 0.6933 - val_accuracy: 0.6595\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.6645 - val_loss: 0.6894 - val_accuracy: 0.6665\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.6524 - val_loss: 0.6873 - val_accuracy: 0.6655\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6675 - val_loss: 0.6811 - val_accuracy: 0.6820\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.6703 - val_loss: 0.6785 - val_accuracy: 0.6745\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.6610 - val_loss: 0.6768 - val_accuracy: 0.6765\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.6767 - val_loss: 0.6719 - val_accuracy: 0.6840\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6669 - val_loss: 0.6685 - val_accuracy: 0.6840\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.6760 - val_loss: 0.6637 - val_accuracy: 0.6910\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.6764 - val_loss: 0.6582 - val_accuracy: 0.6910\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.6717 - val_loss: 0.6615 - val_accuracy: 0.6855\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6783 - val_loss: 0.6640 - val_accuracy: 0.6810\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6886 - val_loss: 0.6547 - val_accuracy: 0.6900\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6861 - val_loss: 0.6501 - val_accuracy: 0.6960\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6830 - val_loss: 0.6464 - val_accuracy: 0.6980\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6849 - val_loss: 0.6464 - val_accuracy: 0.6980\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6989 - val_loss: 0.6511 - val_accuracy: 0.6880\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6952 - val_loss: 0.6494 - val_accuracy: 0.6945\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6841 - val_loss: 0.6373 - val_accuracy: 0.7065\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6905 - val_loss: 0.6430 - val_accuracy: 0.6955\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6870 - val_loss: 0.6385 - val_accuracy: 0.7030\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7049 - val_loss: 0.6330 - val_accuracy: 0.7020\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6895 - val_loss: 0.6351 - val_accuracy: 0.7035\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.7066 - val_loss: 0.6302 - val_accuracy: 0.7080\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7023 - val_loss: 0.6281 - val_accuracy: 0.7030\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6999 - val_loss: 0.6272 - val_accuracy: 0.7110\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6984 - val_loss: 0.6261 - val_accuracy: 0.7065\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7112 - val_loss: 0.6238 - val_accuracy: 0.7120\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7021 - val_loss: 0.6220 - val_accuracy: 0.7135\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6996 - val_loss: 0.6194 - val_accuracy: 0.7185\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.7096 - val_loss: 0.6196 - val_accuracy: 0.7165\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.7098 - val_loss: 0.6233 - val_accuracy: 0.7120\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7140 - val_loss: 0.6209 - val_accuracy: 0.7175\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7007 - val_loss: 0.6199 - val_accuracy: 0.7110\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7143 - val_loss: 0.6221 - val_accuracy: 0.7150\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7141 - val_loss: 0.6107 - val_accuracy: 0.7280\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7062 - val_loss: 0.6114 - val_accuracy: 0.7255\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7111 - val_loss: 0.6114 - val_accuracy: 0.7255\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7094 - val_loss: 0.6317 - val_accuracy: 0.7060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6934 - val_loss: 0.6102 - val_accuracy: 0.7310\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7094 - val_loss: 0.6053 - val_accuracy: 0.7250\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.7162 - val_loss: 0.6067 - val_accuracy: 0.7265\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7211 - val_loss: 0.6084 - val_accuracy: 0.7200\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7099 - val_loss: 0.6067 - val_accuracy: 0.7300\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7214 - val_loss: 0.6033 - val_accuracy: 0.7305\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7231 - val_loss: 0.6055 - val_accuracy: 0.7250\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.7095 - val_loss: 0.6049 - val_accuracy: 0.7245\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.7131 - val_loss: 0.5996 - val_accuracy: 0.7315\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7172 - val_loss: 0.5994 - val_accuracy: 0.7325\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7215 - val_loss: 0.5972 - val_accuracy: 0.7355\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7247 - val_loss: 0.5963 - val_accuracy: 0.7335\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7156 - val_loss: 0.5922 - val_accuracy: 0.7355\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.7217 - val_loss: 0.6023 - val_accuracy: 0.7290\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7160 - val_loss: 0.5931 - val_accuracy: 0.7385\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7264 - val_loss: 0.5898 - val_accuracy: 0.7430\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.7331 - val_loss: 0.5867 - val_accuracy: 0.7415\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7250 - val_loss: 0.5889 - val_accuracy: 0.7390\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7313 - val_loss: 0.5842 - val_accuracy: 0.7470\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7265 - val_loss: 0.5877 - val_accuracy: 0.7410\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7237 - val_loss: 0.5821 - val_accuracy: 0.7470\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7446 - val_loss: 0.5794 - val_accuracy: 0.7405\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.7303 - val_loss: 0.5811 - val_accuracy: 0.7410\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7268 - val_loss: 0.5853 - val_accuracy: 0.7425\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.7387 - val_loss: 0.5813 - val_accuracy: 0.7490\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7348 - val_loss: 0.5777 - val_accuracy: 0.7470\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7251 - val_loss: 0.5804 - val_accuracy: 0.7490\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7335 - val_loss: 0.5747 - val_accuracy: 0.7490\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7459 - val_loss: 0.5705 - val_accuracy: 0.7425\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7490 - val_loss: 0.5692 - val_accuracy: 0.7505\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7489 - val_loss: 0.5709 - val_accuracy: 0.7485\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7375 - val_loss: 0.5732 - val_accuracy: 0.7495\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7388 - val_loss: 0.5669 - val_accuracy: 0.7510\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7432 - val_loss: 0.5663 - val_accuracy: 0.7565\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7434 - val_loss: 0.5625 - val_accuracy: 0.7570\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7461 - val_loss: 0.5678 - val_accuracy: 0.7495\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7470 - val_loss: 0.5648 - val_accuracy: 0.7580\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7376 - val_loss: 0.5643 - val_accuracy: 0.7600\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7381 - val_loss: 0.5639 - val_accuracy: 0.7525\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7446 - val_loss: 0.5605 - val_accuracy: 0.7590\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7415 - val_loss: 0.5606 - val_accuracy: 0.7645\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7522 - val_loss: 0.5533 - val_accuracy: 0.7625\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7504 - val_loss: 0.5544 - val_accuracy: 0.7660\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7454 - val_loss: 0.5586 - val_accuracy: 0.7630\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7530 - val_loss: 0.5528 - val_accuracy: 0.7710\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7619 - val_loss: 0.5732 - val_accuracy: 0.7445\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7489 - val_loss: 0.5557 - val_accuracy: 0.7585\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7639 - val_loss: 0.5521 - val_accuracy: 0.7700\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7511 - val_loss: 0.5470 - val_accuracy: 0.7640\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7595 - val_loss: 0.5523 - val_accuracy: 0.7720\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7601 - val_loss: 0.5486 - val_accuracy: 0.7705\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7540 - val_loss: 0.5417 - val_accuracy: 0.7660\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7565 - val_loss: 0.5471 - val_accuracy: 0.7705\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7654 - val_loss: 0.5435 - val_accuracy: 0.7725\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7532 - val_loss: 0.5392 - val_accuracy: 0.7740\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7672 - val_loss: 0.5608 - val_accuracy: 0.7575\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7603 - val_loss: 0.5394 - val_accuracy: 0.7715\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7604 - val_loss: 0.5498 - val_accuracy: 0.7625\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7675 - val_loss: 0.5398 - val_accuracy: 0.7675\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7657 - val_loss: 0.5390 - val_accuracy: 0.7730\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7739 - val_loss: 0.5329 - val_accuracy: 0.7805\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7749 - val_loss: 0.5379 - val_accuracy: 0.7750\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7698 - val_loss: 0.5333 - val_accuracy: 0.7845\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7704 - val_loss: 0.5330 - val_accuracy: 0.7760\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7747 - val_loss: 0.5357 - val_accuracy: 0.7735\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7695 - val_loss: 0.5332 - val_accuracy: 0.7735\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7702 - val_loss: 0.5402 - val_accuracy: 0.7815\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7769 - val_loss: 0.5290 - val_accuracy: 0.7770\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7787 - val_loss: 0.5414 - val_accuracy: 0.7820\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7651 - val_loss: 0.5291 - val_accuracy: 0.7770\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7698 - val_loss: 0.5338 - val_accuracy: 0.7875\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7706 - val_loss: 0.5254 - val_accuracy: 0.7765\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7679 - val_loss: 0.5342 - val_accuracy: 0.7820\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7709 - val_loss: 0.5239 - val_accuracy: 0.7795\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7652 - val_loss: 0.5341 - val_accuracy: 0.7725\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7698 - val_loss: 0.5278 - val_accuracy: 0.7785\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7763 - val_loss: 0.5251 - val_accuracy: 0.7805\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7723 - val_loss: 0.5244 - val_accuracy: 0.7755\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7751 - val_loss: 0.5265 - val_accuracy: 0.7845\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7730 - val_loss: 0.5237 - val_accuracy: 0.7765\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7821 - val_loss: 0.5266 - val_accuracy: 0.7860\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7754 - val_loss: 0.5236 - val_accuracy: 0.7835\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7799 - val_loss: 0.5237 - val_accuracy: 0.7800\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7813 - val_loss: 0.5278 - val_accuracy: 0.7790\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7797 - val_loss: 0.5229 - val_accuracy: 0.7775\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7722 - val_loss: 0.5246 - val_accuracy: 0.7745\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7767 - val_loss: 0.5316 - val_accuracy: 0.7740\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7785 - val_loss: 0.5201 - val_accuracy: 0.7900\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7863 - val_loss: 0.5291 - val_accuracy: 0.7770\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7837 - val_loss: 0.5205 - val_accuracy: 0.7780\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7761 - val_loss: 0.5246 - val_accuracy: 0.7740\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7810 - val_loss: 0.5205 - val_accuracy: 0.7860\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7865 - val_loss: 0.5162 - val_accuracy: 0.7860\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7915 - val_loss: 0.5244 - val_accuracy: 0.7750\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7842 - val_loss: 0.5199 - val_accuracy: 0.7845\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7850 - val_loss: 0.5226 - val_accuracy: 0.7805\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7896 - val_loss: 0.5202 - val_accuracy: 0.7845\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7839 - val_loss: 0.5191 - val_accuracy: 0.7820\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7806 - val_loss: 0.5220 - val_accuracy: 0.7845\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7807 - val_loss: 0.5221 - val_accuracy: 0.7815\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7891 - val_loss: 0.5187 - val_accuracy: 0.7800\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7856 - val_loss: 0.5141 - val_accuracy: 0.7865\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7864 - val_loss: 0.5165 - val_accuracy: 0.7820\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7771 - val_loss: 0.5221 - val_accuracy: 0.7765\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7818 - val_loss: 0.5180 - val_accuracy: 0.7855\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7862 - val_loss: 0.5290 - val_accuracy: 0.7675\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7855\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7881 - val_loss: 0.5154 - val_accuracy: 0.7840\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7830 - val_loss: 0.5144 - val_accuracy: 0.7845\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7892 - val_loss: 0.5138 - val_accuracy: 0.7850\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7855 - val_loss: 0.5229 - val_accuracy: 0.7905\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7873 - val_loss: 0.5154 - val_accuracy: 0.7850\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7728 - val_loss: 0.5189 - val_accuracy: 0.7820\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7892 - val_loss: 0.5207 - val_accuracy: 0.7770\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7805 - val_loss: 0.5205 - val_accuracy: 0.7850\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7814 - val_loss: 0.5198 - val_accuracy: 0.7835\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7827 - val_loss: 0.5151 - val_accuracy: 0.7880\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7930 - val_loss: 0.5177 - val_accuracy: 0.7875\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7878 - val_loss: 0.5147 - val_accuracy: 0.7895\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7745\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7850 - val_loss: 0.5124 - val_accuracy: 0.7900\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7787 - val_loss: 0.5180 - val_accuracy: 0.7910\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7900 - val_loss: 0.5203 - val_accuracy: 0.7765\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7750\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7844 - val_loss: 0.5142 - val_accuracy: 0.7855\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7822 - val_loss: 0.5189 - val_accuracy: 0.7850\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7836 - val_loss: 0.5191 - val_accuracy: 0.7855\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7715 - val_loss: 0.5124 - val_accuracy: 0.7860\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7883 - val_loss: 0.5202 - val_accuracy: 0.7870\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7902 - val_loss: 0.5142 - val_accuracy: 0.7815\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7900 - val_loss: 0.5209 - val_accuracy: 0.7830\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7892 - val_loss: 0.5165 - val_accuracy: 0.7900\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7871 - val_loss: 0.5148 - val_accuracy: 0.7835\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7913 - val_loss: 0.5181 - val_accuracy: 0.7820\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7919 - val_loss: 0.5129 - val_accuracy: 0.7830\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7905 - val_loss: 0.5123 - val_accuracy: 0.7825\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7885 - val_loss: 0.5221 - val_accuracy: 0.7835\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7828 - val_loss: 0.5159 - val_accuracy: 0.7825\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7890 - val_loss: 0.5134 - val_accuracy: 0.7825\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7836 - val_loss: 0.5141 - val_accuracy: 0.7875\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7888 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7888 - val_loss: 0.5137 - val_accuracy: 0.7950\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7789 - val_loss: 0.5209 - val_accuracy: 0.7865\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7890 - val_loss: 0.5130 - val_accuracy: 0.7795\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7939 - val_loss: 0.5179 - val_accuracy: 0.7860\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7832 - val_loss: 0.5143 - val_accuracy: 0.7900\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7800 - val_loss: 0.5218 - val_accuracy: 0.7870\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7826 - val_loss: 0.5158 - val_accuracy: 0.7785\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7866 - val_loss: 0.5286 - val_accuracy: 0.7710\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7996 - val_loss: 0.5202 - val_accuracy: 0.7780\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7866 - val_loss: 0.5186 - val_accuracy: 0.7865\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7819 - val_loss: 0.5179 - val_accuracy: 0.7800\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7882 - val_loss: 0.5156 - val_accuracy: 0.7825\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7884 - val_loss: 0.5130 - val_accuracy: 0.7890\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7898 - val_loss: 0.5151 - val_accuracy: 0.7795\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7837 - val_loss: 0.5115 - val_accuracy: 0.7810\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7857 - val_loss: 0.5229 - val_accuracy: 0.7730\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7864 - val_loss: 0.5141 - val_accuracy: 0.7870\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7960 - val_loss: 0.5159 - val_accuracy: 0.7855\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7966 - val_loss: 0.5186 - val_accuracy: 0.7840\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7913 - val_loss: 0.5171 - val_accuracy: 0.7775\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7845 - val_loss: 0.5252 - val_accuracy: 0.7710\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7867 - val_loss: 0.5119 - val_accuracy: 0.7860\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7941 - val_loss: 0.5138 - val_accuracy: 0.7935\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7885 - val_loss: 0.5134 - val_accuracy: 0.7870\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7958 - val_loss: 0.5159 - val_accuracy: 0.7870\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7885 - val_loss: 0.5228 - val_accuracy: 0.7975\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.7898 - val_loss: 0.5150 - val_accuracy: 0.7840\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7896 - val_loss: 0.5288 - val_accuracy: 0.7730\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7974 - val_loss: 0.5167 - val_accuracy: 0.7875\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7887 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7863 - val_loss: 0.5138 - val_accuracy: 0.7825\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7970 - val_loss: 0.5132 - val_accuracy: 0.7885\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7990 - val_loss: 0.5215 - val_accuracy: 0.7780\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7934 - val_loss: 0.5217 - val_accuracy: 0.7745\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7835\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7877 - val_loss: 0.5256 - val_accuracy: 0.7725\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7981 - val_loss: 0.5157 - val_accuracy: 0.7845\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7900 - val_loss: 0.5224 - val_accuracy: 0.7830\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7956 - val_loss: 0.5174 - val_accuracy: 0.7825\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7921 - val_loss: 0.5173 - val_accuracy: 0.7875\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7962 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7886 - val_loss: 0.5107 - val_accuracy: 0.7925\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7858 - val_loss: 0.5162 - val_accuracy: 0.7820\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7851 - val_loss: 0.5149 - val_accuracy: 0.7835\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7943 - val_loss: 0.5194 - val_accuracy: 0.7810\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7943 - val_loss: 0.5309 - val_accuracy: 0.7735\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.7869 - val_loss: 0.5141 - val_accuracy: 0.7825\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7970 - val_loss: 0.5173 - val_accuracy: 0.7790\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7850\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7941 - val_loss: 0.5129 - val_accuracy: 0.7825\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7879 - val_loss: 0.5162 - val_accuracy: 0.7830\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias regularization gives a worse result, while activity regularization final accuracy is similar to the simple weight regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=\"DATA/sequences16.csv\"\n",
    "sx, sy = np.loadtxt(fname,delimiter=',',\n",
    "                   usecols= (0,1), unpack=True, dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total samples 3000\n",
      "Lenght of a sample 16\n",
      "Sample: AAGGTCTGCCGGCCGA, label: 1\n",
      "\n",
      "data:3000\n",
      "train: 2100\n",
      "test: 900\n"
     ]
    }
   ],
   "source": [
    "N = len(sy)\n",
    "print(f\"Number of total samples {N}\")\n",
    "Ls = len(sx[0])\n",
    "print(f\"Lenght of a sample {Ls}\")\n",
    "\n",
    "print(f\"Sample: {sx[0]}, label: {sy[0]}\")\n",
    "\n",
    "perc_train = 0.7\n",
    "N_train = int(N*perc_train)\n",
    "N_test = N -N_train\n",
    "print(f'\\ndata:{N}\\ntrain: {N_train}\\ntest: {N_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding dictionary: {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n"
     ]
    }
   ],
   "source": [
    "Q = ['A', 'C', 'G', 'T']\n",
    "Nc=4\n",
    "onehc = {Q[i]: i for i in range(Nc)}\n",
    "print(f\"One-hot encoding dictionary: {onehc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion: One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product of lenght (16) and character possibilities (4): 64\n",
      "\n",
      "Original sequence:\n",
      " AAGGTCTGCCGGCCGA\n",
      "\n",
      "Encoded sequence:\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y = sy.astype(int)\n",
    "\n",
    "L = Ls*Nc\n",
    "print(f\"Product of lenght ({Ls}) and character possibilities ({Nc}): {L}\\n\")\n",
    "\n",
    "x= np.zeros((N,L))\n",
    "\n",
    "for n in range(N):\n",
    "    for i in range(Ls):\n",
    "        x[n][i*4 + onehc[sx[n][i]]] = 1\n",
    "print(f\"Original sequence:\\n {sx[0]}\\n\")\n",
    "print(f\"Encoded sequence:\\n {x[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/test - validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio between y_train labels sum and train samples: 0.24714285714285714\n",
      "Ratio between y_test  labels sum and test samples: 0.24444444444444444\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train) = (x[:N_train], y[:N_train])\n",
    "(x_test, y_test) = (x[N_train:], y[N_train:])\n",
    "print(f\"Ratio between y_train labels sum and train samples: {y_train.sum() / N_train}\")\n",
    "print(f\"Ratio between y_test  labels sum and test samples: {y_test.sum() / N_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow as tf \n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Block One\n",
    "    layers.Conv1D(filters=16, kernel_size=3, activation='relu', padding='same',\n",
    "                  input_shape=[16,4]),\n",
    "    layers.MaxPool1D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.Conv1D(filters=64, kernel_size=6, activation='relu', padding='same'),\n",
    "    layers.MaxPool1D(),\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train = x_train.reshape(2100, 16,4)\n",
    "new_x_test = x_test.reshape(900,16,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "9/9 [==============================] - 1s 43ms/step - loss: 0.7042 - accuracy: 0.5480 - val_loss: 0.6810 - val_accuracy: 0.7556\n",
      "Epoch 2/250\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6540 - accuracy: 0.7579 - val_loss: 0.5582 - val_accuracy: 0.7556\n",
      "Epoch 3/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5788 - accuracy: 0.7477 - val_loss: 0.5388 - val_accuracy: 0.7556\n",
      "Epoch 4/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5816 - accuracy: 0.7462 - val_loss: 0.5356 - val_accuracy: 0.7556\n",
      "Epoch 5/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5574 - accuracy: 0.7590 - val_loss: 0.5312 - val_accuracy: 0.7556\n",
      "Epoch 6/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5573 - accuracy: 0.7544 - val_loss: 0.5241 - val_accuracy: 0.7556\n",
      "Epoch 7/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5531 - accuracy: 0.7553 - val_loss: 0.5132 - val_accuracy: 0.7556\n",
      "Epoch 8/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5511 - accuracy: 0.7515 - val_loss: 0.5081 - val_accuracy: 0.7556\n",
      "Epoch 9/250\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5348 - accuracy: 0.7527 - val_loss: 0.4968 - val_accuracy: 0.7556\n",
      "Epoch 10/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5353 - accuracy: 0.7459 - val_loss: 0.4886 - val_accuracy: 0.7556\n",
      "Epoch 11/250\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5093 - accuracy: 0.7580 - val_loss: 0.4763 - val_accuracy: 0.7556\n",
      "Epoch 12/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4877 - accuracy: 0.7572 - val_loss: 0.4657 - val_accuracy: 0.7556\n",
      "Epoch 13/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4983 - accuracy: 0.7550 - val_loss: 0.4532 - val_accuracy: 0.7556\n",
      "Epoch 14/250\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4737 - accuracy: 0.7616 - val_loss: 0.4427 - val_accuracy: 0.7556\n",
      "Epoch 15/250\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.4741 - accuracy: 0.7539 - val_loss: 0.4279 - val_accuracy: 0.7556\n",
      "Epoch 16/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7564 - val_loss: 0.4137 - val_accuracy: 0.7589\n",
      "Epoch 17/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.7710 - val_loss: 0.3930 - val_accuracy: 0.8222\n",
      "Epoch 18/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8019 - val_loss: 0.3668 - val_accuracy: 0.8456\n",
      "Epoch 19/250\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.8162 - val_loss: 0.3386 - val_accuracy: 0.8533\n",
      "Epoch 20/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8418 - val_loss: 0.3133 - val_accuracy: 0.8689\n",
      "Epoch 21/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3451 - accuracy: 0.8488 - val_loss: 0.2925 - val_accuracy: 0.8844\n",
      "Epoch 22/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.8624 - val_loss: 0.2773 - val_accuracy: 0.8933\n",
      "Epoch 23/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3118 - accuracy: 0.8751 - val_loss: 0.2727 - val_accuracy: 0.9011\n",
      "Epoch 24/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2965 - accuracy: 0.8741 - val_loss: 0.2454 - val_accuracy: 0.9011\n",
      "Epoch 25/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3034 - accuracy: 0.8754 - val_loss: 0.2360 - val_accuracy: 0.9100\n",
      "Epoch 26/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2911 - accuracy: 0.8789 - val_loss: 0.2282 - val_accuracy: 0.9089\n",
      "Epoch 27/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2765 - accuracy: 0.8968 - val_loss: 0.2230 - val_accuracy: 0.9033\n",
      "Epoch 28/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.9027 - val_loss: 0.2097 - val_accuracy: 0.9233\n",
      "Epoch 29/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2605 - accuracy: 0.8927 - val_loss: 0.1999 - val_accuracy: 0.9244\n",
      "Epoch 30/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2536 - accuracy: 0.8933 - val_loss: 0.1960 - val_accuracy: 0.9211\n",
      "Epoch 31/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2402 - accuracy: 0.9050 - val_loss: 0.1837 - val_accuracy: 0.9244\n",
      "Epoch 32/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2165 - accuracy: 0.9273 - val_loss: 0.1747 - val_accuracy: 0.9356\n",
      "Epoch 33/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2182 - accuracy: 0.9178 - val_loss: 0.1712 - val_accuracy: 0.9300\n",
      "Epoch 34/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2183 - accuracy: 0.9398 - val_loss: 0.1676 - val_accuracy: 0.9322\n",
      "Epoch 35/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2039 - accuracy: 0.9434 - val_loss: 0.1598 - val_accuracy: 0.9422\n",
      "Epoch 36/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9484 - val_loss: 0.1544 - val_accuracy: 0.9411\n",
      "Epoch 37/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1875 - accuracy: 0.9641 - val_loss: 0.1467 - val_accuracy: 0.9411\n",
      "Epoch 38/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1951 - accuracy: 0.9560 - val_loss: 0.1502 - val_accuracy: 0.9444\n",
      "Epoch 39/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1754 - accuracy: 0.9637 - val_loss: 0.1383 - val_accuracy: 0.9422\n",
      "Epoch 40/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1707 - accuracy: 0.9551 - val_loss: 0.1384 - val_accuracy: 0.9500\n",
      "Epoch 41/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1765 - accuracy: 0.9562 - val_loss: 0.1518 - val_accuracy: 0.9333\n",
      "Epoch 42/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1786 - accuracy: 0.9574 - val_loss: 0.1371 - val_accuracy: 0.9478\n",
      "Epoch 43/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9690 - val_loss: 0.1264 - val_accuracy: 0.9522\n",
      "Epoch 44/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1552 - accuracy: 0.9666 - val_loss: 0.1218 - val_accuracy: 0.9489\n",
      "Epoch 45/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.9728 - val_loss: 0.1182 - val_accuracy: 0.9511\n",
      "Epoch 46/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9717 - val_loss: 0.1155 - val_accuracy: 0.9533\n",
      "Epoch 47/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9754 - val_loss: 0.1156 - val_accuracy: 0.9567\n",
      "Epoch 48/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9747 - val_loss: 0.1125 - val_accuracy: 0.9544\n",
      "Epoch 49/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1437 - accuracy: 0.9783 - val_loss: 0.1092 - val_accuracy: 0.9567\n",
      "Epoch 50/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.9768 - val_loss: 0.1066 - val_accuracy: 0.9578\n",
      "Epoch 51/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9764 - val_loss: 0.1126 - val_accuracy: 0.9544\n",
      "Epoch 52/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9810 - val_loss: 0.1129 - val_accuracy: 0.9533\n",
      "Epoch 53/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.9746 - val_loss: 0.1065 - val_accuracy: 0.9578\n",
      "Epoch 54/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.9833 - val_loss: 0.1026 - val_accuracy: 0.9589\n",
      "Epoch 55/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9806 - val_loss: 0.1025 - val_accuracy: 0.9600\n",
      "Epoch 56/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9809 - val_loss: 0.0990 - val_accuracy: 0.9600\n",
      "Epoch 57/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1220 - accuracy: 0.9795 - val_loss: 0.1074 - val_accuracy: 0.9533\n",
      "Epoch 58/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9750 - val_loss: 0.0956 - val_accuracy: 0.9633\n",
      "Epoch 59/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9853 - val_loss: 0.0935 - val_accuracy: 0.9611\n",
      "Epoch 60/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9908 - val_loss: 0.0920 - val_accuracy: 0.9600\n",
      "Epoch 61/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9827 - val_loss: 0.0917 - val_accuracy: 0.9611\n",
      "Epoch 62/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.9848 - val_loss: 0.0907 - val_accuracy: 0.9644\n",
      "Epoch 63/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9801 - val_loss: 0.0870 - val_accuracy: 0.9656\n",
      "Epoch 64/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9877 - val_loss: 0.0872 - val_accuracy: 0.9633\n",
      "Epoch 65/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9786 - val_loss: 0.0850 - val_accuracy: 0.9644\n",
      "Epoch 66/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.9893 - val_loss: 0.0852 - val_accuracy: 0.9678\n",
      "Epoch 67/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9912 - val_loss: 0.0860 - val_accuracy: 0.9656\n",
      "Epoch 68/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9909 - val_loss: 0.0875 - val_accuracy: 0.9667\n",
      "Epoch 69/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9823 - val_loss: 0.0956 - val_accuracy: 0.9600\n",
      "Epoch 70/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1088 - accuracy: 0.9816 - val_loss: 0.0903 - val_accuracy: 0.9667\n",
      "Epoch 71/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9825 - val_loss: 0.0883 - val_accuracy: 0.9678\n",
      "Epoch 72/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9867 - val_loss: 0.0865 - val_accuracy: 0.9667\n",
      "Epoch 73/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9846 - val_loss: 0.0795 - val_accuracy: 0.9689\n",
      "Epoch 74/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9847 - val_loss: 0.0811 - val_accuracy: 0.9667\n",
      "Epoch 75/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9840 - val_loss: 0.0791 - val_accuracy: 0.9667\n",
      "Epoch 76/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.9851 - val_loss: 0.0789 - val_accuracy: 0.9667\n",
      "Epoch 77/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9833 - val_loss: 0.0790 - val_accuracy: 0.9678\n",
      "Epoch 78/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9907 - val_loss: 0.0800 - val_accuracy: 0.9667\n",
      "Epoch 79/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9915 - val_loss: 0.0811 - val_accuracy: 0.9689\n",
      "Epoch 80/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9859 - val_loss: 0.0832 - val_accuracy: 0.9689\n",
      "Epoch 81/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9915 - val_loss: 0.0873 - val_accuracy: 0.9611\n",
      "Epoch 82/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9880 - val_loss: 0.0881 - val_accuracy: 0.9611\n",
      "Epoch 83/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9868 - val_loss: 0.0793 - val_accuracy: 0.9711\n",
      "Epoch 84/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9956 - val_loss: 0.0739 - val_accuracy: 0.9678\n",
      "Epoch 85/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9923 - val_loss: 0.0740 - val_accuracy: 0.9689\n",
      "Epoch 86/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9885 - val_loss: 0.0783 - val_accuracy: 0.9700\n",
      "Epoch 87/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9883 - val_loss: 0.0740 - val_accuracy: 0.9733\n",
      "Epoch 88/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9895 - val_loss: 0.0744 - val_accuracy: 0.9744\n",
      "Epoch 89/250\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9863 - val_loss: 0.0742 - val_accuracy: 0.9722\n",
      "Epoch 90/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9912 - val_loss: 0.0798 - val_accuracy: 0.9689\n",
      "Epoch 91/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9900 - val_loss: 0.0770 - val_accuracy: 0.9689\n",
      "Epoch 92/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9929 - val_loss: 0.0755 - val_accuracy: 0.9711\n",
      "Epoch 93/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9920 - val_loss: 0.0733 - val_accuracy: 0.9733\n",
      "Epoch 94/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9832 - val_loss: 0.0778 - val_accuracy: 0.9689\n",
      "Epoch 95/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9885 - val_loss: 0.0850 - val_accuracy: 0.9633\n",
      "Epoch 96/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9868 - val_loss: 0.0857 - val_accuracy: 0.9633\n",
      "Epoch 97/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9849 - val_loss: 0.0712 - val_accuracy: 0.9733\n",
      "Epoch 98/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9884 - val_loss: 0.0743 - val_accuracy: 0.9722\n",
      "Epoch 99/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9871 - val_loss: 0.0709 - val_accuracy: 0.9733\n",
      "Epoch 100/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9924 - val_loss: 0.0883 - val_accuracy: 0.9600\n",
      "Epoch 101/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9908 - val_loss: 0.0730 - val_accuracy: 0.9700\n",
      "Epoch 102/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9932 - val_loss: 0.0740 - val_accuracy: 0.9700\n",
      "Epoch 103/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9901 - val_loss: 0.0743 - val_accuracy: 0.9700\n",
      "Epoch 104/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9897 - val_loss: 0.0768 - val_accuracy: 0.9689\n",
      "Epoch 105/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9920 - val_loss: 0.0693 - val_accuracy: 0.9722\n",
      "Epoch 106/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9916 - val_loss: 0.0707 - val_accuracy: 0.9733\n",
      "Epoch 107/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9893 - val_loss: 0.0688 - val_accuracy: 0.9767\n",
      "Epoch 108/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9887 - val_loss: 0.0701 - val_accuracy: 0.9722\n",
      "Epoch 109/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9879 - val_loss: 0.0746 - val_accuracy: 0.9711\n",
      "Epoch 110/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9883 - val_loss: 0.0709 - val_accuracy: 0.9711\n",
      "Epoch 111/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9919 - val_loss: 0.0757 - val_accuracy: 0.9700\n",
      "Epoch 112/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9899 - val_loss: 0.0792 - val_accuracy: 0.9667\n",
      "Epoch 113/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9924 - val_loss: 0.0792 - val_accuracy: 0.9667\n",
      "Epoch 114/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9881 - val_loss: 0.0686 - val_accuracy: 0.9733\n",
      "Epoch 115/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9894 - val_loss: 0.0723 - val_accuracy: 0.9722\n",
      "Epoch 116/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9896 - val_loss: 0.0685 - val_accuracy: 0.9744\n",
      "Epoch 117/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9926 - val_loss: 0.0690 - val_accuracy: 0.9744\n",
      "Epoch 118/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9913 - val_loss: 0.0676 - val_accuracy: 0.9756\n",
      "Epoch 119/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9906 - val_loss: 0.0762 - val_accuracy: 0.9700\n",
      "Epoch 120/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9938 - val_loss: 0.1066 - val_accuracy: 0.9556\n",
      "Epoch 121/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9891 - val_loss: 0.0684 - val_accuracy: 0.9767\n",
      "Epoch 122/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9930 - val_loss: 0.0711 - val_accuracy: 0.9700\n",
      "Epoch 123/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9920 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
      "Epoch 124/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9896 - val_loss: 0.0780 - val_accuracy: 0.9678\n",
      "Epoch 125/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9908 - val_loss: 0.0786 - val_accuracy: 0.9678\n",
      "Epoch 126/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9876 - val_loss: 0.0681 - val_accuracy: 0.9767\n",
      "Epoch 127/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9936 - val_loss: 0.0726 - val_accuracy: 0.9733\n",
      "Epoch 128/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9876 - val_loss: 0.0784 - val_accuracy: 0.9667\n",
      "Epoch 129/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9923 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
      "Epoch 130/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9930 - val_loss: 0.0705 - val_accuracy: 0.9744\n",
      "Epoch 131/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9900 - val_loss: 0.0697 - val_accuracy: 0.9744\n",
      "Epoch 132/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9912 - val_loss: 0.0757 - val_accuracy: 0.9700\n",
      "Epoch 133/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9901 - val_loss: 0.0784 - val_accuracy: 0.9700\n",
      "Epoch 134/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9910 - val_loss: 0.0733 - val_accuracy: 0.9733\n",
      "Epoch 135/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9885 - val_loss: 0.0718 - val_accuracy: 0.9722\n",
      "Epoch 136/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9948 - val_loss: 0.0761 - val_accuracy: 0.9689\n",
      "Epoch 137/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9822 - val_loss: 0.0770 - val_accuracy: 0.9700\n",
      "Epoch 138/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9880 - val_loss: 0.0672 - val_accuracy: 0.9778\n",
      "Epoch 139/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9933 - val_loss: 0.0681 - val_accuracy: 0.9756\n",
      "Epoch 140/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9874 - val_loss: 0.0773 - val_accuracy: 0.9678\n",
      "Epoch 141/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9919 - val_loss: 0.0708 - val_accuracy: 0.9756\n",
      "Epoch 142/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9947 - val_loss: 0.0665 - val_accuracy: 0.9789\n",
      "Epoch 143/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9883 - val_loss: 0.0680 - val_accuracy: 0.9756\n",
      "Epoch 144/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9872 - val_loss: 0.0700 - val_accuracy: 0.9756\n",
      "Epoch 145/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9926 - val_loss: 0.0734 - val_accuracy: 0.9744\n",
      "Epoch 146/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9950 - val_loss: 0.0682 - val_accuracy: 0.9756\n",
      "Epoch 147/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9878 - val_loss: 0.0710 - val_accuracy: 0.9756\n",
      "Epoch 148/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9880 - val_loss: 0.0874 - val_accuracy: 0.9644\n",
      "Epoch 149/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9880 - val_loss: 0.0731 - val_accuracy: 0.9733\n",
      "Epoch 150/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.9865 - val_loss: 0.0702 - val_accuracy: 0.9744\n",
      "Epoch 151/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9904 - val_loss: 0.0673 - val_accuracy: 0.9789\n",
      "Epoch 152/250\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0664 - accuracy: 0.9885 - val_loss: 0.0774 - val_accuracy: 0.9700\n",
      "Epoch 153/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9885 - val_loss: 0.0800 - val_accuracy: 0.9678\n",
      "Epoch 154/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.9895 - val_loss: 0.0657 - val_accuracy: 0.9778\n",
      "Epoch 155/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9874 - val_loss: 0.0764 - val_accuracy: 0.9700\n",
      "Epoch 156/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9922 - val_loss: 0.0728 - val_accuracy: 0.9733\n",
      "Epoch 157/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9894 - val_loss: 0.0756 - val_accuracy: 0.9711\n",
      "Epoch 158/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9903 - val_loss: 0.0762 - val_accuracy: 0.9722\n",
      "Epoch 159/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9896 - val_loss: 0.0827 - val_accuracy: 0.9678\n",
      "Epoch 160/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9849 - val_loss: 0.0652 - val_accuracy: 0.9778\n",
      "Epoch 161/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9913 - val_loss: 0.0702 - val_accuracy: 0.9744\n",
      "Epoch 162/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9929 - val_loss: 0.0692 - val_accuracy: 0.9767\n",
      "Epoch 163/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9919 - val_loss: 0.0684 - val_accuracy: 0.9756\n",
      "Epoch 164/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9921 - val_loss: 0.0693 - val_accuracy: 0.9767\n",
      "Epoch 165/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9865 - val_loss: 0.0738 - val_accuracy: 0.9733\n",
      "Epoch 166/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9906 - val_loss: 0.0721 - val_accuracy: 0.9744\n",
      "Epoch 167/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9904 - val_loss: 0.0752 - val_accuracy: 0.9744\n",
      "Epoch 168/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0606 - accuracy: 0.9912 - val_loss: 0.0744 - val_accuracy: 0.9733\n",
      "Epoch 169/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.0675 - val_accuracy: 0.9767\n",
      "Epoch 170/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9924 - val_loss: 0.0738 - val_accuracy: 0.9733\n",
      "Epoch 171/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9867 - val_loss: 0.0830 - val_accuracy: 0.9656\n",
      "Epoch 172/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9915 - val_loss: 0.0641 - val_accuracy: 0.9811\n",
      "Epoch 173/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9915 - val_loss: 0.0653 - val_accuracy: 0.9778\n",
      "Epoch 174/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9876 - val_loss: 0.0798 - val_accuracy: 0.9689\n",
      "Epoch 175/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9913 - val_loss: 0.0627 - val_accuracy: 0.9778\n",
      "Epoch 176/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9832 - val_loss: 0.0744 - val_accuracy: 0.9733\n",
      "Epoch 177/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9884 - val_loss: 0.0703 - val_accuracy: 0.9744\n",
      "Epoch 178/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9919 - val_loss: 0.0679 - val_accuracy: 0.9778\n",
      "Epoch 179/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9862 - val_loss: 0.0835 - val_accuracy: 0.9700\n",
      "Epoch 180/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9888 - val_loss: 0.0710 - val_accuracy: 0.9778\n",
      "Epoch 181/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0549 - accuracy: 0.9914 - val_loss: 0.0664 - val_accuracy: 0.9767\n",
      "Epoch 182/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9911 - val_loss: 0.0915 - val_accuracy: 0.9644\n",
      "Epoch 183/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9932 - val_loss: 0.0650 - val_accuracy: 0.9778\n",
      "Epoch 184/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9881 - val_loss: 0.0718 - val_accuracy: 0.9767\n",
      "Epoch 185/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9903 - val_loss: 0.0744 - val_accuracy: 0.9744\n",
      "Epoch 186/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9902 - val_loss: 0.0776 - val_accuracy: 0.9733\n",
      "Epoch 187/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9885 - val_loss: 0.0643 - val_accuracy: 0.9789\n",
      "Epoch 188/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9857 - val_loss: 0.0726 - val_accuracy: 0.9767\n",
      "Epoch 189/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9917 - val_loss: 0.0684 - val_accuracy: 0.9756\n",
      "Epoch 190/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0568 - accuracy: 0.9915 - val_loss: 0.0681 - val_accuracy: 0.9767\n",
      "Epoch 191/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0582 - accuracy: 0.9879 - val_loss: 0.0674 - val_accuracy: 0.9789\n",
      "Epoch 192/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9898 - val_loss: 0.0740 - val_accuracy: 0.9756\n",
      "Epoch 193/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9875 - val_loss: 0.0783 - val_accuracy: 0.9711\n",
      "Epoch 194/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9934 - val_loss: 0.0649 - val_accuracy: 0.9789\n",
      "Epoch 195/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9861 - val_loss: 0.0993 - val_accuracy: 0.9600\n",
      "Epoch 196/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9940 - val_loss: 0.0621 - val_accuracy: 0.9800\n",
      "Epoch 197/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9894 - val_loss: 0.0717 - val_accuracy: 0.9744\n",
      "Epoch 198/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9934 - val_loss: 0.0754 - val_accuracy: 0.9733\n",
      "Epoch 199/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9926 - val_loss: 0.0648 - val_accuracy: 0.9800\n",
      "Epoch 200/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9880 - val_loss: 0.0627 - val_accuracy: 0.9800\n",
      "Epoch 201/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9882 - val_loss: 0.0653 - val_accuracy: 0.9744\n",
      "Epoch 202/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9926 - val_loss: 0.0669 - val_accuracy: 0.9744\n",
      "Epoch 203/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9898 - val_loss: 0.0799 - val_accuracy: 0.9722\n",
      "Epoch 204/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9877 - val_loss: 0.0633 - val_accuracy: 0.9800\n",
      "Epoch 205/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9878 - val_loss: 0.0786 - val_accuracy: 0.9700\n",
      "Epoch 206/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9881 - val_loss: 0.0629 - val_accuracy: 0.9811\n",
      "Epoch 207/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9878 - val_loss: 0.0833 - val_accuracy: 0.9689\n",
      "Epoch 208/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9915 - val_loss: 0.0671 - val_accuracy: 0.9778\n",
      "Epoch 209/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9898 - val_loss: 0.0759 - val_accuracy: 0.9744\n",
      "Epoch 210/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9931 - val_loss: 0.0648 - val_accuracy: 0.9811\n",
      "Epoch 211/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9921 - val_loss: 0.0902 - val_accuracy: 0.9667\n",
      "Epoch 212/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9901 - val_loss: 0.0719 - val_accuracy: 0.9756\n",
      "Epoch 213/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9958 - val_loss: 0.0735 - val_accuracy: 0.9756\n",
      "Epoch 214/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9937 - val_loss: 0.0670 - val_accuracy: 0.9778\n",
      "Epoch 215/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 0.9917 - val_loss: 0.0730 - val_accuracy: 0.9767\n",
      "Epoch 216/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9925 - val_loss: 0.0830 - val_accuracy: 0.9722\n",
      "Epoch 217/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9899 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "Epoch 218/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9916 - val_loss: 0.0703 - val_accuracy: 0.9756\n",
      "Epoch 219/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9903 - val_loss: 0.0766 - val_accuracy: 0.9744\n",
      "Epoch 220/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9893 - val_loss: 0.0694 - val_accuracy: 0.9756\n",
      "Epoch 221/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9890 - val_loss: 0.0771 - val_accuracy: 0.9767\n",
      "Epoch 222/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9937 - val_loss: 0.0731 - val_accuracy: 0.9756\n",
      "Epoch 223/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9912 - val_loss: 0.0792 - val_accuracy: 0.9733\n",
      "Epoch 224/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9866 - val_loss: 0.0688 - val_accuracy: 0.9778\n",
      "Epoch 225/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9930 - val_loss: 0.0791 - val_accuracy: 0.9733\n",
      "Epoch 226/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9909 - val_loss: 0.0669 - val_accuracy: 0.9778\n",
      "Epoch 227/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9935 - val_loss: 0.0792 - val_accuracy: 0.9722\n",
      "Epoch 228/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 0.9888 - val_loss: 0.0802 - val_accuracy: 0.9722\n",
      "Epoch 229/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9919 - val_loss: 0.0806 - val_accuracy: 0.9733\n",
      "Epoch 230/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9921 - val_loss: 0.0662 - val_accuracy: 0.9800\n",
      "Epoch 231/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9928 - val_loss: 0.0751 - val_accuracy: 0.9756\n",
      "Epoch 232/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9870 - val_loss: 0.0668 - val_accuracy: 0.9789\n",
      "Epoch 233/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9930 - val_loss: 0.0713 - val_accuracy: 0.9767\n",
      "Epoch 234/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9904 - val_loss: 0.0834 - val_accuracy: 0.9689\n",
      "Epoch 235/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9872 - val_loss: 0.0770 - val_accuracy: 0.9722\n",
      "Epoch 236/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9884 - val_loss: 0.0697 - val_accuracy: 0.9756\n",
      "Epoch 237/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9898 - val_loss: 0.0794 - val_accuracy: 0.9733\n",
      "Epoch 238/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9880 - val_loss: 0.0701 - val_accuracy: 0.9756\n",
      "Epoch 239/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9864 - val_loss: 0.0726 - val_accuracy: 0.9756\n",
      "Epoch 240/250\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0537 - accuracy: 0.9874 - val_loss: 0.0749 - val_accuracy: 0.9722\n",
      "Epoch 241/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9905 - val_loss: 0.0702 - val_accuracy: 0.9767\n",
      "Epoch 242/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9917 - val_loss: 0.0720 - val_accuracy: 0.9744\n",
      "Epoch 243/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9860 - val_loss: 0.0711 - val_accuracy: 0.9756\n",
      "Epoch 244/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9880 - val_loss: 0.0750 - val_accuracy: 0.9744\n",
      "Epoch 245/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9913 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 246/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9925 - val_loss: 0.0725 - val_accuracy: 0.9778\n",
      "Epoch 247/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9860 - val_loss: 0.0686 - val_accuracy: 0.9800\n",
      "Epoch 248/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9905 - val_loss: 0.0738 - val_accuracy: 0.9778\n",
      "Epoch 249/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9833 - val_loss: 0.0877 - val_accuracy: 0.9700\n",
      "Epoch 250/250\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9887 - val_loss: 0.0679 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(new_x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (new_x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_res(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is good, with a very high validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
