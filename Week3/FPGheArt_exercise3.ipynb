{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import initializers, regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "str0 = \"ts_L60_Z12_A500_DX50_bias5_N10000\"\n",
    "\n",
    "fnamex = \"DATA/x_\"+str0+\".csv\"\n",
    "fnamey = \"DATA/y_\"+str0+\".csv\"\n",
    "\n",
    "x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "N = len(x)\n",
    "print(N)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_std =  scaler.fit_transform(x.T).T\n",
    "\n",
    "plt.plot(x_std[0], label = '0')\n",
    "plt.plot(x_std[1], label = '1')\n",
    "plt.plot(x_std[2], label = '2')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "N_categ = 3\n",
    "y = np.zeros((N,N_categ))\n",
    "\n",
    "for n in range(N):\n",
    "    y[n][categ[n]] = 1.\n",
    "    \n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 8000 2000 60\n"
     ]
    }
   ],
   "source": [
    "perc_train = 0.8\n",
    "N_train = int(N*perc_train)\n",
    "N_val = N-N_train\n",
    "\n",
    "x_train = x_std[:N_train]\n",
    "y_train = y[:N_train]\n",
    "x_val = x_std[N_train:]\n",
    "y_val = y[N_train:]\n",
    "\n",
    "\n",
    "L = len(x[0])\n",
    "print(N, N_train, N_val, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],L,1) #1 - channel (RGB:3)\n",
    "                                                # L = sample size\n",
    "x_val = x_val.reshape(x_val.shape[0],L,1)\n",
    "\n",
    "input_shape = (L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 50, 5)             60        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 10, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 4, 5)              180       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2, 5)              0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 383\n",
      "Trainable params: 383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "reg = regularizers.l2(0.01) #Lasso\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "#kernel_size = 11... similar to 12 as before\n",
    "model.add(Conv1D( filters = 5, kernel_size = 11, kernel_regularizer = reg, \n",
    "                 kernel_initializer = ini, \n",
    "                 activation = \"relu\", \n",
    "                 input_shape = input_shape                \n",
    "                ))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(filters = 5, kernel_size = 7, \n",
    "                 activation = \"relu\", \n",
    "                ))\n",
    "model.add(MaxPooling1D(2)) #optional\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, \n",
    "              optimizer = \"adam\", \n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "# model.save_weights(\"Original_Weights_CNN1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Working!\n",
    "The NN has as input larger and larger numbers. We shall manipulate the data at the beginning for example reshuffling them as they have average 0 and remove their standard deviation (set it to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 - 0s - loss: 1.0999 - accuracy: 0.3479 - val_loss: 1.0964 - val_accuracy: 0.3670\n",
      "Epoch 2/250\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3640 - val_loss: 1.0901 - val_accuracy: 0.3880\n",
      "Epoch 3/250\n",
      "32/32 - 0s - loss: 1.0870 - accuracy: 0.3935 - val_loss: 1.0748 - val_accuracy: 0.4180\n",
      "Epoch 4/250\n",
      "32/32 - 0s - loss: 1.0666 - accuracy: 0.4334 - val_loss: 1.0431 - val_accuracy: 0.4945\n",
      "Epoch 5/250\n",
      "32/32 - 0s - loss: 1.0268 - accuracy: 0.4986 - val_loss: 0.9893 - val_accuracy: 0.5685\n",
      "Epoch 6/250\n",
      "32/32 - 0s - loss: 0.9713 - accuracy: 0.5403 - val_loss: 0.9250 - val_accuracy: 0.6105\n",
      "Epoch 7/250\n",
      "32/32 - 0s - loss: 0.9218 - accuracy: 0.5680 - val_loss: 0.8794 - val_accuracy: 0.6350\n",
      "Epoch 8/250\n",
      "32/32 - 0s - loss: 0.8949 - accuracy: 0.5894 - val_loss: 0.8482 - val_accuracy: 0.6520\n",
      "Epoch 9/250\n",
      "32/32 - 0s - loss: 0.8674 - accuracy: 0.6065 - val_loss: 0.8242 - val_accuracy: 0.6590\n",
      "Epoch 10/250\n",
      "32/32 - 0s - loss: 0.8447 - accuracy: 0.6331 - val_loss: 0.8079 - val_accuracy: 0.6760\n",
      "Epoch 11/250\n",
      "32/32 - 0s - loss: 0.8327 - accuracy: 0.6364 - val_loss: 0.7922 - val_accuracy: 0.6930\n",
      "Epoch 12/250\n",
      "32/32 - 0s - loss: 0.8110 - accuracy: 0.6587 - val_loss: 0.7631 - val_accuracy: 0.7005\n",
      "Epoch 13/250\n",
      "32/32 - 0s - loss: 0.7939 - accuracy: 0.6700 - val_loss: 0.7477 - val_accuracy: 0.7140\n",
      "Epoch 14/250\n",
      "32/32 - 0s - loss: 0.7743 - accuracy: 0.6839 - val_loss: 0.7288 - val_accuracy: 0.7195\n",
      "Epoch 15/250\n",
      "32/32 - 0s - loss: 0.7538 - accuracy: 0.6923 - val_loss: 0.7128 - val_accuracy: 0.7250\n",
      "Epoch 16/250\n",
      "32/32 - 0s - loss: 0.7467 - accuracy: 0.6999 - val_loss: 0.7008 - val_accuracy: 0.7340\n",
      "Epoch 17/250\n",
      "32/32 - 0s - loss: 0.7267 - accuracy: 0.7114 - val_loss: 0.6907 - val_accuracy: 0.7375\n",
      "Epoch 18/250\n",
      "32/32 - 0s - loss: 0.7182 - accuracy: 0.7138 - val_loss: 0.6866 - val_accuracy: 0.7465\n",
      "Epoch 19/250\n",
      "32/32 - 0s - loss: 0.7050 - accuracy: 0.7214 - val_loss: 0.6728 - val_accuracy: 0.7475\n",
      "Epoch 20/250\n",
      "32/32 - 0s - loss: 0.6989 - accuracy: 0.7249 - val_loss: 0.6652 - val_accuracy: 0.7535\n",
      "Epoch 21/250\n",
      "32/32 - 0s - loss: 0.6887 - accuracy: 0.7343 - val_loss: 0.6587 - val_accuracy: 0.7515\n",
      "Epoch 22/250\n",
      "32/32 - 0s - loss: 0.6803 - accuracy: 0.7360 - val_loss: 0.6510 - val_accuracy: 0.7635\n",
      "Epoch 23/250\n",
      "32/32 - 0s - loss: 0.6728 - accuracy: 0.7393 - val_loss: 0.6443 - val_accuracy: 0.7685\n",
      "Epoch 24/250\n",
      "32/32 - 0s - loss: 0.6593 - accuracy: 0.7474 - val_loss: 0.6387 - val_accuracy: 0.7695\n",
      "Epoch 25/250\n",
      "32/32 - 0s - loss: 0.6590 - accuracy: 0.7451 - val_loss: 0.6320 - val_accuracy: 0.7755\n",
      "Epoch 26/250\n",
      "32/32 - 0s - loss: 0.6496 - accuracy: 0.7523 - val_loss: 0.6282 - val_accuracy: 0.7715\n",
      "Epoch 27/250\n",
      "32/32 - 0s - loss: 0.6544 - accuracy: 0.7549 - val_loss: 0.6251 - val_accuracy: 0.7735\n",
      "Epoch 28/250\n",
      "32/32 - 0s - loss: 0.6369 - accuracy: 0.7579 - val_loss: 0.6173 - val_accuracy: 0.7775\n",
      "Epoch 29/250\n",
      "32/32 - 0s - loss: 0.6316 - accuracy: 0.7550 - val_loss: 0.6110 - val_accuracy: 0.7805\n",
      "Epoch 30/250\n",
      "32/32 - 0s - loss: 0.6297 - accuracy: 0.7657 - val_loss: 0.6108 - val_accuracy: 0.7780\n",
      "Epoch 31/250\n",
      "32/32 - 0s - loss: 0.6207 - accuracy: 0.7659 - val_loss: 0.6037 - val_accuracy: 0.7810\n",
      "Epoch 32/250\n",
      "32/32 - 0s - loss: 0.6205 - accuracy: 0.7736 - val_loss: 0.5991 - val_accuracy: 0.7860\n",
      "Epoch 33/250\n",
      "32/32 - 0s - loss: 0.6186 - accuracy: 0.7691 - val_loss: 0.5957 - val_accuracy: 0.7915\n",
      "Epoch 34/250\n",
      "32/32 - 0s - loss: 0.6083 - accuracy: 0.7720 - val_loss: 0.5898 - val_accuracy: 0.7900\n",
      "Epoch 35/250\n",
      "32/32 - 0s - loss: 0.6078 - accuracy: 0.7749 - val_loss: 0.5916 - val_accuracy: 0.7905\n",
      "Epoch 36/250\n",
      "32/32 - 0s - loss: 0.5993 - accuracy: 0.7794 - val_loss: 0.5868 - val_accuracy: 0.7930\n",
      "Epoch 37/250\n",
      "32/32 - 0s - loss: 0.5969 - accuracy: 0.7805 - val_loss: 0.5859 - val_accuracy: 0.7920\n",
      "Epoch 38/250\n",
      "32/32 - 0s - loss: 0.6007 - accuracy: 0.7784 - val_loss: 0.5840 - val_accuracy: 0.7920\n",
      "Epoch 39/250\n",
      "32/32 - 0s - loss: 0.5921 - accuracy: 0.7845 - val_loss: 0.5753 - val_accuracy: 0.7965\n",
      "Epoch 40/250\n",
      "32/32 - 0s - loss: 0.5946 - accuracy: 0.7812 - val_loss: 0.5775 - val_accuracy: 0.7935\n",
      "Epoch 41/250\n",
      "32/32 - 0s - loss: 0.5878 - accuracy: 0.7829 - val_loss: 0.5717 - val_accuracy: 0.7955\n",
      "Epoch 42/250\n",
      "32/32 - 0s - loss: 0.5853 - accuracy: 0.7836 - val_loss: 0.5726 - val_accuracy: 0.7945\n",
      "Epoch 43/250\n",
      "32/32 - 0s - loss: 0.5818 - accuracy: 0.7843 - val_loss: 0.5671 - val_accuracy: 0.7945\n",
      "Epoch 44/250\n",
      "32/32 - 0s - loss: 0.5796 - accuracy: 0.7885 - val_loss: 0.5698 - val_accuracy: 0.7950\n",
      "Epoch 45/250\n",
      "32/32 - 0s - loss: 0.5761 - accuracy: 0.7884 - val_loss: 0.5651 - val_accuracy: 0.7915\n",
      "Epoch 46/250\n",
      "32/32 - 0s - loss: 0.5716 - accuracy: 0.7889 - val_loss: 0.5607 - val_accuracy: 0.7980\n",
      "Epoch 47/250\n",
      "32/32 - 0s - loss: 0.5697 - accuracy: 0.7926 - val_loss: 0.5563 - val_accuracy: 0.7995\n",
      "Epoch 48/250\n",
      "32/32 - 0s - loss: 0.5728 - accuracy: 0.7911 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 49/250\n",
      "32/32 - 0s - loss: 0.5670 - accuracy: 0.7921 - val_loss: 0.5544 - val_accuracy: 0.7985\n",
      "Epoch 50/250\n",
      "32/32 - 0s - loss: 0.5653 - accuracy: 0.7937 - val_loss: 0.5517 - val_accuracy: 0.8010\n",
      "Epoch 51/250\n",
      "32/32 - 0s - loss: 0.5671 - accuracy: 0.7906 - val_loss: 0.5551 - val_accuracy: 0.7990\n",
      "Epoch 52/250\n",
      "32/32 - 0s - loss: 0.5592 - accuracy: 0.7931 - val_loss: 0.5556 - val_accuracy: 0.7995\n",
      "Epoch 53/250\n",
      "32/32 - 0s - loss: 0.5563 - accuracy: 0.8021 - val_loss: 0.5449 - val_accuracy: 0.8065\n",
      "Epoch 54/250\n",
      "32/32 - 0s - loss: 0.5575 - accuracy: 0.7997 - val_loss: 0.5443 - val_accuracy: 0.8090\n",
      "Epoch 55/250\n",
      "32/32 - 0s - loss: 0.5559 - accuracy: 0.7999 - val_loss: 0.5424 - val_accuracy: 0.8075\n",
      "Epoch 56/250\n",
      "32/32 - 0s - loss: 0.5560 - accuracy: 0.8002 - val_loss: 0.5409 - val_accuracy: 0.8095\n",
      "Epoch 57/250\n",
      "32/32 - 0s - loss: 0.5508 - accuracy: 0.8014 - val_loss: 0.5425 - val_accuracy: 0.8000\n",
      "Epoch 58/250\n",
      "32/32 - 0s - loss: 0.5474 - accuracy: 0.8043 - val_loss: 0.5387 - val_accuracy: 0.8075\n",
      "Epoch 59/250\n",
      "32/32 - 0s - loss: 0.5526 - accuracy: 0.8012 - val_loss: 0.5399 - val_accuracy: 0.8000\n",
      "Epoch 60/250\n",
      "32/32 - 0s - loss: 0.5509 - accuracy: 0.7995 - val_loss: 0.5349 - val_accuracy: 0.8080\n",
      "Epoch 61/250\n",
      "32/32 - 0s - loss: 0.5468 - accuracy: 0.8050 - val_loss: 0.5330 - val_accuracy: 0.8105\n",
      "Epoch 62/250\n",
      "32/32 - 0s - loss: 0.5445 - accuracy: 0.8026 - val_loss: 0.5326 - val_accuracy: 0.8110\n",
      "Epoch 63/250\n",
      "32/32 - 0s - loss: 0.5416 - accuracy: 0.8044 - val_loss: 0.5308 - val_accuracy: 0.8130\n",
      "Epoch 64/250\n",
      "32/32 - 0s - loss: 0.5470 - accuracy: 0.8004 - val_loss: 0.5349 - val_accuracy: 0.8025\n",
      "Epoch 65/250\n",
      "32/32 - 0s - loss: 0.5452 - accuracy: 0.8035 - val_loss: 0.5296 - val_accuracy: 0.8100\n",
      "Epoch 66/250\n",
      "32/32 - 0s - loss: 0.5399 - accuracy: 0.8091 - val_loss: 0.5293 - val_accuracy: 0.8120\n",
      "Epoch 67/250\n",
      "32/32 - 0s - loss: 0.5391 - accuracy: 0.8050 - val_loss: 0.5259 - val_accuracy: 0.8110\n",
      "Epoch 68/250\n",
      "32/32 - 0s - loss: 0.5396 - accuracy: 0.8061 - val_loss: 0.5289 - val_accuracy: 0.8065\n",
      "Epoch 69/250\n",
      "32/32 - 0s - loss: 0.5419 - accuracy: 0.8036 - val_loss: 0.5243 - val_accuracy: 0.8110\n",
      "Epoch 70/250\n",
      "32/32 - 0s - loss: 0.5327 - accuracy: 0.8049 - val_loss: 0.5229 - val_accuracy: 0.8100\n",
      "Epoch 71/250\n",
      "32/32 - 0s - loss: 0.5316 - accuracy: 0.8117 - val_loss: 0.5227 - val_accuracy: 0.8105\n",
      "Epoch 72/250\n",
      "32/32 - 0s - loss: 0.5281 - accuracy: 0.8071 - val_loss: 0.5305 - val_accuracy: 0.8050\n",
      "Epoch 73/250\n",
      "32/32 - 0s - loss: 0.5338 - accuracy: 0.8085 - val_loss: 0.5273 - val_accuracy: 0.8060\n",
      "Epoch 74/250\n",
      "32/32 - 0s - loss: 0.5310 - accuracy: 0.8129 - val_loss: 0.5185 - val_accuracy: 0.8135\n",
      "Epoch 75/250\n",
      "32/32 - 0s - loss: 0.5295 - accuracy: 0.8116 - val_loss: 0.5188 - val_accuracy: 0.8150\n",
      "Epoch 76/250\n",
      "32/32 - 0s - loss: 0.5286 - accuracy: 0.8115 - val_loss: 0.5182 - val_accuracy: 0.8145\n",
      "Epoch 77/250\n",
      "32/32 - 0s - loss: 0.5240 - accuracy: 0.8154 - val_loss: 0.5185 - val_accuracy: 0.8175\n",
      "Epoch 78/250\n",
      "32/32 - 0s - loss: 0.5277 - accuracy: 0.8096 - val_loss: 0.5220 - val_accuracy: 0.8115\n",
      "Epoch 79/250\n",
      "32/32 - 0s - loss: 0.5253 - accuracy: 0.8138 - val_loss: 0.5141 - val_accuracy: 0.8185\n",
      "Epoch 80/250\n",
      "32/32 - 0s - loss: 0.5174 - accuracy: 0.8169 - val_loss: 0.5185 - val_accuracy: 0.8155\n",
      "Epoch 81/250\n",
      "32/32 - 0s - loss: 0.5249 - accuracy: 0.8120 - val_loss: 0.5138 - val_accuracy: 0.8160\n",
      "Epoch 82/250\n",
      "32/32 - 0s - loss: 0.5214 - accuracy: 0.8139 - val_loss: 0.5133 - val_accuracy: 0.8140\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.5231 - accuracy: 0.8119 - val_loss: 0.5155 - val_accuracy: 0.8135\n",
      "Epoch 84/250\n",
      "32/32 - 0s - loss: 0.5120 - accuracy: 0.8164 - val_loss: 0.5163 - val_accuracy: 0.8165\n",
      "Epoch 85/250\n",
      "32/32 - 0s - loss: 0.5213 - accuracy: 0.8102 - val_loss: 0.5093 - val_accuracy: 0.8170\n",
      "Epoch 86/250\n",
      "32/32 - 0s - loss: 0.5205 - accuracy: 0.8175 - val_loss: 0.5144 - val_accuracy: 0.8110\n",
      "Epoch 87/250\n",
      "32/32 - 0s - loss: 0.5218 - accuracy: 0.8185 - val_loss: 0.5113 - val_accuracy: 0.8175\n",
      "Epoch 88/250\n",
      "32/32 - 0s - loss: 0.5203 - accuracy: 0.8189 - val_loss: 0.5142 - val_accuracy: 0.8155\n",
      "Epoch 89/250\n",
      "32/32 - 0s - loss: 0.5088 - accuracy: 0.8179 - val_loss: 0.5108 - val_accuracy: 0.8195\n",
      "Epoch 90/250\n",
      "32/32 - 0s - loss: 0.5077 - accuracy: 0.8205 - val_loss: 0.5145 - val_accuracy: 0.8170\n",
      "Epoch 91/250\n",
      "32/32 - 0s - loss: 0.5111 - accuracy: 0.8171 - val_loss: 0.5119 - val_accuracy: 0.8155\n",
      "Epoch 92/250\n",
      "32/32 - 0s - loss: 0.5152 - accuracy: 0.8195 - val_loss: 0.5099 - val_accuracy: 0.8155\n",
      "Epoch 93/250\n",
      "32/32 - 0s - loss: 0.5111 - accuracy: 0.8191 - val_loss: 0.5070 - val_accuracy: 0.8190\n",
      "Epoch 94/250\n",
      "32/32 - 0s - loss: 0.5092 - accuracy: 0.8192 - val_loss: 0.5080 - val_accuracy: 0.8185\n",
      "Epoch 95/250\n",
      "32/32 - 0s - loss: 0.5077 - accuracy: 0.8213 - val_loss: 0.5059 - val_accuracy: 0.8210\n",
      "Epoch 96/250\n",
      "32/32 - 0s - loss: 0.5076 - accuracy: 0.8186 - val_loss: 0.5093 - val_accuracy: 0.8230\n",
      "Epoch 97/250\n",
      "32/32 - 0s - loss: 0.5041 - accuracy: 0.8192 - val_loss: 0.5060 - val_accuracy: 0.8200\n",
      "Epoch 98/250\n",
      "32/32 - 0s - loss: 0.5074 - accuracy: 0.8250 - val_loss: 0.5065 - val_accuracy: 0.8215\n",
      "Epoch 99/250\n",
      "32/32 - 0s - loss: 0.5111 - accuracy: 0.8211 - val_loss: 0.5070 - val_accuracy: 0.8185\n",
      "Epoch 100/250\n",
      "32/32 - 0s - loss: 0.5089 - accuracy: 0.8155 - val_loss: 0.5064 - val_accuracy: 0.8190\n",
      "Epoch 101/250\n",
      "32/32 - 0s - loss: 0.5083 - accuracy: 0.8202 - val_loss: 0.5064 - val_accuracy: 0.8200\n",
      "Epoch 102/250\n",
      "32/32 - 0s - loss: 0.5017 - accuracy: 0.8216 - val_loss: 0.5124 - val_accuracy: 0.8165\n",
      "Epoch 103/250\n",
      "32/32 - 0s - loss: 0.5093 - accuracy: 0.8209 - val_loss: 0.5086 - val_accuracy: 0.8190\n",
      "Epoch 104/250\n",
      "32/32 - 0s - loss: 0.5075 - accuracy: 0.8206 - val_loss: 0.5093 - val_accuracy: 0.8200\n",
      "Epoch 105/250\n",
      "32/32 - 0s - loss: 0.5042 - accuracy: 0.8215 - val_loss: 0.5023 - val_accuracy: 0.8220\n",
      "Epoch 106/250\n",
      "32/32 - 0s - loss: 0.5021 - accuracy: 0.8200 - val_loss: 0.5042 - val_accuracy: 0.8225\n",
      "Epoch 107/250\n",
      "32/32 - 0s - loss: 0.5034 - accuracy: 0.8226 - val_loss: 0.5074 - val_accuracy: 0.8210\n",
      "Epoch 108/250\n",
      "32/32 - 0s - loss: 0.5043 - accuracy: 0.8215 - val_loss: 0.5034 - val_accuracy: 0.8215\n",
      "Epoch 109/250\n",
      "32/32 - 0s - loss: 0.5014 - accuracy: 0.8201 - val_loss: 0.5098 - val_accuracy: 0.8190\n",
      "Epoch 110/250\n",
      "32/32 - 0s - loss: 0.5010 - accuracy: 0.8265 - val_loss: 0.5014 - val_accuracy: 0.8230\n",
      "Epoch 111/250\n",
      "32/32 - 0s - loss: 0.5002 - accuracy: 0.8211 - val_loss: 0.5062 - val_accuracy: 0.8220\n",
      "Epoch 112/250\n",
      "32/32 - 0s - loss: 0.5056 - accuracy: 0.8152 - val_loss: 0.5026 - val_accuracy: 0.8225\n",
      "Epoch 113/250\n",
      "32/32 - 0s - loss: 0.5016 - accuracy: 0.8255 - val_loss: 0.5039 - val_accuracy: 0.8200\n",
      "Epoch 114/250\n",
      "32/32 - 0s - loss: 0.5038 - accuracy: 0.8190 - val_loss: 0.5025 - val_accuracy: 0.8210\n",
      "Epoch 115/250\n",
      "32/32 - 0s - loss: 0.4991 - accuracy: 0.8248 - val_loss: 0.5015 - val_accuracy: 0.8220\n",
      "Epoch 116/250\n",
      "32/32 - 0s - loss: 0.5024 - accuracy: 0.8234 - val_loss: 0.5014 - val_accuracy: 0.8220\n",
      "Epoch 117/250\n",
      "32/32 - 0s - loss: 0.4968 - accuracy: 0.8253 - val_loss: 0.5075 - val_accuracy: 0.8155\n",
      "Epoch 118/250\n",
      "32/32 - 0s - loss: 0.4946 - accuracy: 0.8200 - val_loss: 0.4989 - val_accuracy: 0.8200\n",
      "Epoch 119/250\n",
      "32/32 - 0s - loss: 0.5045 - accuracy: 0.8183 - val_loss: 0.5018 - val_accuracy: 0.8225\n",
      "Epoch 120/250\n",
      "32/32 - 0s - loss: 0.4988 - accuracy: 0.8214 - val_loss: 0.5009 - val_accuracy: 0.8220\n",
      "Epoch 121/250\n",
      "32/32 - 0s - loss: 0.4946 - accuracy: 0.8251 - val_loss: 0.5078 - val_accuracy: 0.8185\n",
      "Epoch 122/250\n",
      "32/32 - 0s - loss: 0.4965 - accuracy: 0.8214 - val_loss: 0.5037 - val_accuracy: 0.8235\n",
      "Epoch 123/250\n",
      "32/32 - 0s - loss: 0.4974 - accuracy: 0.8265 - val_loss: 0.5006 - val_accuracy: 0.8240\n",
      "Epoch 124/250\n",
      "32/32 - 0s - loss: 0.4959 - accuracy: 0.8276 - val_loss: 0.5052 - val_accuracy: 0.8175\n",
      "Epoch 125/250\n",
      "32/32 - 0s - loss: 0.4908 - accuracy: 0.8251 - val_loss: 0.5001 - val_accuracy: 0.8230\n",
      "Epoch 126/250\n",
      "32/32 - 0s - loss: 0.4982 - accuracy: 0.8220 - val_loss: 0.5008 - val_accuracy: 0.8185\n",
      "Epoch 127/250\n",
      "32/32 - 0s - loss: 0.4971 - accuracy: 0.8274 - val_loss: 0.4997 - val_accuracy: 0.8265\n",
      "Epoch 128/250\n",
      "32/32 - 0s - loss: 0.4920 - accuracy: 0.8264 - val_loss: 0.5049 - val_accuracy: 0.8225\n",
      "Epoch 129/250\n",
      "32/32 - 0s - loss: 0.4953 - accuracy: 0.8246 - val_loss: 0.4993 - val_accuracy: 0.8230\n",
      "Epoch 130/250\n",
      "32/32 - 0s - loss: 0.4928 - accuracy: 0.8269 - val_loss: 0.4985 - val_accuracy: 0.8230\n",
      "Epoch 131/250\n",
      "32/32 - 0s - loss: 0.4950 - accuracy: 0.8256 - val_loss: 0.5023 - val_accuracy: 0.8195\n",
      "Epoch 132/250\n",
      "32/32 - 0s - loss: 0.4910 - accuracy: 0.8265 - val_loss: 0.4975 - val_accuracy: 0.8200\n",
      "Epoch 133/250\n",
      "32/32 - 0s - loss: 0.4949 - accuracy: 0.8219 - val_loss: 0.4992 - val_accuracy: 0.8245\n",
      "Epoch 134/250\n",
      "32/32 - 0s - loss: 0.4892 - accuracy: 0.8255 - val_loss: 0.4977 - val_accuracy: 0.8190\n",
      "Epoch 135/250\n",
      "32/32 - 0s - loss: 0.4934 - accuracy: 0.8248 - val_loss: 0.4985 - val_accuracy: 0.8220\n",
      "Epoch 136/250\n",
      "32/32 - 0s - loss: 0.4856 - accuracy: 0.8253 - val_loss: 0.4996 - val_accuracy: 0.8190\n",
      "Epoch 137/250\n",
      "32/32 - 0s - loss: 0.4886 - accuracy: 0.8291 - val_loss: 0.5010 - val_accuracy: 0.8215\n",
      "Epoch 138/250\n",
      "32/32 - 0s - loss: 0.4888 - accuracy: 0.8265 - val_loss: 0.5010 - val_accuracy: 0.8195\n",
      "Epoch 139/250\n",
      "32/32 - 0s - loss: 0.4972 - accuracy: 0.8275 - val_loss: 0.4995 - val_accuracy: 0.8235\n",
      "Epoch 140/250\n",
      "32/32 - 0s - loss: 0.4867 - accuracy: 0.8253 - val_loss: 0.4982 - val_accuracy: 0.8210\n",
      "Epoch 141/250\n",
      "32/32 - 0s - loss: 0.4889 - accuracy: 0.8265 - val_loss: 0.5000 - val_accuracy: 0.8215\n",
      "Epoch 142/250\n",
      "32/32 - 0s - loss: 0.4889 - accuracy: 0.8292 - val_loss: 0.4973 - val_accuracy: 0.8205\n",
      "Epoch 143/250\n",
      "32/32 - 0s - loss: 0.4900 - accuracy: 0.8259 - val_loss: 0.4954 - val_accuracy: 0.8240\n",
      "Epoch 144/250\n",
      "32/32 - 0s - loss: 0.4903 - accuracy: 0.8289 - val_loss: 0.4995 - val_accuracy: 0.8210\n",
      "Epoch 145/250\n",
      "32/32 - 0s - loss: 0.4871 - accuracy: 0.8278 - val_loss: 0.5002 - val_accuracy: 0.8225\n",
      "Epoch 146/250\n",
      "32/32 - 0s - loss: 0.4867 - accuracy: 0.8310 - val_loss: 0.5001 - val_accuracy: 0.8175\n",
      "Epoch 147/250\n",
      "32/32 - 0s - loss: 0.4918 - accuracy: 0.8259 - val_loss: 0.4997 - val_accuracy: 0.8215\n",
      "Epoch 148/250\n",
      "32/32 - 0s - loss: 0.4839 - accuracy: 0.8271 - val_loss: 0.5037 - val_accuracy: 0.8210\n",
      "Epoch 149/250\n",
      "32/32 - 0s - loss: 0.4894 - accuracy: 0.8270 - val_loss: 0.4962 - val_accuracy: 0.8235\n",
      "Epoch 150/250\n",
      "32/32 - 0s - loss: 0.4845 - accuracy: 0.8289 - val_loss: 0.4949 - val_accuracy: 0.8200\n",
      "Epoch 151/250\n",
      "32/32 - 0s - loss: 0.4836 - accuracy: 0.8304 - val_loss: 0.4975 - val_accuracy: 0.8215\n",
      "Epoch 152/250\n",
      "32/32 - 0s - loss: 0.4856 - accuracy: 0.8292 - val_loss: 0.4969 - val_accuracy: 0.8205\n",
      "Epoch 153/250\n",
      "32/32 - 0s - loss: 0.4861 - accuracy: 0.8273 - val_loss: 0.5019 - val_accuracy: 0.8220\n",
      "Epoch 154/250\n",
      "32/32 - 0s - loss: 0.4838 - accuracy: 0.8307 - val_loss: 0.5037 - val_accuracy: 0.8220\n",
      "Epoch 155/250\n",
      "32/32 - 0s - loss: 0.4874 - accuracy: 0.8300 - val_loss: 0.5019 - val_accuracy: 0.8240\n",
      "Epoch 156/250\n",
      "32/32 - 0s - loss: 0.4821 - accuracy: 0.8326 - val_loss: 0.4958 - val_accuracy: 0.8225\n",
      "Epoch 157/250\n",
      "32/32 - 0s - loss: 0.4814 - accuracy: 0.8280 - val_loss: 0.4973 - val_accuracy: 0.8210\n",
      "Epoch 158/250\n",
      "32/32 - 0s - loss: 0.4832 - accuracy: 0.8330 - val_loss: 0.4974 - val_accuracy: 0.8205\n",
      "Epoch 159/250\n",
      "32/32 - 0s - loss: 0.4830 - accuracy: 0.8261 - val_loss: 0.5011 - val_accuracy: 0.8245\n",
      "Epoch 160/250\n",
      "32/32 - 0s - loss: 0.4812 - accuracy: 0.8260 - val_loss: 0.4960 - val_accuracy: 0.8205\n",
      "Epoch 161/250\n",
      "32/32 - 0s - loss: 0.4838 - accuracy: 0.8269 - val_loss: 0.4962 - val_accuracy: 0.8225\n",
      "Epoch 162/250\n",
      "32/32 - 0s - loss: 0.4839 - accuracy: 0.8279 - val_loss: 0.4969 - val_accuracy: 0.8215\n",
      "Epoch 163/250\n",
      "32/32 - 0s - loss: 0.4832 - accuracy: 0.8261 - val_loss: 0.4947 - val_accuracy: 0.8210\n",
      "Epoch 164/250\n",
      "32/32 - 0s - loss: 0.4849 - accuracy: 0.8263 - val_loss: 0.4937 - val_accuracy: 0.8265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "32/32 - 0s - loss: 0.4829 - accuracy: 0.8256 - val_loss: 0.4951 - val_accuracy: 0.8265\n",
      "Epoch 166/250\n",
      "32/32 - 0s - loss: 0.4830 - accuracy: 0.8273 - val_loss: 0.4949 - val_accuracy: 0.8205\n",
      "Epoch 167/250\n",
      "32/32 - 0s - loss: 0.4851 - accuracy: 0.8271 - val_loss: 0.4937 - val_accuracy: 0.8265\n",
      "Epoch 168/250\n",
      "32/32 - 0s - loss: 0.4867 - accuracy: 0.8276 - val_loss: 0.5014 - val_accuracy: 0.8205\n",
      "Epoch 169/250\n",
      "32/32 - 0s - loss: 0.4823 - accuracy: 0.8273 - val_loss: 0.4949 - val_accuracy: 0.8225\n",
      "Epoch 170/250\n",
      "32/32 - 0s - loss: 0.4803 - accuracy: 0.8303 - val_loss: 0.4987 - val_accuracy: 0.8270\n",
      "Epoch 171/250\n",
      "32/32 - 0s - loss: 0.4860 - accuracy: 0.8296 - val_loss: 0.4928 - val_accuracy: 0.8245\n",
      "Epoch 172/250\n",
      "32/32 - 0s - loss: 0.4798 - accuracy: 0.8295 - val_loss: 0.4954 - val_accuracy: 0.8240\n",
      "Epoch 173/250\n",
      "32/32 - 0s - loss: 0.4856 - accuracy: 0.8289 - val_loss: 0.4941 - val_accuracy: 0.8250\n",
      "Epoch 174/250\n",
      "32/32 - 0s - loss: 0.4786 - accuracy: 0.8280 - val_loss: 0.5020 - val_accuracy: 0.8200\n",
      "Epoch 175/250\n",
      "32/32 - 0s - loss: 0.4851 - accuracy: 0.8231 - val_loss: 0.4925 - val_accuracy: 0.8245\n",
      "Epoch 176/250\n",
      "32/32 - 0s - loss: 0.4815 - accuracy: 0.8305 - val_loss: 0.5033 - val_accuracy: 0.8220\n",
      "Epoch 177/250\n",
      "32/32 - 0s - loss: 0.4827 - accuracy: 0.8286 - val_loss: 0.4917 - val_accuracy: 0.8215\n",
      "Epoch 178/250\n",
      "32/32 - 0s - loss: 0.4901 - accuracy: 0.8267 - val_loss: 0.4910 - val_accuracy: 0.8230\n",
      "Epoch 179/250\n",
      "32/32 - 0s - loss: 0.4809 - accuracy: 0.8259 - val_loss: 0.4898 - val_accuracy: 0.8215\n",
      "Epoch 180/250\n",
      "32/32 - 0s - loss: 0.4812 - accuracy: 0.8314 - val_loss: 0.4942 - val_accuracy: 0.8275\n",
      "Epoch 181/250\n",
      "32/32 - 0s - loss: 0.4791 - accuracy: 0.8294 - val_loss: 0.4953 - val_accuracy: 0.8200\n",
      "Epoch 182/250\n",
      "32/32 - 0s - loss: 0.4824 - accuracy: 0.8265 - val_loss: 0.4923 - val_accuracy: 0.8260\n",
      "Epoch 183/250\n",
      "32/32 - 0s - loss: 0.4803 - accuracy: 0.8300 - val_loss: 0.4923 - val_accuracy: 0.8220\n",
      "Epoch 184/250\n",
      "32/32 - 0s - loss: 0.4804 - accuracy: 0.8313 - val_loss: 0.4921 - val_accuracy: 0.8245\n",
      "Epoch 185/250\n",
      "32/32 - 0s - loss: 0.4830 - accuracy: 0.8286 - val_loss: 0.4981 - val_accuracy: 0.8220\n",
      "Epoch 186/250\n",
      "32/32 - 0s - loss: 0.4786 - accuracy: 0.8261 - val_loss: 0.4895 - val_accuracy: 0.8260\n",
      "Epoch 187/250\n",
      "32/32 - 0s - loss: 0.4731 - accuracy: 0.8315 - val_loss: 0.4887 - val_accuracy: 0.8255\n",
      "Epoch 188/250\n",
      "32/32 - 0s - loss: 0.4731 - accuracy: 0.8329 - val_loss: 0.4891 - val_accuracy: 0.8250\n",
      "Epoch 189/250\n",
      "32/32 - 0s - loss: 0.4791 - accuracy: 0.8296 - val_loss: 0.4934 - val_accuracy: 0.8260\n",
      "Epoch 190/250\n",
      "32/32 - 0s - loss: 0.4762 - accuracy: 0.8281 - val_loss: 0.4879 - val_accuracy: 0.8235\n",
      "Epoch 191/250\n",
      "32/32 - 0s - loss: 0.4744 - accuracy: 0.8310 - val_loss: 0.4887 - val_accuracy: 0.8230\n",
      "Epoch 192/250\n",
      "32/32 - 0s - loss: 0.4760 - accuracy: 0.8249 - val_loss: 0.4881 - val_accuracy: 0.8215\n",
      "Epoch 193/250\n",
      "32/32 - 0s - loss: 0.4745 - accuracy: 0.8304 - val_loss: 0.4905 - val_accuracy: 0.8220\n",
      "Epoch 194/250\n",
      "32/32 - 0s - loss: 0.4677 - accuracy: 0.8307 - val_loss: 0.4866 - val_accuracy: 0.8220\n",
      "Epoch 195/250\n",
      "32/32 - 0s - loss: 0.4766 - accuracy: 0.8310 - val_loss: 0.4987 - val_accuracy: 0.8225\n",
      "Epoch 196/250\n",
      "32/32 - 0s - loss: 0.4711 - accuracy: 0.8315 - val_loss: 0.4904 - val_accuracy: 0.8260\n",
      "Epoch 197/250\n",
      "32/32 - 0s - loss: 0.4715 - accuracy: 0.8331 - val_loss: 0.4897 - val_accuracy: 0.8255\n",
      "Epoch 198/250\n",
      "32/32 - 0s - loss: 0.4735 - accuracy: 0.8294 - val_loss: 0.4872 - val_accuracy: 0.8250\n",
      "Epoch 199/250\n",
      "32/32 - 0s - loss: 0.4763 - accuracy: 0.8325 - val_loss: 0.4964 - val_accuracy: 0.8210\n",
      "Epoch 200/250\n",
      "32/32 - 0s - loss: 0.4733 - accuracy: 0.8289 - val_loss: 0.4911 - val_accuracy: 0.8205\n",
      "Epoch 201/250\n",
      "32/32 - 0s - loss: 0.4702 - accuracy: 0.8326 - val_loss: 0.4931 - val_accuracy: 0.8235\n",
      "Epoch 202/250\n",
      "32/32 - 0s - loss: 0.4759 - accuracy: 0.8314 - val_loss: 0.4836 - val_accuracy: 0.8210\n",
      "Epoch 203/250\n",
      "32/32 - 0s - loss: 0.4746 - accuracy: 0.8286 - val_loss: 0.4854 - val_accuracy: 0.8230\n",
      "Epoch 204/250\n",
      "32/32 - 0s - loss: 0.4779 - accuracy: 0.8301 - val_loss: 0.4862 - val_accuracy: 0.8235\n",
      "Epoch 205/250\n",
      "32/32 - 0s - loss: 0.4665 - accuracy: 0.8363 - val_loss: 0.4846 - val_accuracy: 0.8225\n",
      "Epoch 206/250\n",
      "32/32 - 0s - loss: 0.4733 - accuracy: 0.8285 - val_loss: 0.4812 - val_accuracy: 0.8235\n",
      "Epoch 207/250\n",
      "32/32 - 0s - loss: 0.4693 - accuracy: 0.8303 - val_loss: 0.4842 - val_accuracy: 0.8270\n",
      "Epoch 208/250\n",
      "32/32 - 0s - loss: 0.4607 - accuracy: 0.8359 - val_loss: 0.4815 - val_accuracy: 0.8250\n",
      "Epoch 209/250\n",
      "32/32 - 0s - loss: 0.4705 - accuracy: 0.8351 - val_loss: 0.4893 - val_accuracy: 0.8225\n",
      "Epoch 210/250\n",
      "32/32 - 0s - loss: 0.4721 - accuracy: 0.8271 - val_loss: 0.4872 - val_accuracy: 0.8250\n",
      "Epoch 211/250\n",
      "32/32 - 0s - loss: 0.4707 - accuracy: 0.8322 - val_loss: 0.4839 - val_accuracy: 0.8250\n",
      "Epoch 212/250\n",
      "32/32 - 0s - loss: 0.4721 - accuracy: 0.8276 - val_loss: 0.4827 - val_accuracy: 0.8240\n",
      "Epoch 213/250\n",
      "32/32 - 0s - loss: 0.4616 - accuracy: 0.8339 - val_loss: 0.4849 - val_accuracy: 0.8245\n",
      "Epoch 214/250\n",
      "32/32 - 0s - loss: 0.4676 - accuracy: 0.8330 - val_loss: 0.4824 - val_accuracy: 0.8240\n",
      "Epoch 215/250\n",
      "32/32 - 0s - loss: 0.4652 - accuracy: 0.8310 - val_loss: 0.4837 - val_accuracy: 0.8225\n",
      "Epoch 216/250\n",
      "32/32 - 0s - loss: 0.4660 - accuracy: 0.8340 - val_loss: 0.4821 - val_accuracy: 0.8285\n",
      "Epoch 217/250\n",
      "32/32 - 0s - loss: 0.4637 - accuracy: 0.8301 - val_loss: 0.4834 - val_accuracy: 0.8265\n",
      "Epoch 218/250\n",
      "32/32 - 0s - loss: 0.4650 - accuracy: 0.8326 - val_loss: 0.4835 - val_accuracy: 0.8230\n",
      "Epoch 219/250\n",
      "32/32 - 0s - loss: 0.4662 - accuracy: 0.8322 - val_loss: 0.4839 - val_accuracy: 0.8245\n",
      "Epoch 220/250\n",
      "32/32 - 0s - loss: 0.4612 - accuracy: 0.8314 - val_loss: 0.4793 - val_accuracy: 0.8200\n",
      "Epoch 221/250\n",
      "32/32 - 0s - loss: 0.4605 - accuracy: 0.8349 - val_loss: 0.4842 - val_accuracy: 0.8240\n",
      "Epoch 222/250\n",
      "32/32 - 0s - loss: 0.4635 - accuracy: 0.8285 - val_loss: 0.4823 - val_accuracy: 0.8250\n",
      "Epoch 223/250\n",
      "32/32 - 0s - loss: 0.4594 - accuracy: 0.8363 - val_loss: 0.4817 - val_accuracy: 0.8270\n",
      "Epoch 224/250\n",
      "32/32 - 0s - loss: 0.4653 - accuracy: 0.8351 - val_loss: 0.4804 - val_accuracy: 0.8245\n",
      "Epoch 225/250\n",
      "32/32 - 0s - loss: 0.4610 - accuracy: 0.8372 - val_loss: 0.4788 - val_accuracy: 0.8260\n",
      "Epoch 226/250\n",
      "32/32 - 0s - loss: 0.4618 - accuracy: 0.8309 - val_loss: 0.4852 - val_accuracy: 0.8175\n",
      "Epoch 227/250\n",
      "32/32 - 0s - loss: 0.4614 - accuracy: 0.8328 - val_loss: 0.4772 - val_accuracy: 0.8235\n",
      "Epoch 228/250\n",
      "32/32 - 0s - loss: 0.4637 - accuracy: 0.8334 - val_loss: 0.4838 - val_accuracy: 0.8275\n",
      "Epoch 229/250\n",
      "32/32 - 0s - loss: 0.4626 - accuracy: 0.8347 - val_loss: 0.4824 - val_accuracy: 0.8245\n",
      "Epoch 230/250\n",
      "32/32 - 0s - loss: 0.4671 - accuracy: 0.8326 - val_loss: 0.4838 - val_accuracy: 0.8260\n",
      "Epoch 231/250\n",
      "32/32 - 0s - loss: 0.4632 - accuracy: 0.8357 - val_loss: 0.4803 - val_accuracy: 0.8255\n",
      "Epoch 232/250\n",
      "32/32 - 0s - loss: 0.4611 - accuracy: 0.8357 - val_loss: 0.4779 - val_accuracy: 0.8235\n",
      "Epoch 233/250\n",
      "32/32 - 0s - loss: 0.4634 - accuracy: 0.8363 - val_loss: 0.4798 - val_accuracy: 0.8275\n",
      "Epoch 234/250\n",
      "32/32 - 0s - loss: 0.4572 - accuracy: 0.8357 - val_loss: 0.4797 - val_accuracy: 0.8230\n",
      "Epoch 235/250\n",
      "32/32 - 0s - loss: 0.4654 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.8245\n",
      "Epoch 236/250\n",
      "32/32 - 0s - loss: 0.4570 - accuracy: 0.8382 - val_loss: 0.4770 - val_accuracy: 0.8280\n",
      "Epoch 237/250\n",
      "32/32 - 0s - loss: 0.4555 - accuracy: 0.8349 - val_loss: 0.4752 - val_accuracy: 0.8255\n",
      "Epoch 238/250\n",
      "32/32 - 0s - loss: 0.4610 - accuracy: 0.8356 - val_loss: 0.4767 - val_accuracy: 0.8260\n",
      "Epoch 239/250\n",
      "32/32 - 0s - loss: 0.4618 - accuracy: 0.8369 - val_loss: 0.4785 - val_accuracy: 0.8255\n",
      "Epoch 240/250\n",
      "32/32 - 0s - loss: 0.4624 - accuracy: 0.8353 - val_loss: 0.4782 - val_accuracy: 0.8250\n",
      "Epoch 241/250\n",
      "32/32 - 0s - loss: 0.4634 - accuracy: 0.8351 - val_loss: 0.4798 - val_accuracy: 0.8240\n",
      "Epoch 242/250\n",
      "32/32 - 0s - loss: 0.4627 - accuracy: 0.8345 - val_loss: 0.4755 - val_accuracy: 0.8255\n",
      "Epoch 243/250\n",
      "32/32 - 0s - loss: 0.4642 - accuracy: 0.8364 - val_loss: 0.4830 - val_accuracy: 0.8240\n",
      "Epoch 244/250\n",
      "32/32 - 0s - loss: 0.4631 - accuracy: 0.8324 - val_loss: 0.4815 - val_accuracy: 0.8290\n",
      "Epoch 245/250\n",
      "32/32 - 0s - loss: 0.4568 - accuracy: 0.8382 - val_loss: 0.4779 - val_accuracy: 0.8245\n",
      "Epoch 246/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4620 - accuracy: 0.8370 - val_loss: 0.4763 - val_accuracy: 0.8230\n",
      "Epoch 247/250\n",
      "32/32 - 0s - loss: 0.4555 - accuracy: 0.8379 - val_loss: 0.4762 - val_accuracy: 0.8290\n",
      "Epoch 248/250\n",
      "32/32 - 0s - loss: 0.4658 - accuracy: 0.8307 - val_loss: 0.4738 - val_accuracy: 0.8260\n",
      "Epoch 249/250\n",
      "32/32 - 0s - loss: 0.4585 - accuracy: 0.8355 - val_loss: 0.4786 - val_accuracy: 0.8300\n",
      "Epoch 250/250\n",
      "32/32 - 0s - loss: 0.4617 - accuracy: 0.8370 - val_loss: 0.4789 - val_accuracy: 0.8245\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = 250, epochs = 250, \n",
    "                 validation_data = (x_val, y_val), \n",
    "                verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(categ[N_train:],np.argmax(model.predict(x_val), axis=1),  normalize = 'true')\n",
    "\n",
    "\n",
    "#Better visualization of confusion matrices\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize = (15, 8))\n",
    "ax1.matshow(c_matrix, cmap = plt.cm.YlGn, alpha = 0.5)\n",
    "ax1.set_xticks(np.arange(3))\n",
    "ax1.set_yticks(np.arange(3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax1.text(x=j, y=i, s=round(c_matrix[i, j],2), ha=\"center\", va=\"center\")\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.set_xlabel('predicted label')\n",
    "ax1.set_ylabel('true label')\n",
    "ax1.set_title('CNN')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Discrimination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1016 - accuracy: 0.3305 - val_loss: 1.1004 - val_accuracy: 0.3400\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3359 - val_loss: 1.1001 - val_accuracy: 0.3365\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3346 - val_loss: 1.0999 - val_accuracy: 0.3605\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3347 - val_loss: 1.0999 - val_accuracy: 0.3595\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.1001 - accuracy: 0.3356 - val_loss: 1.0999 - val_accuracy: 0.3525\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.1001 - accuracy: 0.3400 - val_loss: 1.0998 - val_accuracy: 0.3490\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3352 - val_loss: 1.0998 - val_accuracy: 0.3490\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3428 - val_loss: 1.0997 - val_accuracy: 0.3580\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.1003 - accuracy: 0.3346 - val_loss: 1.0997 - val_accuracy: 0.3520\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.1001 - accuracy: 0.3375 - val_loss: 1.0997 - val_accuracy: 0.3565\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0997 - accuracy: 0.3439 - val_loss: 1.0997 - val_accuracy: 0.3485\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0998 - accuracy: 0.3416 - val_loss: 1.0997 - val_accuracy: 0.3510\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0999 - accuracy: 0.3408 - val_loss: 1.0996 - val_accuracy: 0.3575\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3396 - val_loss: 1.0996 - val_accuracy: 0.3575\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0996 - accuracy: 0.3436 - val_loss: 1.0996 - val_accuracy: 0.3480\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1020 - accuracy: 0.3316 - val_loss: 1.1008 - val_accuracy: 0.3240\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.1008 - accuracy: 0.3345 - val_loss: 1.1004 - val_accuracy: 0.3350\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.1004 - accuracy: 0.3330 - val_loss: 1.1003 - val_accuracy: 0.3345\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.1005 - accuracy: 0.3354 - val_loss: 1.1003 - val_accuracy: 0.3445\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.1005 - accuracy: 0.3351 - val_loss: 1.1002 - val_accuracy: 0.3460\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.1001 - accuracy: 0.3369 - val_loss: 1.1002 - val_accuracy: 0.3390\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.1001 - accuracy: 0.3404 - val_loss: 1.1002 - val_accuracy: 0.3425\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3390 - val_loss: 1.1002 - val_accuracy: 0.3365\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3350 - val_loss: 1.1002 - val_accuracy: 0.3380\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.1000 - accuracy: 0.3351 - val_loss: 1.1001 - val_accuracy: 0.3370\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0998 - accuracy: 0.3366 - val_loss: 1.1002 - val_accuracy: 0.3360\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0992 - accuracy: 0.3449 - val_loss: 1.1001 - val_accuracy: 0.3395\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0996 - accuracy: 0.3410 - val_loss: 1.1001 - val_accuracy: 0.3375\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.0995 - accuracy: 0.3428 - val_loss: 1.1001 - val_accuracy: 0.3375\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3526 - val_loss: 1.1001 - val_accuracy: 0.3390\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1019 - accuracy: 0.3334 - val_loss: 1.1008 - val_accuracy: 0.3390\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.1005 - accuracy: 0.3326 - val_loss: 1.1005 - val_accuracy: 0.3250\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0998 - accuracy: 0.3390 - val_loss: 1.1005 - val_accuracy: 0.3285\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.1002 - accuracy: 0.3364 - val_loss: 1.1004 - val_accuracy: 0.3275\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0998 - accuracy: 0.3338 - val_loss: 1.1004 - val_accuracy: 0.3235\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0999 - accuracy: 0.3339 - val_loss: 1.1003 - val_accuracy: 0.3230\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0997 - accuracy: 0.3330 - val_loss: 1.1002 - val_accuracy: 0.3280\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0999 - accuracy: 0.3399 - val_loss: 1.1002 - val_accuracy: 0.3225\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0995 - accuracy: 0.3377 - val_loss: 1.1001 - val_accuracy: 0.3280\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3411 - val_loss: 1.1001 - val_accuracy: 0.3305\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0994 - accuracy: 0.3425 - val_loss: 1.1000 - val_accuracy: 0.3375\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0994 - accuracy: 0.3389 - val_loss: 1.0998 - val_accuracy: 0.3370\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0994 - accuracy: 0.3433 - val_loss: 1.0998 - val_accuracy: 0.3260\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.0990 - accuracy: 0.3481 - val_loss: 1.0996 - val_accuracy: 0.3430\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0992 - accuracy: 0.3511 - val_loss: 1.0996 - val_accuracy: 0.3395\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1013 - accuracy: 0.3310 - val_loss: 1.1009 - val_accuracy: 0.3290\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.0999 - accuracy: 0.3451 - val_loss: 1.1003 - val_accuracy: 0.3465\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0995 - accuracy: 0.3459 - val_loss: 1.0998 - val_accuracy: 0.3460\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0993 - accuracy: 0.3517 - val_loss: 1.0995 - val_accuracy: 0.3530\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0985 - accuracy: 0.3566 - val_loss: 1.0991 - val_accuracy: 0.3580\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0986 - accuracy: 0.3573 - val_loss: 1.0988 - val_accuracy: 0.3585\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0980 - accuracy: 0.3630 - val_loss: 1.0985 - val_accuracy: 0.3585\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0980 - accuracy: 0.3674 - val_loss: 1.0982 - val_accuracy: 0.3640\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0980 - accuracy: 0.3599 - val_loss: 1.0980 - val_accuracy: 0.3550\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0980 - accuracy: 0.3565 - val_loss: 1.0978 - val_accuracy: 0.3600\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0973 - accuracy: 0.3669 - val_loss: 1.0973 - val_accuracy: 0.3595\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0977 - accuracy: 0.3556 - val_loss: 1.0971 - val_accuracy: 0.3585\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0973 - accuracy: 0.3585 - val_loss: 1.0969 - val_accuracy: 0.3525\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.0960 - accuracy: 0.3650 - val_loss: 1.0963 - val_accuracy: 0.3665\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0963 - accuracy: 0.3656 - val_loss: 1.0960 - val_accuracy: 0.3590\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1024 - accuracy: 0.3307 - val_loss: 1.1010 - val_accuracy: 0.3220\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.1002 - accuracy: 0.3340 - val_loss: 1.1006 - val_accuracy: 0.3310\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0995 - accuracy: 0.3434 - val_loss: 1.1003 - val_accuracy: 0.3340\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0989 - accuracy: 0.3456 - val_loss: 1.0999 - val_accuracy: 0.3385\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0982 - accuracy: 0.3544 - val_loss: 1.0996 - val_accuracy: 0.3450\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0978 - accuracy: 0.3550 - val_loss: 1.0993 - val_accuracy: 0.3420\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0977 - accuracy: 0.3531 - val_loss: 1.0988 - val_accuracy: 0.3490\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0975 - accuracy: 0.3618 - val_loss: 1.0984 - val_accuracy: 0.3435\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0968 - accuracy: 0.3621 - val_loss: 1.0981 - val_accuracy: 0.3555\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0958 - accuracy: 0.3716 - val_loss: 1.0976 - val_accuracy: 0.3635\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0957 - accuracy: 0.3742 - val_loss: 1.0973 - val_accuracy: 0.3605\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3725 - val_loss: 1.0968 - val_accuracy: 0.3670\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0948 - accuracy: 0.3740 - val_loss: 1.0963 - val_accuracy: 0.3670\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.0947 - accuracy: 0.3746 - val_loss: 1.0959 - val_accuracy: 0.3645\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0933 - accuracy: 0.3750 - val_loss: 1.0952 - val_accuracy: 0.3735\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1019 - accuracy: 0.3334 - val_loss: 1.0999 - val_accuracy: 0.3510\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.0997 - accuracy: 0.3476 - val_loss: 1.0983 - val_accuracy: 0.3715\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0979 - accuracy: 0.3655 - val_loss: 1.0970 - val_accuracy: 0.3765\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0972 - accuracy: 0.3668 - val_loss: 1.0958 - val_accuracy: 0.3790\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0963 - accuracy: 0.3669 - val_loss: 1.0942 - val_accuracy: 0.3880\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0943 - accuracy: 0.3806 - val_loss: 1.0921 - val_accuracy: 0.3865\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0916 - accuracy: 0.3814 - val_loss: 1.0899 - val_accuracy: 0.3795\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0905 - accuracy: 0.3891 - val_loss: 1.0870 - val_accuracy: 0.3920\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0879 - accuracy: 0.3899 - val_loss: 1.0845 - val_accuracy: 0.4005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0858 - accuracy: 0.3985 - val_loss: 1.0806 - val_accuracy: 0.4125\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0831 - accuracy: 0.3971 - val_loss: 1.0776 - val_accuracy: 0.4200\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0803 - accuracy: 0.3994 - val_loss: 1.0740 - val_accuracy: 0.4240\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0775 - accuracy: 0.4084 - val_loss: 1.0701 - val_accuracy: 0.4315\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.0741 - accuracy: 0.4179 - val_loss: 1.0671 - val_accuracy: 0.4430\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0694 - accuracy: 0.4216 - val_loss: 1.0625 - val_accuracy: 0.4395\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1017 - accuracy: 0.3314 - val_loss: 1.1002 - val_accuracy: 0.3410\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.0984 - accuracy: 0.3599 - val_loss: 1.0974 - val_accuracy: 0.3790\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0959 - accuracy: 0.3729 - val_loss: 1.0949 - val_accuracy: 0.3885\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0944 - accuracy: 0.3819 - val_loss: 1.0921 - val_accuracy: 0.4045\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0917 - accuracy: 0.3889 - val_loss: 1.0889 - val_accuracy: 0.4150\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0891 - accuracy: 0.3991 - val_loss: 1.0854 - val_accuracy: 0.4185\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0854 - accuracy: 0.4015 - val_loss: 1.0805 - val_accuracy: 0.4235\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0813 - accuracy: 0.4015 - val_loss: 1.0747 - val_accuracy: 0.4265\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0760 - accuracy: 0.4090 - val_loss: 1.0688 - val_accuracy: 0.4425\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0724 - accuracy: 0.4094 - val_loss: 1.0623 - val_accuracy: 0.4485\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0649 - accuracy: 0.4195 - val_loss: 1.0539 - val_accuracy: 0.4505\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 1.0581 - accuracy: 0.4296 - val_loss: 1.0459 - val_accuracy: 0.4505\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 1.0515 - accuracy: 0.4325 - val_loss: 1.0420 - val_accuracy: 0.4550\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 1.0423 - accuracy: 0.4555 - val_loss: 1.0304 - val_accuracy: 0.4715\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 1.0323 - accuracy: 0.4572 - val_loss: 1.0219 - val_accuracy: 0.4705\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1009 - accuracy: 0.3459 - val_loss: 1.0989 - val_accuracy: 0.3515\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.0960 - accuracy: 0.3704 - val_loss: 1.0955 - val_accuracy: 0.3780\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0923 - accuracy: 0.3880 - val_loss: 1.0918 - val_accuracy: 0.3970\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0870 - accuracy: 0.4065 - val_loss: 1.0865 - val_accuracy: 0.4150\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0819 - accuracy: 0.4046 - val_loss: 1.0797 - val_accuracy: 0.4200\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0746 - accuracy: 0.4194 - val_loss: 1.0715 - val_accuracy: 0.4180\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0637 - accuracy: 0.4259 - val_loss: 1.0620 - val_accuracy: 0.4260\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0542 - accuracy: 0.4333 - val_loss: 1.0505 - val_accuracy: 0.4410\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0425 - accuracy: 0.4520 - val_loss: 1.0386 - val_accuracy: 0.4580\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0278 - accuracy: 0.4600 - val_loss: 1.0248 - val_accuracy: 0.4710\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 1.0133 - accuracy: 0.4757 - val_loss: 1.0103 - val_accuracy: 0.4760\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 0.9940 - accuracy: 0.4889 - val_loss: 0.9924 - val_accuracy: 0.4945\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 0.9820 - accuracy: 0.4933 - val_loss: 0.9820 - val_accuracy: 0.5140\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 0.9686 - accuracy: 0.5073 - val_loss: 0.9686 - val_accuracy: 0.5230\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 0.9518 - accuracy: 0.5190 - val_loss: 0.9588 - val_accuracy: 0.5230\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1011 - accuracy: 0.3401 - val_loss: 1.0976 - val_accuracy: 0.3625\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.0951 - accuracy: 0.3744 - val_loss: 1.0931 - val_accuracy: 0.3930\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0900 - accuracy: 0.4083 - val_loss: 1.0878 - val_accuracy: 0.4065\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0850 - accuracy: 0.4128 - val_loss: 1.0815 - val_accuracy: 0.4305\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0775 - accuracy: 0.4236 - val_loss: 1.0732 - val_accuracy: 0.4410\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0698 - accuracy: 0.4301 - val_loss: 1.0629 - val_accuracy: 0.4550\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0579 - accuracy: 0.4397 - val_loss: 1.0496 - val_accuracy: 0.4635\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0463 - accuracy: 0.4510 - val_loss: 1.0350 - val_accuracy: 0.4730\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0298 - accuracy: 0.4602 - val_loss: 1.0199 - val_accuracy: 0.4960\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 1.0135 - accuracy: 0.4756 - val_loss: 0.9997 - val_accuracy: 0.5020\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 0.9965 - accuracy: 0.4918 - val_loss: 0.9789 - val_accuracy: 0.5330\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 0.9716 - accuracy: 0.5110 - val_loss: 0.9543 - val_accuracy: 0.5370\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 0.9480 - accuracy: 0.5312 - val_loss: 0.9313 - val_accuracy: 0.5580\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 0.9248 - accuracy: 0.5506 - val_loss: 0.9070 - val_accuracy: 0.5675\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 0.9095 - accuracy: 0.5546 - val_loss: 0.8923 - val_accuracy: 0.5915\n",
      "Epoch 1/15\n",
      "32/32 - 0s - loss: 1.1007 - accuracy: 0.3410 - val_loss: 1.0965 - val_accuracy: 0.3590\n",
      "Epoch 2/15\n",
      "32/32 - 0s - loss: 1.0949 - accuracy: 0.3756 - val_loss: 1.0929 - val_accuracy: 0.3965\n",
      "Epoch 3/15\n",
      "32/32 - 0s - loss: 1.0895 - accuracy: 0.4134 - val_loss: 1.0871 - val_accuracy: 0.4220\n",
      "Epoch 4/15\n",
      "32/32 - 0s - loss: 1.0836 - accuracy: 0.4199 - val_loss: 1.0796 - val_accuracy: 0.4290\n",
      "Epoch 5/15\n",
      "32/32 - 0s - loss: 1.0765 - accuracy: 0.4191 - val_loss: 1.0705 - val_accuracy: 0.4475\n",
      "Epoch 6/15\n",
      "32/32 - 0s - loss: 1.0638 - accuracy: 0.4406 - val_loss: 1.0579 - val_accuracy: 0.4565\n",
      "Epoch 7/15\n",
      "32/32 - 0s - loss: 1.0511 - accuracy: 0.4495 - val_loss: 1.0426 - val_accuracy: 0.4700\n",
      "Epoch 8/15\n",
      "32/32 - 0s - loss: 1.0361 - accuracy: 0.4600 - val_loss: 1.0257 - val_accuracy: 0.4865\n",
      "Epoch 9/15\n",
      "32/32 - 0s - loss: 1.0171 - accuracy: 0.4735 - val_loss: 1.0077 - val_accuracy: 0.5055\n",
      "Epoch 10/15\n",
      "32/32 - 0s - loss: 0.9985 - accuracy: 0.4865 - val_loss: 0.9879 - val_accuracy: 0.5090\n",
      "Epoch 11/15\n",
      "32/32 - 0s - loss: 0.9729 - accuracy: 0.5107 - val_loss: 0.9637 - val_accuracy: 0.5265\n",
      "Epoch 12/15\n",
      "32/32 - 0s - loss: 0.9478 - accuracy: 0.5311 - val_loss: 0.9339 - val_accuracy: 0.5550\n",
      "Epoch 13/15\n",
      "32/32 - 0s - loss: 0.9116 - accuracy: 0.5541 - val_loss: 0.8945 - val_accuracy: 0.5835\n",
      "Epoch 14/15\n",
      "32/32 - 0s - loss: 0.8808 - accuracy: 0.5794 - val_loss: 0.8748 - val_accuracy: 0.5950\n",
      "Epoch 15/15\n",
      "32/32 - 0s - loss: 0.8562 - accuracy: 0.5880 - val_loss: 0.8534 - val_accuracy: 0.6025\n"
     ]
    }
   ],
   "source": [
    "As = np.linspace(50,500,10)\n",
    "res = []\n",
    "\n",
    "y_predicted_list = []\n",
    "\n",
    "for A in As:\n",
    "    str0 = f\"ts_L60_Z12_A{A}_DX50_bias5_N10000\"\n",
    "    fnamex = \"DATA/x_\" + str0 + \".csv\"\n",
    "    fnamey = \"DATA/y_\" + str0 + \".csv\"\n",
    "\n",
    "    x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_std =  scaler.fit_transform(x.T).T\n",
    "    categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "    N_categ = 3\n",
    "    y = np.zeros((N,N_categ))\n",
    "\n",
    "    for n in range(N):\n",
    "        y[n][categ[n]] = 1.\n",
    "\n",
    "    perc_train = 0.8\n",
    "    N_train = int(N*perc_train)\n",
    "    N_val = N-N_train\n",
    "\n",
    "    x_train = x_std[:N_train]\n",
    "    y_train = y[:N_train]\n",
    "    x_val = x_std[N_train:]\n",
    "    y_val = y[N_train:]\n",
    "\n",
    "\n",
    "    L = len(x[0])\n",
    "    x_train = x_train.reshape(x_train.shape[0],L,1) #1 - channel (RGB:3)\n",
    "                                                   # L = sample size\n",
    "    x_val = x_val.reshape(x_val.shape[0],L,1)\n",
    "\n",
    "    input_shape = (L,1)\n",
    "\n",
    "    model.load_weights(\"Original_Weights_CNN1.h5\")\n",
    "    hist = model.fit(x_train, y_train, batch_size = 250, epochs = 15, \n",
    "                 validation_data = (x_val, y_val), \n",
    "                verbose = 2, shuffle = True)\n",
    "    res.append(pd.DataFrame(hist.history).iloc[:,-1])\n",
    "    y_predicted_list.append(np.argmax(model.predict(x_val), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better visualization of confusion matrices\n",
    "fig, ax1 = plt.subplots(nrows=3, ncols=3, figsize = (15, 8))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        c_matrix = confusion_matrix(categ[N_train:],y_predicted_list[3*i+j],  normalize = 'true')\n",
    "        ax1[i,j].matshow(c_matrix, cmap = plt.cm.YlGn, alpha = 0.5)\n",
    "        ax1[i,j].set_xticks(np.arange(3))\n",
    "        ax1[i,j].set_yticks(np.arange(3))\n",
    "        for l in range(3):\n",
    "            for m in range(3):\n",
    "                ax1[i,j].text(x=l, y=m, s=round(c_matrix[m, l],2), ha=\"center\", va=\"center\")\n",
    "        ax1[i,j].xaxis.set_ticks_position('bottom')\n",
    "        ax1[i,j].set_xlabel('predicted label')\n",
    "        ax1[i,j].set_ylabel('true label')\n",
    "        ax1[i,j].set_title(f\"AmplitudeToNoiseRatio: {As[3*i+j]/50} \")\n",
    "        fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(res).save_txt(\"Results_Discrimination.csv\")\n",
    "np.asarray(y_predicted_list).save_txt(\"Results_YPredicted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POINT 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt(\"DATA/x_ts_comp_N10000.csv\", delimiter =\",\")\n",
    "categ_y = np.loadtxt(\"DATA/y_ts_comp_N10000.csv\", delimiter =\",\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x =  scaler.fit_transform(x.T).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(categ_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(x[0])\n",
    "input_shape = (len(x[0]),1)\n",
    "N_categ = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2)\n",
    "x_train = x_train.reshape(x_train.shape[0],L,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 51, 4)             44        \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 597\n",
      "Trainable params: 597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=4, kernel_size = 10,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 7ms/step - loss: 1.1015 - accuracy: 0.3261 - val_loss: 1.0953 - val_accuracy: 0.3585\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0947 - accuracy: 0.3590 - val_loss: 1.0916 - val_accuracy: 0.3780\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.3908 - val_loss: 1.0841 - val_accuracy: 0.3810\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0807 - accuracy: 0.4071 - val_loss: 1.0740 - val_accuracy: 0.4105\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0703 - accuracy: 0.4142 - val_loss: 1.0557 - val_accuracy: 0.4165\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0509 - accuracy: 0.4374 - val_loss: 1.0393 - val_accuracy: 0.4300\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0354 - accuracy: 0.4437 - val_loss: 1.0237 - val_accuracy: 0.4495\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.4545 - val_loss: 1.0074 - val_accuracy: 0.4500\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.4708 - val_loss: 0.9908 - val_accuracy: 0.4690\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9818 - accuracy: 0.4985 - val_loss: 0.9683 - val_accuracy: 0.4810\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9653 - accuracy: 0.4966 - val_loss: 0.9431 - val_accuracy: 0.4825\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9399 - accuracy: 0.5014 - val_loss: 0.9127 - val_accuracy: 0.4990\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9093 - accuracy: 0.5236 - val_loss: 0.8883 - val_accuracy: 0.5325\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8701 - accuracy: 0.5596 - val_loss: 0.8549 - val_accuracy: 0.5600\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8550 - accuracy: 0.5603 - val_loss: 0.8216 - val_accuracy: 0.5865\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.5813 - val_loss: 0.7917 - val_accuracy: 0.6140\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.5994 - val_loss: 0.7686 - val_accuracy: 0.6315\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.6216 - val_loss: 0.7550 - val_accuracy: 0.6435\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7714 - accuracy: 0.6159 - val_loss: 0.7463 - val_accuracy: 0.6505\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.6303 - val_loss: 0.7318 - val_accuracy: 0.6615\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.6349 - val_loss: 0.7300 - val_accuracy: 0.6555\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.6376 - val_loss: 0.7190 - val_accuracy: 0.6675\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7454 - accuracy: 0.6488 - val_loss: 0.7200 - val_accuracy: 0.6645\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7404 - accuracy: 0.6481 - val_loss: 0.7172 - val_accuracy: 0.6680\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7404 - accuracy: 0.6506 - val_loss: 0.7127 - val_accuracy: 0.6650\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7382 - accuracy: 0.6544 - val_loss: 0.7120 - val_accuracy: 0.6635\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.6573 - val_loss: 0.7113 - val_accuracy: 0.6680\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.6534 - val_loss: 0.7068 - val_accuracy: 0.6690\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7278 - accuracy: 0.6620 - val_loss: 0.7042 - val_accuracy: 0.6745\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.6579 - val_loss: 0.7051 - val_accuracy: 0.6715\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7180 - accuracy: 0.6667 - val_loss: 0.7049 - val_accuracy: 0.6705\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.6656 - val_loss: 0.7028 - val_accuracy: 0.6665\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7167 - accuracy: 0.6648 - val_loss: 0.7032 - val_accuracy: 0.6695\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7174 - accuracy: 0.6685 - val_loss: 0.7055 - val_accuracy: 0.6775\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.6650 - val_loss: 0.7022 - val_accuracy: 0.6760\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.6677 - val_loss: 0.7015 - val_accuracy: 0.6715\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.6618 - val_loss: 0.6977 - val_accuracy: 0.6740\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.6708 - val_loss: 0.6997 - val_accuracy: 0.6770\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.6725 - val_loss: 0.6977 - val_accuracy: 0.6710\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.6678 - val_loss: 0.6954 - val_accuracy: 0.6745\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.6821 - val_loss: 0.6956 - val_accuracy: 0.6730\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.6771 - val_loss: 0.6967 - val_accuracy: 0.6730\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.6773 - val_loss: 0.6934 - val_accuracy: 0.6725\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.6722 - val_loss: 0.6962 - val_accuracy: 0.6745\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.6817 - val_loss: 0.6924 - val_accuracy: 0.6730\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6735 - val_loss: 0.6944 - val_accuracy: 0.6675\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.6791 - val_loss: 0.6948 - val_accuracy: 0.6715\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6858 - val_loss: 0.6924 - val_accuracy: 0.6755\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.6783 - val_loss: 0.6962 - val_accuracy: 0.6720\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6752 - val_loss: 0.6987 - val_accuracy: 0.6755\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.6726 - val_loss: 0.6916 - val_accuracy: 0.6740\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6796 - val_loss: 0.6939 - val_accuracy: 0.6710\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6679 - val_loss: 0.6920 - val_accuracy: 0.6735\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.6769 - val_loss: 0.7011 - val_accuracy: 0.6740\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.6722 - val_loss: 0.6974 - val_accuracy: 0.6770\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6890 - val_loss: 0.6867 - val_accuracy: 0.6715\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.6821 - val_loss: 0.6905 - val_accuracy: 0.6760\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.6838 - val_loss: 0.6956 - val_accuracy: 0.6775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.6763 - val_loss: 0.6930 - val_accuracy: 0.6770\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6859 - val_loss: 0.6873 - val_accuracy: 0.6800\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.6836 - val_loss: 0.6878 - val_accuracy: 0.6760\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6855 - val_loss: 0.6882 - val_accuracy: 0.6745\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6900 - val_loss: 0.6838 - val_accuracy: 0.6770\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6889 - val_loss: 0.6865 - val_accuracy: 0.6735\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6848 - val_loss: 0.6848 - val_accuracy: 0.6765\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.6847 - val_loss: 0.6860 - val_accuracy: 0.6765\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.6808 - val_loss: 0.6851 - val_accuracy: 0.6790\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6885 - val_loss: 0.7020 - val_accuracy: 0.6760\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.6829 - val_loss: 0.6943 - val_accuracy: 0.6725\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.6841 - val_loss: 0.6867 - val_accuracy: 0.6770\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6825 - val_loss: 0.6843 - val_accuracy: 0.6760\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6856 - val_loss: 0.6889 - val_accuracy: 0.6790\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.6841 - val_loss: 0.6820 - val_accuracy: 0.6750\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6793 - val_loss: 0.6818 - val_accuracy: 0.6715\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.6909 - val_loss: 0.6818 - val_accuracy: 0.6740\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.6800 - val_loss: 0.6819 - val_accuracy: 0.6795\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6886 - val_loss: 0.6896 - val_accuracy: 0.6850\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6775 - val_loss: 0.6811 - val_accuracy: 0.6760\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6856 - val_loss: 0.6814 - val_accuracy: 0.6775\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.6825 - val_loss: 0.6872 - val_accuracy: 0.6860\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6834 - val_loss: 0.6815 - val_accuracy: 0.6765\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.6955 - val_loss: 0.6816 - val_accuracy: 0.6805\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6815 - val_loss: 0.6838 - val_accuracy: 0.6885\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6952 - val_loss: 0.6835 - val_accuracy: 0.6855\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.6899 - val_loss: 0.7010 - val_accuracy: 0.6820\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6847 - val_loss: 0.6826 - val_accuracy: 0.6835\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6792 - val_loss: 0.6866 - val_accuracy: 0.6860\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6884 - val_loss: 0.6784 - val_accuracy: 0.6820\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6896 - val_loss: 0.6795 - val_accuracy: 0.6820\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6848 - val_loss: 0.6783 - val_accuracy: 0.6865\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6905 - val_loss: 0.6809 - val_accuracy: 0.6840\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.6832 - val_loss: 0.6811 - val_accuracy: 0.6840\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6891 - val_loss: 0.6888 - val_accuracy: 0.6820\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.6856 - val_loss: 0.6755 - val_accuracy: 0.6830\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6818 - val_loss: 0.6784 - val_accuracy: 0.6870\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6956 - val_loss: 0.6761 - val_accuracy: 0.6875\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6930 - val_loss: 0.6748 - val_accuracy: 0.6855\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6920 - val_loss: 0.6783 - val_accuracy: 0.6865\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.6879 - val_loss: 0.6772 - val_accuracy: 0.6895\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6903 - val_loss: 0.6769 - val_accuracy: 0.6865\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.6909 - val_loss: 0.6759 - val_accuracy: 0.6865\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.6972 - val_loss: 0.6747 - val_accuracy: 0.6855\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6951 - val_loss: 0.6738 - val_accuracy: 0.6845\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7030 - val_loss: 0.6743 - val_accuracy: 0.6860\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.7041 - val_loss: 0.6768 - val_accuracy: 0.6900\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6951 - val_loss: 0.6714 - val_accuracy: 0.6860\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6889 - val_loss: 0.6739 - val_accuracy: 0.6900\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6963 - val_loss: 0.6805 - val_accuracy: 0.6865\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6861 - val_loss: 0.6751 - val_accuracy: 0.6850\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6946 - val_loss: 0.6716 - val_accuracy: 0.6895\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6937 - val_loss: 0.6773 - val_accuracy: 0.6830\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6947 - val_loss: 0.6724 - val_accuracy: 0.6885\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6927 - val_loss: 0.6711 - val_accuracy: 0.6835\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6965 - val_loss: 0.6711 - val_accuracy: 0.6905\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7007 - val_loss: 0.6714 - val_accuracy: 0.6890\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6972 - val_loss: 0.6711 - val_accuracy: 0.6900\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6912 - val_loss: 0.6757 - val_accuracy: 0.6905\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.7047 - val_loss: 0.6793 - val_accuracy: 0.6920\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6952 - val_loss: 0.6714 - val_accuracy: 0.6860\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6960 - val_loss: 0.6720 - val_accuracy: 0.6905\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6969 - val_loss: 0.6706 - val_accuracy: 0.6870\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6932 - val_loss: 0.6755 - val_accuracy: 0.6880\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7027 - val_loss: 0.6711 - val_accuracy: 0.6930\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6955 - val_loss: 0.6682 - val_accuracy: 0.6885\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6995 - val_loss: 0.6703 - val_accuracy: 0.6910\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.7033 - val_loss: 0.6681 - val_accuracy: 0.6905\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6829 - val_loss: 0.6793 - val_accuracy: 0.6895\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6941 - val_loss: 0.6685 - val_accuracy: 0.6920\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7074 - val_loss: 0.6697 - val_accuracy: 0.6925\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.6974 - val_loss: 0.6668 - val_accuracy: 0.6870\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7049 - val_loss: 0.6690 - val_accuracy: 0.6960\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6962 - val_loss: 0.6685 - val_accuracy: 0.6900\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6976 - val_loss: 0.6680 - val_accuracy: 0.6950\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6986 - val_loss: 0.6667 - val_accuracy: 0.6860\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.7057 - val_loss: 0.6686 - val_accuracy: 0.6915\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.7067 - val_loss: 0.6677 - val_accuracy: 0.6920\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.7097 - val_loss: 0.6630 - val_accuracy: 0.6920\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.7011 - val_loss: 0.6646 - val_accuracy: 0.6955\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7040 - val_loss: 0.6652 - val_accuracy: 0.6930\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.7084 - val_loss: 0.6645 - val_accuracy: 0.6905\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.7096 - val_loss: 0.6688 - val_accuracy: 0.6915\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7056 - val_loss: 0.6639 - val_accuracy: 0.6895\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6942 - val_loss: 0.6625 - val_accuracy: 0.6940\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.7036 - val_loss: 0.6607 - val_accuracy: 0.6920\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.7036 - val_loss: 0.6635 - val_accuracy: 0.6920\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6999 - val_loss: 0.6623 - val_accuracy: 0.6940\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.7130 - val_loss: 0.6662 - val_accuracy: 0.6915\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.7022 - val_loss: 0.6662 - val_accuracy: 0.6915\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.7063 - val_loss: 0.6633 - val_accuracy: 0.6925\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.7116 - val_loss: 0.6595 - val_accuracy: 0.6955\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.7061 - val_loss: 0.6658 - val_accuracy: 0.6940\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7008 - val_loss: 0.6629 - val_accuracy: 0.6950\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.7071 - val_loss: 0.6652 - val_accuracy: 0.6970\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.7052 - val_loss: 0.6606 - val_accuracy: 0.6930\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.7055 - val_loss: 0.6596 - val_accuracy: 0.6930\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.7058 - val_loss: 0.6575 - val_accuracy: 0.6905\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6970 - val_loss: 0.6585 - val_accuracy: 0.6940\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6993 - val_loss: 0.6589 - val_accuracy: 0.6970\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.7062 - val_loss: 0.6610 - val_accuracy: 0.6930\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.7039 - val_loss: 0.6622 - val_accuracy: 0.6960\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.7004 - val_loss: 0.6617 - val_accuracy: 0.6940\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7095 - val_loss: 0.6609 - val_accuracy: 0.6960\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.7084 - val_loss: 0.6638 - val_accuracy: 0.6960\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.7010 - val_loss: 0.6651 - val_accuracy: 0.6940\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.7000 - val_loss: 0.6640 - val_accuracy: 0.6900\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.7104 - val_loss: 0.6603 - val_accuracy: 0.6925\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7185 - val_loss: 0.6581 - val_accuracy: 0.6990\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.7005 - val_loss: 0.6557 - val_accuracy: 0.6960\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6965 - val_loss: 0.6565 - val_accuracy: 0.6985\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.7124 - val_loss: 0.6551 - val_accuracy: 0.6985\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.7069 - val_loss: 0.6581 - val_accuracy: 0.7005\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.7064 - val_loss: 0.6579 - val_accuracy: 0.6995\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6905 - val_loss: 0.6556 - val_accuracy: 0.6995\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.7055 - val_loss: 0.6547 - val_accuracy: 0.6985\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7108 - val_loss: 0.6563 - val_accuracy: 0.6995\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6980 - val_loss: 0.6597 - val_accuracy: 0.7010\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.7059 - val_loss: 0.6561 - val_accuracy: 0.7045\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.7101 - val_loss: 0.6569 - val_accuracy: 0.7000\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7154 - val_loss: 0.6614 - val_accuracy: 0.6945\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.7085 - val_loss: 0.6580 - val_accuracy: 0.7005\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.7198 - val_loss: 0.6622 - val_accuracy: 0.6990\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.7055 - val_loss: 0.6539 - val_accuracy: 0.7030\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.7070 - val_loss: 0.6547 - val_accuracy: 0.6985\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7073 - val_loss: 0.6529 - val_accuracy: 0.7000\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7147 - val_loss: 0.6525 - val_accuracy: 0.7010\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7065 - val_loss: 0.6537 - val_accuracy: 0.7005\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.7093 - val_loss: 0.6591 - val_accuracy: 0.7050\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.7045 - val_loss: 0.6543 - val_accuracy: 0.7035\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7131 - val_loss: 0.6568 - val_accuracy: 0.6925\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.7086 - val_loss: 0.6530 - val_accuracy: 0.7010\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7054 - val_loss: 0.6572 - val_accuracy: 0.6920\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.7025 - val_loss: 0.6593 - val_accuracy: 0.7010\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7099 - val_loss: 0.6534 - val_accuracy: 0.7045\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.7091 - val_loss: 0.6549 - val_accuracy: 0.6990\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.7159 - val_loss: 0.6519 - val_accuracy: 0.7040\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7120 - val_loss: 0.6524 - val_accuracy: 0.7040\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.7094 - val_loss: 0.6509 - val_accuracy: 0.7050\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7042 - val_loss: 0.6586 - val_accuracy: 0.6970\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7164 - val_loss: 0.6517 - val_accuracy: 0.7035\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7153 - val_loss: 0.6568 - val_accuracy: 0.6970\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.7091 - val_loss: 0.6529 - val_accuracy: 0.7040\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7029 - val_loss: 0.6507 - val_accuracy: 0.7030\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.7009 - val_loss: 0.6518 - val_accuracy: 0.7005\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.7059 - val_loss: 0.6520 - val_accuracy: 0.6980\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7040 - val_loss: 0.6514 - val_accuracy: 0.7050\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7107 - val_loss: 0.6564 - val_accuracy: 0.7020\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7137 - val_loss: 0.6602 - val_accuracy: 0.6975\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.7113 - val_loss: 0.6497 - val_accuracy: 0.7065\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7129 - val_loss: 0.6532 - val_accuracy: 0.7040\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7117 - val_loss: 0.6498 - val_accuracy: 0.7045\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.7011 - val_loss: 0.6521 - val_accuracy: 0.6955\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7129 - val_loss: 0.6493 - val_accuracy: 0.7030\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7077 - val_loss: 0.6527 - val_accuracy: 0.6990\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7064 - val_loss: 0.6530 - val_accuracy: 0.6995\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.7206 - val_loss: 0.6487 - val_accuracy: 0.7030\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7113 - val_loss: 0.6484 - val_accuracy: 0.7015\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.7152 - val_loss: 0.6511 - val_accuracy: 0.7025\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.7135 - val_loss: 0.6520 - val_accuracy: 0.6970\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7076 - val_loss: 0.6552 - val_accuracy: 0.6995\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7177 - val_loss: 0.6482 - val_accuracy: 0.7045\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7128 - val_loss: 0.6484 - val_accuracy: 0.7030\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.7202 - val_loss: 0.6518 - val_accuracy: 0.7040\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7160 - val_loss: 0.6480 - val_accuracy: 0.7035\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.7039 - val_loss: 0.6517 - val_accuracy: 0.7055\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7199 - val_loss: 0.6475 - val_accuracy: 0.7045\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.7098 - val_loss: 0.6490 - val_accuracy: 0.7010\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7197 - val_loss: 0.6536 - val_accuracy: 0.7020\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7191 - val_loss: 0.6547 - val_accuracy: 0.7050\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7155 - val_loss: 0.6545 - val_accuracy: 0.7055\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.7207 - val_loss: 0.6508 - val_accuracy: 0.7070\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.7189 - val_loss: 0.6554 - val_accuracy: 0.7070\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.7176 - val_loss: 0.6469 - val_accuracy: 0.7040\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7130 - val_loss: 0.6469 - val_accuracy: 0.7040\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.7178 - val_loss: 0.6468 - val_accuracy: 0.7030\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7162 - val_loss: 0.6463 - val_accuracy: 0.7035\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.7178 - val_loss: 0.6476 - val_accuracy: 0.7065\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.7147 - val_loss: 0.6462 - val_accuracy: 0.7035\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7097 - val_loss: 0.6537 - val_accuracy: 0.7005\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7213 - val_loss: 0.6466 - val_accuracy: 0.7040\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.7121 - val_loss: 0.6460 - val_accuracy: 0.7040\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7088 - val_loss: 0.6588 - val_accuracy: 0.7015\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.7182 - val_loss: 0.6479 - val_accuracy: 0.7060\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.7134 - val_loss: 0.6451 - val_accuracy: 0.7035\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.7202 - val_loss: 0.6450 - val_accuracy: 0.7045\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.7174 - val_loss: 0.6469 - val_accuracy: 0.7035\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7207 - val_loss: 0.6491 - val_accuracy: 0.7010\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7128 - val_loss: 0.6484 - val_accuracy: 0.7035\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7194 - val_loss: 0.6538 - val_accuracy: 0.7020\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7152 - val_loss: 0.6456 - val_accuracy: 0.7055\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7245 - val_loss: 0.6479 - val_accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 56, 3)             18        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_25 (Averag (None, 11, 3)             0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 12)                408       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=3, kernel_size = 5,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 14ms/step - loss: 1.0991 - accuracy: 0.3449 - val_loss: 1.0981 - val_accuracy: 0.3680\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0965 - accuracy: 0.3650 - val_loss: 1.0946 - val_accuracy: 0.3865\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0919 - accuracy: 0.3948 - val_loss: 1.0874 - val_accuracy: 0.3985\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0843 - accuracy: 0.3978 - val_loss: 1.0751 - val_accuracy: 0.4040\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0704 - accuracy: 0.4190 - val_loss: 1.0583 - val_accuracy: 0.4140\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0551 - accuracy: 0.4220 - val_loss: 1.0428 - val_accuracy: 0.4295\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0441 - accuracy: 0.4384 - val_loss: 1.0302 - val_accuracy: 0.4405\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0343 - accuracy: 0.4492 - val_loss: 1.0217 - val_accuracy: 0.4415\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0272 - accuracy: 0.4564 - val_loss: 1.0118 - val_accuracy: 0.4635\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0195 - accuracy: 0.4496 - val_loss: 1.0052 - val_accuracy: 0.4625\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0116 - accuracy: 0.4625 - val_loss: 0.9998 - val_accuracy: 0.4645\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0052 - accuracy: 0.4555 - val_loss: 0.9921 - val_accuracy: 0.4745\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0001 - accuracy: 0.4663 - val_loss: 0.9865 - val_accuracy: 0.4705\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9952 - accuracy: 0.4717 - val_loss: 0.9805 - val_accuracy: 0.4785\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9901 - accuracy: 0.4657 - val_loss: 0.9788 - val_accuracy: 0.4785\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9842 - accuracy: 0.4782 - val_loss: 0.9706 - val_accuracy: 0.4810\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9754 - accuracy: 0.4812 - val_loss: 0.9659 - val_accuracy: 0.4915\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9691 - accuracy: 0.4879 - val_loss: 0.9622 - val_accuracy: 0.4895\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9641 - accuracy: 0.4863 - val_loss: 0.9572 - val_accuracy: 0.4850\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9647 - accuracy: 0.4859 - val_loss: 0.9551 - val_accuracy: 0.4895\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9608 - accuracy: 0.4921 - val_loss: 0.9528 - val_accuracy: 0.4785\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9550 - accuracy: 0.4851 - val_loss: 0.9513 - val_accuracy: 0.4770\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9575 - accuracy: 0.4941 - val_loss: 0.9470 - val_accuracy: 0.4970\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9475 - accuracy: 0.5058 - val_loss: 0.9453 - val_accuracy: 0.4695\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9457 - accuracy: 0.5137 - val_loss: 0.9422 - val_accuracy: 0.4985\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9474 - accuracy: 0.5096 - val_loss: 0.9443 - val_accuracy: 0.5010\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9605 - accuracy: 0.4977 - val_loss: 0.9407 - val_accuracy: 0.4710\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9329 - accuracy: 0.4996 - val_loss: 0.9399 - val_accuracy: 0.4730\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9468 - accuracy: 0.5014 - val_loss: 0.9365 - val_accuracy: 0.5025\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9362 - accuracy: 0.5078 - val_loss: 0.9359 - val_accuracy: 0.4940\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9274 - accuracy: 0.5138 - val_loss: 0.9357 - val_accuracy: 0.5030\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9311 - accuracy: 0.5163 - val_loss: 0.9403 - val_accuracy: 0.5040\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9253 - accuracy: 0.5123 - val_loss: 0.9371 - val_accuracy: 0.5010\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9350 - accuracy: 0.5170 - val_loss: 0.9314 - val_accuracy: 0.4915\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9336 - accuracy: 0.5187 - val_loss: 0.9319 - val_accuracy: 0.5030\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9309 - accuracy: 0.5038 - val_loss: 0.9338 - val_accuracy: 0.4990\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9318 - accuracy: 0.5041 - val_loss: 0.9324 - val_accuracy: 0.5050\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.5294 - val_loss: 0.9333 - val_accuracy: 0.5005\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9174 - accuracy: 0.5257 - val_loss: 0.9295 - val_accuracy: 0.5110\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9222 - accuracy: 0.5123 - val_loss: 0.9269 - val_accuracy: 0.5045\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9187 - accuracy: 0.5128 - val_loss: 0.9305 - val_accuracy: 0.5110\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9168 - accuracy: 0.5196 - val_loss: 0.9291 - val_accuracy: 0.5110\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9136 - accuracy: 0.5180 - val_loss: 0.9255 - val_accuracy: 0.4995\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9174 - accuracy: 0.5257 - val_loss: 0.9258 - val_accuracy: 0.4880\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.5124 - val_loss: 0.9233 - val_accuracy: 0.5105\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9199 - accuracy: 0.5129 - val_loss: 0.9237 - val_accuracy: 0.5135\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9222 - accuracy: 0.5208 - val_loss: 0.9242 - val_accuracy: 0.4980\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9122 - accuracy: 0.5194 - val_loss: 0.9290 - val_accuracy: 0.4975\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.5178 - val_loss: 0.9229 - val_accuracy: 0.4950\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9083 - accuracy: 0.5233 - val_loss: 0.9249 - val_accuracy: 0.5010\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9076 - accuracy: 0.5251 - val_loss: 0.9216 - val_accuracy: 0.4985\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9015 - accuracy: 0.5193 - val_loss: 0.9199 - val_accuracy: 0.5110\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9086 - accuracy: 0.5207 - val_loss: 0.9197 - val_accuracy: 0.5190\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.5248 - val_loss: 0.9177 - val_accuracy: 0.5110\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9160 - accuracy: 0.5196 - val_loss: 0.9199 - val_accuracy: 0.5045\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9041 - accuracy: 0.5206 - val_loss: 0.9173 - val_accuracy: 0.5115\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9105 - accuracy: 0.5118 - val_loss: 0.9156 - val_accuracy: 0.5035\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9046 - accuracy: 0.5276 - val_loss: 0.9151 - val_accuracy: 0.5110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9073 - accuracy: 0.5227 - val_loss: 0.9129 - val_accuracy: 0.5225\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.5404 - val_loss: 0.9130 - val_accuracy: 0.5160\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8872 - accuracy: 0.5326 - val_loss: 0.9099 - val_accuracy: 0.5215\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9073 - accuracy: 0.5204 - val_loss: 0.9076 - val_accuracy: 0.5060\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8862 - accuracy: 0.5413 - val_loss: 0.9057 - val_accuracy: 0.5200\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8829 - accuracy: 0.5361 - val_loss: 0.9067 - val_accuracy: 0.5100\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8912 - accuracy: 0.5236 - val_loss: 0.8993 - val_accuracy: 0.5125\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8827 - accuracy: 0.5427 - val_loss: 0.8989 - val_accuracy: 0.5165\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8839 - accuracy: 0.5335 - val_loss: 0.8955 - val_accuracy: 0.5190\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8768 - accuracy: 0.5490 - val_loss: 0.8900 - val_accuracy: 0.5220\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8605 - accuracy: 0.5473 - val_loss: 0.8867 - val_accuracy: 0.5315\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.5463 - val_loss: 0.8850 - val_accuracy: 0.5190\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8660 - accuracy: 0.5449 - val_loss: 0.8817 - val_accuracy: 0.5245\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8662 - accuracy: 0.5435 - val_loss: 0.8761 - val_accuracy: 0.5255\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8537 - accuracy: 0.5354 - val_loss: 0.8737 - val_accuracy: 0.5250\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8553 - accuracy: 0.5543 - val_loss: 0.8683 - val_accuracy: 0.5300\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8528 - accuracy: 0.5572 - val_loss: 0.8650 - val_accuracy: 0.5325\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.5512 - val_loss: 0.8607 - val_accuracy: 0.5335\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8470 - accuracy: 0.5436 - val_loss: 0.8559 - val_accuracy: 0.5365\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8427 - accuracy: 0.5535 - val_loss: 0.8526 - val_accuracy: 0.5385\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8316 - accuracy: 0.5588 - val_loss: 0.8500 - val_accuracy: 0.5420\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8261 - accuracy: 0.5644 - val_loss: 0.8465 - val_accuracy: 0.5395\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.5617 - val_loss: 0.8448 - val_accuracy: 0.5390\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8272 - accuracy: 0.5615 - val_loss: 0.8416 - val_accuracy: 0.5450\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8202 - accuracy: 0.5616 - val_loss: 0.8421 - val_accuracy: 0.5540\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8338 - accuracy: 0.5582 - val_loss: 0.8388 - val_accuracy: 0.5615\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8177 - accuracy: 0.5721 - val_loss: 0.8343 - val_accuracy: 0.5630\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8209 - accuracy: 0.5629 - val_loss: 0.8308 - val_accuracy: 0.5610\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8186 - accuracy: 0.5669 - val_loss: 0.8304 - val_accuracy: 0.5550\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8203 - accuracy: 0.5649 - val_loss: 0.8269 - val_accuracy: 0.5660\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.5776 - val_loss: 0.8238 - val_accuracy: 0.5670\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8122 - accuracy: 0.5711 - val_loss: 0.8224 - val_accuracy: 0.5665\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8063 - accuracy: 0.5753 - val_loss: 0.8294 - val_accuracy: 0.5570\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8062 - accuracy: 0.5745 - val_loss: 0.8177 - val_accuracy: 0.5695\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.5847 - val_loss: 0.8140 - val_accuracy: 0.5655\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.5753 - val_loss: 0.8229 - val_accuracy: 0.5595\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8058 - accuracy: 0.5769 - val_loss: 0.8103 - val_accuracy: 0.5720\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7968 - accuracy: 0.5870 - val_loss: 0.8108 - val_accuracy: 0.5750\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7863 - accuracy: 0.5899 - val_loss: 0.8078 - val_accuracy: 0.5710\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7846 - accuracy: 0.5844 - val_loss: 0.8056 - val_accuracy: 0.5780\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7759 - accuracy: 0.5882 - val_loss: 0.8023 - val_accuracy: 0.5785\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7940 - accuracy: 0.5816 - val_loss: 0.8088 - val_accuracy: 0.5730\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7907 - accuracy: 0.5828 - val_loss: 0.7987 - val_accuracy: 0.5800\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.5850 - val_loss: 0.7987 - val_accuracy: 0.5865\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.5885 - val_loss: 0.7944 - val_accuracy: 0.5910\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.5966 - val_loss: 0.7944 - val_accuracy: 0.5920\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.5902 - val_loss: 0.7915 - val_accuracy: 0.5880\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7817 - accuracy: 0.5890 - val_loss: 0.7898 - val_accuracy: 0.5870\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7795 - accuracy: 0.5927 - val_loss: 0.7887 - val_accuracy: 0.5830\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.5988 - val_loss: 0.7886 - val_accuracy: 0.5870\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7636 - accuracy: 0.6013 - val_loss: 0.7839 - val_accuracy: 0.5915\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7693 - accuracy: 0.5978 - val_loss: 0.7848 - val_accuracy: 0.5860\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.5951 - val_loss: 0.7853 - val_accuracy: 0.5855\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7699 - accuracy: 0.6007 - val_loss: 0.7818 - val_accuracy: 0.5935\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7647 - accuracy: 0.5999 - val_loss: 0.7931 - val_accuracy: 0.5885\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7624 - accuracy: 0.6006 - val_loss: 0.7763 - val_accuracy: 0.5940\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7557 - accuracy: 0.6108 - val_loss: 0.7753 - val_accuracy: 0.5960\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7640 - accuracy: 0.6092 - val_loss: 0.7733 - val_accuracy: 0.5960\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.6086 - val_loss: 0.7716 - val_accuracy: 0.5990\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.6023 - val_loss: 0.7735 - val_accuracy: 0.5975\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7596 - accuracy: 0.6020 - val_loss: 0.7691 - val_accuracy: 0.5965\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.6120 - val_loss: 0.7675 - val_accuracy: 0.6030\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.6111 - val_loss: 0.7659 - val_accuracy: 0.6015\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.6090 - val_loss: 0.7658 - val_accuracy: 0.6015\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.6172 - val_loss: 0.7761 - val_accuracy: 0.6105\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7411 - accuracy: 0.6181 - val_loss: 0.7629 - val_accuracy: 0.6065\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.6174 - val_loss: 0.7636 - val_accuracy: 0.6050\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.6121 - val_loss: 0.7621 - val_accuracy: 0.6180\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.6176 - val_loss: 0.7607 - val_accuracy: 0.6215\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.6160 - val_loss: 0.7611 - val_accuracy: 0.6160\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.6097 - val_loss: 0.7630 - val_accuracy: 0.6200\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.6278 - val_loss: 0.7594 - val_accuracy: 0.6110\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.6231 - val_loss: 0.7547 - val_accuracy: 0.6180\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7459 - accuracy: 0.6090 - val_loss: 0.7538 - val_accuracy: 0.6215\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.6094 - val_loss: 0.7555 - val_accuracy: 0.6080\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.6182 - val_loss: 0.7491 - val_accuracy: 0.6180\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.6207 - val_loss: 0.7500 - val_accuracy: 0.6200\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7331 - accuracy: 0.6194 - val_loss: 0.7578 - val_accuracy: 0.6050\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.6309 - val_loss: 0.7492 - val_accuracy: 0.6185\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.6278 - val_loss: 0.7479 - val_accuracy: 0.6255\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7336 - accuracy: 0.6256 - val_loss: 0.7492 - val_accuracy: 0.6225\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.6238 - val_loss: 0.7578 - val_accuracy: 0.6240\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7413 - accuracy: 0.6206 - val_loss: 0.7450 - val_accuracy: 0.6240\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7302 - accuracy: 0.6253 - val_loss: 0.7427 - val_accuracy: 0.6280\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.6242 - val_loss: 0.7420 - val_accuracy: 0.6240\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.6338 - val_loss: 0.7416 - val_accuracy: 0.6300\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7285 - accuracy: 0.6400 - val_loss: 0.7479 - val_accuracy: 0.6155\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.6173 - val_loss: 0.7429 - val_accuracy: 0.6315\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7147 - accuracy: 0.6410 - val_loss: 0.7516 - val_accuracy: 0.6210\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7337 - accuracy: 0.6313 - val_loss: 0.7414 - val_accuracy: 0.6325\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.6341 - val_loss: 0.7416 - val_accuracy: 0.6335\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.6306 - val_loss: 0.7386 - val_accuracy: 0.6285\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.6378 - val_loss: 0.7365 - val_accuracy: 0.6325\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.6270 - val_loss: 0.7367 - val_accuracy: 0.6320\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7074 - accuracy: 0.6377 - val_loss: 0.7357 - val_accuracy: 0.6315\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.6355 - val_loss: 0.7346 - val_accuracy: 0.6310\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.6416 - val_loss: 0.7334 - val_accuracy: 0.6345\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7138 - accuracy: 0.6345 - val_loss: 0.7399 - val_accuracy: 0.6230\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.6399 - val_loss: 0.7344 - val_accuracy: 0.6370\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.6486 - val_loss: 0.7368 - val_accuracy: 0.6345\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.6438 - val_loss: 0.7327 - val_accuracy: 0.6380\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.6480 - val_loss: 0.7383 - val_accuracy: 0.6290\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.6407 - val_loss: 0.7305 - val_accuracy: 0.6425\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.6559 - val_loss: 0.7409 - val_accuracy: 0.6360\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.6385 - val_loss: 0.7293 - val_accuracy: 0.6415\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.6536 - val_loss: 0.7278 - val_accuracy: 0.6415\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.6483 - val_loss: 0.7309 - val_accuracy: 0.6450\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.6456 - val_loss: 0.7396 - val_accuracy: 0.6300\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.6403 - val_loss: 0.7275 - val_accuracy: 0.6455\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.6596 - val_loss: 0.7261 - val_accuracy: 0.6395\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.6530 - val_loss: 0.7303 - val_accuracy: 0.6445\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.6536 - val_loss: 0.7321 - val_accuracy: 0.6420\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.6429 - val_loss: 0.7274 - val_accuracy: 0.6430\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6589 - val_loss: 0.7307 - val_accuracy: 0.6385\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.6442 - val_loss: 0.7260 - val_accuracy: 0.6425\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.6549 - val_loss: 0.7239 - val_accuracy: 0.6450\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.6567 - val_loss: 0.7243 - val_accuracy: 0.6475\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6526 - val_loss: 0.7236 - val_accuracy: 0.6450\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.6510 - val_loss: 0.7258 - val_accuracy: 0.6440\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.6513 - val_loss: 0.7233 - val_accuracy: 0.6425\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6569 - val_loss: 0.7234 - val_accuracy: 0.6435\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.6491 - val_loss: 0.7231 - val_accuracy: 0.6470\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.6571 - val_loss: 0.7347 - val_accuracy: 0.6350\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.6414 - val_loss: 0.7237 - val_accuracy: 0.6495\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.6504 - val_loss: 0.7246 - val_accuracy: 0.6500\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.6475 - val_loss: 0.7213 - val_accuracy: 0.6470\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.6557 - val_loss: 0.7202 - val_accuracy: 0.6460\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.6541 - val_loss: 0.7206 - val_accuracy: 0.6480\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.6581 - val_loss: 0.7282 - val_accuracy: 0.6490\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.6583 - val_loss: 0.7205 - val_accuracy: 0.6515\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.6638 - val_loss: 0.7222 - val_accuracy: 0.6540\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.6613 - val_loss: 0.7262 - val_accuracy: 0.6390\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6648 - val_loss: 0.7259 - val_accuracy: 0.6385\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6571 - val_loss: 0.7183 - val_accuracy: 0.6510\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.6556 - val_loss: 0.7251 - val_accuracy: 0.6395\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6542 - val_loss: 0.7188 - val_accuracy: 0.6470\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6660 - val_loss: 0.7191 - val_accuracy: 0.6495\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.6497 - val_loss: 0.7315 - val_accuracy: 0.6480\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6722 - val_loss: 0.7164 - val_accuracy: 0.6545\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6612 - val_loss: 0.7200 - val_accuracy: 0.6530\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.6566 - val_loss: 0.7226 - val_accuracy: 0.6440\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.6554 - val_loss: 0.7183 - val_accuracy: 0.6610\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6607 - val_loss: 0.7175 - val_accuracy: 0.6580\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6645 - val_loss: 0.7172 - val_accuracy: 0.6575\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.6626 - val_loss: 0.7158 - val_accuracy: 0.6565\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.6552 - val_loss: 0.7172 - val_accuracy: 0.6525\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6657 - val_loss: 0.7220 - val_accuracy: 0.6530\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.6621 - val_loss: 0.7229 - val_accuracy: 0.6410\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6578 - val_loss: 0.7149 - val_accuracy: 0.6545\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6654 - val_loss: 0.7149 - val_accuracy: 0.6515\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.6586 - val_loss: 0.7136 - val_accuracy: 0.6580\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6717 - val_loss: 0.7167 - val_accuracy: 0.6610\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6703 - val_loss: 0.7148 - val_accuracy: 0.6615\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.6610 - val_loss: 0.7142 - val_accuracy: 0.6640\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.6622 - val_loss: 0.7114 - val_accuracy: 0.6590\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.6668 - val_loss: 0.7118 - val_accuracy: 0.6600\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.6628 - val_loss: 0.7107 - val_accuracy: 0.6610\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6712 - val_loss: 0.7163 - val_accuracy: 0.6585\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.6587 - val_loss: 0.7115 - val_accuracy: 0.6635\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.6620 - val_loss: 0.7115 - val_accuracy: 0.6620\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.6682 - val_loss: 0.7080 - val_accuracy: 0.6645\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6814 - val_loss: 0.7113 - val_accuracy: 0.6625\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6688 - val_loss: 0.7105 - val_accuracy: 0.6640\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.6640 - val_loss: 0.7128 - val_accuracy: 0.6650\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.6644 - val_loss: 0.7102 - val_accuracy: 0.6665\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.6714 - val_loss: 0.7086 - val_accuracy: 0.6600\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.6595 - val_loss: 0.7093 - val_accuracy: 0.6615\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.6734 - val_loss: 0.7160 - val_accuracy: 0.6645\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6755 - val_loss: 0.7086 - val_accuracy: 0.6645\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6791 - val_loss: 0.7070 - val_accuracy: 0.6620\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.6673 - val_loss: 0.7095 - val_accuracy: 0.6620\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6715 - val_loss: 0.7131 - val_accuracy: 0.6630\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.6713 - val_loss: 0.7083 - val_accuracy: 0.6565\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.6653 - val_loss: 0.7094 - val_accuracy: 0.6630\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.6680 - val_loss: 0.7076 - val_accuracy: 0.6650\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6755 - val_loss: 0.7085 - val_accuracy: 0.6645\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.6649 - val_loss: 0.7090 - val_accuracy: 0.6675\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.6789 - val_loss: 0.7213 - val_accuracy: 0.6615\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6640 - val_loss: 0.7065 - val_accuracy: 0.6610\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6800 - val_loss: 0.7108 - val_accuracy: 0.6665\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6733 - val_loss: 0.7059 - val_accuracy: 0.6615\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6699 - val_loss: 0.7061 - val_accuracy: 0.6650\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.6762 - val_loss: 0.7114 - val_accuracy: 0.6565\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.6728 - val_loss: 0.7214 - val_accuracy: 0.6605\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6650 - val_loss: 0.7057 - val_accuracy: 0.6660\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6711 - val_loss: 0.7091 - val_accuracy: 0.6570\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6734 - val_loss: 0.7130 - val_accuracy: 0.6645\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.6779 - val_loss: 0.7079 - val_accuracy: 0.6580\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6777 - val_loss: 0.7054 - val_accuracy: 0.6680\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6768 - val_loss: 0.7062 - val_accuracy: 0.6660\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6728 - val_loss: 0.7066 - val_accuracy: 0.6610\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.6661 - val_loss: 0.7049 - val_accuracy: 0.6665\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 38, 13)            312       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_20 (Averag (None, 7, 13)             0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 276       \n",
      "=================================================================\n",
      "Total params: 588\n",
      "Trainable params: 588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=13, kernel_size = 23,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 14ms/step - loss: 1.1259 - accuracy: 0.3460 - val_loss: 1.1082 - val_accuracy: 0.3565\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1026 - accuracy: 0.3756 - val_loss: 1.0967 - val_accuracy: 0.3995\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0928 - accuracy: 0.4165 - val_loss: 1.0852 - val_accuracy: 0.3960\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0812 - accuracy: 0.4178 - val_loss: 1.0744 - val_accuracy: 0.4075\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0711 - accuracy: 0.4275 - val_loss: 1.0646 - val_accuracy: 0.4310\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0654 - accuracy: 0.4342 - val_loss: 1.0566 - val_accuracy: 0.4365\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0658 - accuracy: 0.4352 - val_loss: 1.0499 - val_accuracy: 0.4295\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0574 - accuracy: 0.4429 - val_loss: 1.0420 - val_accuracy: 0.4510\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0429 - accuracy: 0.4760 - val_loss: 1.0317 - val_accuracy: 0.4610\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0359 - accuracy: 0.4786 - val_loss: 1.0219 - val_accuracy: 0.5000\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0296 - accuracy: 0.4903 - val_loss: 1.0098 - val_accuracy: 0.4990\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0195 - accuracy: 0.4977 - val_loss: 0.9974 - val_accuracy: 0.5420\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0053 - accuracy: 0.5336 - val_loss: 0.9829 - val_accuracy: 0.5645\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9919 - accuracy: 0.5510 - val_loss: 0.9680 - val_accuracy: 0.5855\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9752 - accuracy: 0.5665 - val_loss: 0.9546 - val_accuracy: 0.6085\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9668 - accuracy: 0.5798 - val_loss: 0.9409 - val_accuracy: 0.6240\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9569 - accuracy: 0.5847 - val_loss: 0.9276 - val_accuracy: 0.6125\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9473 - accuracy: 0.6033 - val_loss: 0.9148 - val_accuracy: 0.6330\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9324 - accuracy: 0.5989 - val_loss: 0.9041 - val_accuracy: 0.6365\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9267 - accuracy: 0.5987 - val_loss: 0.8923 - val_accuracy: 0.6515\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9123 - accuracy: 0.6317 - val_loss: 0.8829 - val_accuracy: 0.6480\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9094 - accuracy: 0.6264 - val_loss: 0.8738 - val_accuracy: 0.6510\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9016 - accuracy: 0.6208 - val_loss: 0.8657 - val_accuracy: 0.6620\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8956 - accuracy: 0.6245 - val_loss: 0.8598 - val_accuracy: 0.6570\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8770 - accuracy: 0.6405 - val_loss: 0.8507 - val_accuracy: 0.6665\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8682 - accuracy: 0.6530 - val_loss: 0.8464 - val_accuracy: 0.6540\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8751 - accuracy: 0.6365 - val_loss: 0.8389 - val_accuracy: 0.6810\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8707 - accuracy: 0.6410 - val_loss: 0.8340 - val_accuracy: 0.6700\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8618 - accuracy: 0.6502 - val_loss: 0.8285 - val_accuracy: 0.6765\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8583 - accuracy: 0.6481 - val_loss: 0.8236 - val_accuracy: 0.6815\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8487 - accuracy: 0.6555 - val_loss: 0.8200 - val_accuracy: 0.6785\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8580 - accuracy: 0.6467 - val_loss: 0.8155 - val_accuracy: 0.6825\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.6493 - val_loss: 0.8109 - val_accuracy: 0.6850\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8493 - accuracy: 0.6479 - val_loss: 0.8110 - val_accuracy: 0.6830\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8413 - accuracy: 0.6544 - val_loss: 0.8061 - val_accuracy: 0.6875\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.6665 - val_loss: 0.8011 - val_accuracy: 0.6935\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.6497 - val_loss: 0.8018 - val_accuracy: 0.6845\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8368 - accuracy: 0.6580 - val_loss: 0.7964 - val_accuracy: 0.6870\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8376 - accuracy: 0.6538 - val_loss: 0.7953 - val_accuracy: 0.6905\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8264 - accuracy: 0.6625 - val_loss: 0.7906 - val_accuracy: 0.6860\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8295 - accuracy: 0.6689 - val_loss: 0.7894 - val_accuracy: 0.6960\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8256 - accuracy: 0.6724 - val_loss: 0.7871 - val_accuracy: 0.6900\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8173 - accuracy: 0.6731 - val_loss: 0.7851 - val_accuracy: 0.6975\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8213 - accuracy: 0.6658 - val_loss: 0.7809 - val_accuracy: 0.6895\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8214 - accuracy: 0.6604 - val_loss: 0.7784 - val_accuracy: 0.6995\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8211 - accuracy: 0.6652 - val_loss: 0.7782 - val_accuracy: 0.6950\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8265 - accuracy: 0.6579 - val_loss: 0.7747 - val_accuracy: 0.6990\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.6732 - val_loss: 0.7733 - val_accuracy: 0.7030\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8132 - accuracy: 0.6650 - val_loss: 0.7733 - val_accuracy: 0.7010\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.6645 - val_loss: 0.7705 - val_accuracy: 0.7040\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7987 - accuracy: 0.6824 - val_loss: 0.7670 - val_accuracy: 0.7030\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.6771 - val_loss: 0.7683 - val_accuracy: 0.7030\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8188 - accuracy: 0.6740 - val_loss: 0.7642 - val_accuracy: 0.7000\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8110 - accuracy: 0.6690 - val_loss: 0.7615 - val_accuracy: 0.7110\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8047 - accuracy: 0.6769 - val_loss: 0.7610 - val_accuracy: 0.7100\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.6754 - val_loss: 0.7588 - val_accuracy: 0.7090\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8033 - accuracy: 0.6822 - val_loss: 0.7591 - val_accuracy: 0.7035\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8059 - accuracy: 0.6792 - val_loss: 0.7592 - val_accuracy: 0.7015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8081 - accuracy: 0.6677 - val_loss: 0.7554 - val_accuracy: 0.7090\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7964 - accuracy: 0.6873 - val_loss: 0.7557 - val_accuracy: 0.7120\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.6828 - val_loss: 0.7534 - val_accuracy: 0.7115\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8036 - accuracy: 0.6768 - val_loss: 0.7530 - val_accuracy: 0.7080\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.6801 - val_loss: 0.7501 - val_accuracy: 0.7100\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7962 - accuracy: 0.6750 - val_loss: 0.7510 - val_accuracy: 0.7010\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7870 - accuracy: 0.6838 - val_loss: 0.7485 - val_accuracy: 0.7085\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7924 - accuracy: 0.6906 - val_loss: 0.7458 - val_accuracy: 0.7105\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7946 - accuracy: 0.6870 - val_loss: 0.7477 - val_accuracy: 0.7145\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7887 - accuracy: 0.6886 - val_loss: 0.7433 - val_accuracy: 0.7170\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7835 - accuracy: 0.6943 - val_loss: 0.7403 - val_accuracy: 0.7150\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7888 - accuracy: 0.6823 - val_loss: 0.7418 - val_accuracy: 0.7110\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7789 - accuracy: 0.6961 - val_loss: 0.7394 - val_accuracy: 0.7155\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7809 - accuracy: 0.6935 - val_loss: 0.7394 - val_accuracy: 0.7130\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7771 - accuracy: 0.7003 - val_loss: 0.7385 - val_accuracy: 0.7115\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7870 - accuracy: 0.6897 - val_loss: 0.7364 - val_accuracy: 0.7135\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7818 - accuracy: 0.6830 - val_loss: 0.7359 - val_accuracy: 0.7135\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.6838 - val_loss: 0.7330 - val_accuracy: 0.7165\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7737 - accuracy: 0.6900 - val_loss: 0.7335 - val_accuracy: 0.7195\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7742 - accuracy: 0.6915 - val_loss: 0.7343 - val_accuracy: 0.7185\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7822 - accuracy: 0.6819 - val_loss: 0.7318 - val_accuracy: 0.7200\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7730 - accuracy: 0.6921 - val_loss: 0.7311 - val_accuracy: 0.7145\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.6993 - val_loss: 0.7286 - val_accuracy: 0.7220\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7754 - accuracy: 0.6942 - val_loss: 0.7276 - val_accuracy: 0.7225\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7763 - accuracy: 0.6939 - val_loss: 0.7273 - val_accuracy: 0.7185\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7812 - accuracy: 0.6846 - val_loss: 0.7266 - val_accuracy: 0.7180\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7871 - accuracy: 0.6757 - val_loss: 0.7281 - val_accuracy: 0.7190\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7813 - accuracy: 0.6924 - val_loss: 0.7250 - val_accuracy: 0.7165\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7708 - accuracy: 0.6946 - val_loss: 0.7235 - val_accuracy: 0.7200\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7684 - accuracy: 0.6951 - val_loss: 0.7237 - val_accuracy: 0.7170\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7639 - accuracy: 0.6963 - val_loss: 0.7232 - val_accuracy: 0.7160\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7637 - accuracy: 0.7080 - val_loss: 0.7245 - val_accuracy: 0.7150\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7751 - accuracy: 0.6941 - val_loss: 0.7210 - val_accuracy: 0.7220\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7624 - accuracy: 0.6946 - val_loss: 0.7207 - val_accuracy: 0.7210\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7637 - accuracy: 0.7058 - val_loss: 0.7181 - val_accuracy: 0.7225\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7679 - accuracy: 0.6967 - val_loss: 0.7188 - val_accuracy: 0.7235\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.7024 - val_loss: 0.7179 - val_accuracy: 0.7195\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7609 - accuracy: 0.6979 - val_loss: 0.7163 - val_accuracy: 0.7235\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.6986 - val_loss: 0.7165 - val_accuracy: 0.7245\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7641 - accuracy: 0.6963 - val_loss: 0.7184 - val_accuracy: 0.7200\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7610 - accuracy: 0.6922 - val_loss: 0.7146 - val_accuracy: 0.7225\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.7042 - val_loss: 0.7134 - val_accuracy: 0.7300\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.6975 - val_loss: 0.7136 - val_accuracy: 0.7200\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.7018 - val_loss: 0.7126 - val_accuracy: 0.7245\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7586 - accuracy: 0.6937 - val_loss: 0.7097 - val_accuracy: 0.7290\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.7054 - val_loss: 0.7112 - val_accuracy: 0.7275\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7530 - accuracy: 0.7012 - val_loss: 0.7075 - val_accuracy: 0.7225\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.7035 - val_loss: 0.7080 - val_accuracy: 0.7285\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.7002 - val_loss: 0.7089 - val_accuracy: 0.7260\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7051 - val_loss: 0.7090 - val_accuracy: 0.7300\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.6993 - val_loss: 0.7074 - val_accuracy: 0.7260\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.7014 - val_loss: 0.7048 - val_accuracy: 0.7300\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7066 - val_loss: 0.7065 - val_accuracy: 0.7295\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.7003 - val_loss: 0.7047 - val_accuracy: 0.7230\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.6984 - val_loss: 0.7054 - val_accuracy: 0.7270\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7108 - val_loss: 0.7025 - val_accuracy: 0.7265\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.7053 - val_loss: 0.7016 - val_accuracy: 0.7325\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7101 - val_loss: 0.7022 - val_accuracy: 0.7295\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.7020 - val_loss: 0.7010 - val_accuracy: 0.7235\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.6973 - val_loss: 0.7004 - val_accuracy: 0.7300\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.7139 - val_loss: 0.7040 - val_accuracy: 0.7305\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.7068 - val_loss: 0.7008 - val_accuracy: 0.7295\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7057 - val_loss: 0.7019 - val_accuracy: 0.7290\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.7143 - val_loss: 0.6990 - val_accuracy: 0.7275\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.7033 - val_loss: 0.6955 - val_accuracy: 0.7330\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7150 - val_loss: 0.6979 - val_accuracy: 0.7280\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.7047 - val_loss: 0.6954 - val_accuracy: 0.7275\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.7163 - val_loss: 0.6953 - val_accuracy: 0.7270\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7024 - val_loss: 0.6971 - val_accuracy: 0.7255\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7431 - accuracy: 0.7014 - val_loss: 0.6952 - val_accuracy: 0.7300\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7106 - val_loss: 0.6950 - val_accuracy: 0.7265\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7403 - accuracy: 0.7087 - val_loss: 0.6966 - val_accuracy: 0.7345\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.7116 - val_loss: 0.6923 - val_accuracy: 0.7290\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.7053 - val_loss: 0.6949 - val_accuracy: 0.7380\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7191 - val_loss: 0.6904 - val_accuracy: 0.7300\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.7057 - val_loss: 0.6911 - val_accuracy: 0.7310\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7303 - accuracy: 0.7098 - val_loss: 0.6895 - val_accuracy: 0.7270\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.7102 - val_loss: 0.6924 - val_accuracy: 0.7305\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7122 - val_loss: 0.6919 - val_accuracy: 0.7380\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.7089 - val_loss: 0.6894 - val_accuracy: 0.7345\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7083 - val_loss: 0.6869 - val_accuracy: 0.7350\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7119 - val_loss: 0.6880 - val_accuracy: 0.7325\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.7056 - val_loss: 0.6862 - val_accuracy: 0.7340\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7296 - accuracy: 0.7101 - val_loss: 0.6864 - val_accuracy: 0.7365\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.7116 - val_loss: 0.6862 - val_accuracy: 0.7355\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.7164 - val_loss: 0.6856 - val_accuracy: 0.7340\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.7156 - val_loss: 0.6854 - val_accuracy: 0.7305\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.7141 - val_loss: 0.6827 - val_accuracy: 0.7330\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.7172 - val_loss: 0.6846 - val_accuracy: 0.7320\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.7218 - val_loss: 0.6864 - val_accuracy: 0.7410\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7197 - val_loss: 0.6816 - val_accuracy: 0.7380\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.6994 - val_loss: 0.6863 - val_accuracy: 0.7315\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.7064 - val_loss: 0.6827 - val_accuracy: 0.7355\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.7139 - val_loss: 0.6829 - val_accuracy: 0.7345\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7332 - accuracy: 0.7134 - val_loss: 0.6814 - val_accuracy: 0.7320\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.7195 - val_loss: 0.6813 - val_accuracy: 0.7315\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.7171 - val_loss: 0.6819 - val_accuracy: 0.7345\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.7170 - val_loss: 0.6820 - val_accuracy: 0.7345\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.7160 - val_loss: 0.6792 - val_accuracy: 0.7340\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7285 - accuracy: 0.7108 - val_loss: 0.6811 - val_accuracy: 0.7390\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.7177 - val_loss: 0.6813 - val_accuracy: 0.7355\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.7188 - val_loss: 0.6775 - val_accuracy: 0.7440\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.7244 - val_loss: 0.6772 - val_accuracy: 0.7365\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.7157 - val_loss: 0.6753 - val_accuracy: 0.7385\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7203 - accuracy: 0.7166 - val_loss: 0.6780 - val_accuracy: 0.7375\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7200 - val_loss: 0.6771 - val_accuracy: 0.7350\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.7101 - val_loss: 0.6769 - val_accuracy: 0.7285\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.7198 - val_loss: 0.6760 - val_accuracy: 0.7400\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.7183 - val_loss: 0.6750 - val_accuracy: 0.7445\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.7260 - val_loss: 0.6748 - val_accuracy: 0.7395\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.7103 - val_loss: 0.6726 - val_accuracy: 0.7370\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7320 - accuracy: 0.7130 - val_loss: 0.6730 - val_accuracy: 0.7375\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7193 - accuracy: 0.7254 - val_loss: 0.6756 - val_accuracy: 0.7395\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.7205 - val_loss: 0.6738 - val_accuracy: 0.7435\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.7193 - val_loss: 0.6730 - val_accuracy: 0.7445\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.7190 - val_loss: 0.6721 - val_accuracy: 0.7455\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.7147 - val_loss: 0.6736 - val_accuracy: 0.7385\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.7178 - val_loss: 0.6703 - val_accuracy: 0.7440\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.7284 - val_loss: 0.6734 - val_accuracy: 0.7365\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7118 - accuracy: 0.7192 - val_loss: 0.6713 - val_accuracy: 0.7440\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7103 - accuracy: 0.7286 - val_loss: 0.6693 - val_accuracy: 0.7455\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.7288 - val_loss: 0.6708 - val_accuracy: 0.7450\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.7214 - val_loss: 0.6691 - val_accuracy: 0.7400\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.7249 - val_loss: 0.6674 - val_accuracy: 0.7430\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7169 - accuracy: 0.7204 - val_loss: 0.6706 - val_accuracy: 0.7460\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.7135 - val_loss: 0.6702 - val_accuracy: 0.7380\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.7180 - val_loss: 0.6667 - val_accuracy: 0.7470\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.7234 - val_loss: 0.6718 - val_accuracy: 0.7345\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.7176 - val_loss: 0.6686 - val_accuracy: 0.7370\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7241 - val_loss: 0.6683 - val_accuracy: 0.7435\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.7249 - val_loss: 0.6675 - val_accuracy: 0.7390\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7224 - accuracy: 0.7116 - val_loss: 0.6681 - val_accuracy: 0.7425\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.7161 - val_loss: 0.6660 - val_accuracy: 0.7375\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.7220 - val_loss: 0.6657 - val_accuracy: 0.7325\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7302 - val_loss: 0.6650 - val_accuracy: 0.7435\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7163 - accuracy: 0.7199 - val_loss: 0.6661 - val_accuracy: 0.7480\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.7295 - val_loss: 0.6647 - val_accuracy: 0.7425\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.7207 - val_loss: 0.6656 - val_accuracy: 0.7460\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.7279 - val_loss: 0.6609 - val_accuracy: 0.7465\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.7257 - val_loss: 0.6621 - val_accuracy: 0.7445\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.7238 - val_loss: 0.6643 - val_accuracy: 0.7415\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.7329 - val_loss: 0.6592 - val_accuracy: 0.7470\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7219 - accuracy: 0.7153 - val_loss: 0.6606 - val_accuracy: 0.7510\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.7309 - val_loss: 0.6585 - val_accuracy: 0.7490\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.7285 - val_loss: 0.6586 - val_accuracy: 0.7515\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.7229 - val_loss: 0.6631 - val_accuracy: 0.7460\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.7279 - val_loss: 0.6575 - val_accuracy: 0.7500\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.7199 - val_loss: 0.6614 - val_accuracy: 0.7400\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.7300 - val_loss: 0.6588 - val_accuracy: 0.7470\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.7285 - val_loss: 0.6574 - val_accuracy: 0.7470\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7115 - accuracy: 0.7217 - val_loss: 0.6595 - val_accuracy: 0.7495\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7050 - accuracy: 0.7228 - val_loss: 0.6606 - val_accuracy: 0.7515\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7325 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.7254 - val_loss: 0.6567 - val_accuracy: 0.7540\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7341 - val_loss: 0.6604 - val_accuracy: 0.7390\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.7205 - val_loss: 0.6567 - val_accuracy: 0.7450\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.7295 - val_loss: 0.6577 - val_accuracy: 0.7500\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.7294 - val_loss: 0.6549 - val_accuracy: 0.7475\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.7196 - val_loss: 0.6572 - val_accuracy: 0.7520\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.7287 - val_loss: 0.6554 - val_accuracy: 0.7525\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7198 - accuracy: 0.7134 - val_loss: 0.6565 - val_accuracy: 0.7485\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.7343 - val_loss: 0.6549 - val_accuracy: 0.7520\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.7261 - val_loss: 0.6566 - val_accuracy: 0.7505\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.7322 - val_loss: 0.6549 - val_accuracy: 0.7510\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.7269 - val_loss: 0.6570 - val_accuracy: 0.7545\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.7216 - val_loss: 0.6563 - val_accuracy: 0.7510\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.7263 - val_loss: 0.6539 - val_accuracy: 0.7565\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7392 - val_loss: 0.6537 - val_accuracy: 0.7500\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.7385 - val_loss: 0.6573 - val_accuracy: 0.7545\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.7238 - val_loss: 0.6513 - val_accuracy: 0.7515\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.7256 - val_loss: 0.6534 - val_accuracy: 0.7550\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.7363 - val_loss: 0.6520 - val_accuracy: 0.7500\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.7317 - val_loss: 0.6512 - val_accuracy: 0.7570\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.7288 - val_loss: 0.6528 - val_accuracy: 0.7555\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.7316 - val_loss: 0.6517 - val_accuracy: 0.7560\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.7266 - val_loss: 0.6523 - val_accuracy: 0.7460\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.7292 - val_loss: 0.6512 - val_accuracy: 0.7525\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.7237 - val_loss: 0.6560 - val_accuracy: 0.7535\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.7335 - val_loss: 0.6523 - val_accuracy: 0.7490\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.7353 - val_loss: 0.6509 - val_accuracy: 0.7560\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.7271 - val_loss: 0.6486 - val_accuracy: 0.7490\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6975 - accuracy: 0.7322 - val_loss: 0.6525 - val_accuracy: 0.7460\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.7264 - val_loss: 0.6486 - val_accuracy: 0.7535\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.7225 - val_loss: 0.6488 - val_accuracy: 0.7520\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.7284 - val_loss: 0.6485 - val_accuracy: 0.7445\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.7297 - val_loss: 0.6497 - val_accuracy: 0.7540\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.7305 - val_loss: 0.6525 - val_accuracy: 0.7520\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.7335 - val_loss: 0.6468 - val_accuracy: 0.7565\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.7334 - val_loss: 0.6471 - val_accuracy: 0.7550\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.7271 - val_loss: 0.6490 - val_accuracy: 0.7510\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.7207 - val_loss: 0.6475 - val_accuracy: 0.7495\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.7303 - val_loss: 0.6477 - val_accuracy: 0.7485\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result is achieved by the combination of a strong Convolutional neural network and one dense layer. We can also appreciate how the number of parameters increases a lot with the number of filters, while the kernel size has a minimum effect. In practice if we change the kernel size or the number of nodes in the dense layer we obtain approximately the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same model we used in lessons to evaluate how regulations values change the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN(reg = regularizers.l2, l= 0.001):\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=4, kernel_size = 10,\n",
    "                    kernel_regularizer = reg(l),\n",
    "                    kernel_initializer=ini,\n",
    "                    activation = \"relu\",\n",
    "                    input_shape = input_shape\n",
    "                    ))\n",
    "    model.add(AveragePooling1D(5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10,activation=\"relu\"))\n",
    "    model.add(Dense(10,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(reg = regularizers.l2, l= 0.001):\n",
    "    # create the mode\n",
    "    model=create_CNN(reg,l)\n",
    "    # compile the model\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# # call Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn = compile_model)\n",
    "\n",
    "\n",
    "# define parameter dictionary\n",
    "reg = [regularizers.l1, regularizers.l2, regularizers.l1_l2]\n",
    "l= [0.1,0.01,0.001,0.0001]\n",
    "param_grid = dict(reg = reg , l=l)\n",
    "# # call scikit grid search module\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=1, cv=4)\n",
    "grid_result = grid.fit(x_train,y_train, epochs=250, batch_size = 250, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_l</th>\n",
       "      <th>param_reg</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.743135</td>\n",
       "      <td>0.396809</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.1, 'reg': &lt;class 'tensorflow.python.ke...</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.555042</td>\n",
       "      <td>4.664063</td>\n",
       "      <td>0.180385</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.1, 'reg': &lt;function l1_l2 at 0x7fa2bbc...</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.651340</td>\n",
       "      <td>4.081976</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.040384</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.01, 'reg': &lt;class 'tensorflow.python.k...</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>0.065722</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.346722</td>\n",
       "      <td>4.184644</td>\n",
       "      <td>0.158263</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.0001, 'reg': &lt;class 'tensorflow.python...</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.673250</td>\n",
       "      <td>0.076202</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.771484</td>\n",
       "      <td>4.224691</td>\n",
       "      <td>0.172961</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.01, 'reg': &lt;function l1_l2 at 0x7fa2bb...</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.674750</td>\n",
       "      <td>0.072110</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.804894</td>\n",
       "      <td>0.155126</td>\n",
       "      <td>0.144236</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.1, 'reg': &lt;class 'tensorflow.python.ke...</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.702375</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.286934</td>\n",
       "      <td>3.832132</td>\n",
       "      <td>0.168695</td>\n",
       "      <td>0.035507</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.001, 'reg': &lt;class 'tensorflow.python....</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.704625</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.200689</td>\n",
       "      <td>4.584406</td>\n",
       "      <td>0.182908</td>\n",
       "      <td>0.044824</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.0001, 'reg': &lt;function l1_l2 at 0x7fa2...</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.7170</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.710375</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.526269</td>\n",
       "      <td>4.302998</td>\n",
       "      <td>0.192493</td>\n",
       "      <td>0.048365</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>&lt;function l1_l2 at 0x7fa2bbcd2550&gt;</td>\n",
       "      <td>{'l': 0.001, 'reg': &lt;function l1_l2 at 0x7fa2b...</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.712125</td>\n",
       "      <td>0.020879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.064559</td>\n",
       "      <td>1.456055</td>\n",
       "      <td>0.162866</td>\n",
       "      <td>0.031747</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.01, 'reg': &lt;class 'tensorflow.python.k...</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.999654</td>\n",
       "      <td>3.616142</td>\n",
       "      <td>0.187711</td>\n",
       "      <td>0.062828</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L2'&gt;</td>\n",
       "      <td>{'l': 0.001, 'reg': &lt;class 'tensorflow.python....</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.714125</td>\n",
       "      <td>0.022714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.789652</td>\n",
       "      <td>3.290008</td>\n",
       "      <td>0.172440</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.regularizers.L1'&gt;</td>\n",
       "      <td>{'l': 0.0001, 'reg': &lt;class 'tensorflow.python...</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>0.723875</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_l  \\\n",
       "0       11.743135      0.396809         0.144392        0.006275   0.1000   \n",
       "2       15.555042      4.664063         0.180385        0.043716   0.1000   \n",
       "3       15.651340      4.081976         0.188800        0.040384   0.0100   \n",
       "10      15.346722      4.184644         0.158263        0.033479   0.0001   \n",
       "5       14.771484      4.224691         0.172961        0.031725   0.0100   \n",
       "1       11.804894      0.155126         0.144236        0.008223   0.1000   \n",
       "6       16.286934      3.832132         0.168695        0.035507   0.0010   \n",
       "11      16.200689      4.584406         0.182908        0.044824   0.0001   \n",
       "8       14.526269      4.302998         0.192493        0.048365   0.0010   \n",
       "4       12.064559      1.456055         0.162866        0.031747   0.0100   \n",
       "7       15.999654      3.616142         0.187711        0.062828   0.0010   \n",
       "9       13.789652      3.290008         0.172440        0.036120   0.0001   \n",
       "\n",
       "                                            param_reg  \\\n",
       "0   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "2                  <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "3   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "10  <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "5                  <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "1   <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "6   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "11                 <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "8                  <function l1_l2 at 0x7fa2bbcd2550>   \n",
       "4   <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "7   <class 'tensorflow.python.keras.regularizers.L2'>   \n",
       "9   <class 'tensorflow.python.keras.regularizers.L1'>   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'l': 0.1, 'reg': <class 'tensorflow.python.ke...             0.3205   \n",
       "2   {'l': 0.1, 'reg': <function l1_l2 at 0x7fa2bbc...             0.3205   \n",
       "3   {'l': 0.01, 'reg': <class 'tensorflow.python.k...             0.6730   \n",
       "10  {'l': 0.0001, 'reg': <class 'tensorflow.python...             0.5415   \n",
       "5   {'l': 0.01, 'reg': <function l1_l2 at 0x7fa2bb...             0.7050   \n",
       "1   {'l': 0.1, 'reg': <class 'tensorflow.python.ke...             0.7130   \n",
       "6   {'l': 0.001, 'reg': <class 'tensorflow.python....             0.6950   \n",
       "11  {'l': 0.0001, 'reg': <function l1_l2 at 0x7fa2...             0.6950   \n",
       "8   {'l': 0.001, 'reg': <function l1_l2 at 0x7fa2b...             0.6930   \n",
       "4   {'l': 0.01, 'reg': <class 'tensorflow.python.k...             0.6880   \n",
       "7   {'l': 0.001, 'reg': <class 'tensorflow.python....             0.6885   \n",
       "9   {'l': 0.0001, 'reg': <class 'tensorflow.python...             0.6845   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0              0.3360             0.3140             0.3305         0.325250   \n",
       "2              0.3360             0.3140             0.3305         0.325250   \n",
       "3              0.5395             0.6810             0.5525         0.611500   \n",
       "10             0.7125             0.7245             0.7145         0.673250   \n",
       "5              0.5505             0.7255             0.7180         0.674750   \n",
       "1              0.6915             0.6825             0.7225         0.702375   \n",
       "6              0.6920             0.7335             0.6980         0.704625   \n",
       "11             0.7170             0.7315             0.6980         0.710375   \n",
       "8              0.7165             0.6945             0.7445         0.712125   \n",
       "4              0.7120             0.7180             0.7320         0.712500   \n",
       "7              0.7255             0.6970             0.7455         0.714125   \n",
       "9              0.7125             0.7195             0.7790         0.723875   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.008548               11  \n",
       "2         0.008548               11  \n",
       "3         0.065722               10  \n",
       "10        0.076202                9  \n",
       "5         0.072110                8  \n",
       "1         0.016056                7  \n",
       "6         0.016805                6  \n",
       "11        0.014830                5  \n",
       "8         0.020879                4  \n",
       "4         0.015898                3  \n",
       "7         0.022714                2  \n",
       "9         0.034415                1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GridSearch = pd.read_csv(\"DATA/Regularization_results.csv\", index_col = False)\n",
    "df_GridSearch = df_GridSearch.iloc[:,1:]\n",
    "df_GridSearch.sort_values(by = \"rank_test_score\", ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best fits are achieved by weak regularizers, as expected. Also L2 allows to have stronger regularization with similarr results, these can be seen as the best tradeoffs as they allows to get good accuracy with also a stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1117 - accuracy: 0.3287 - val_loss: 1.1054 - val_accuracy: 0.3435\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1042 - accuracy: 0.3459 - val_loss: 1.1009 - val_accuracy: 0.3520\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0992 - accuracy: 0.3746 - val_loss: 1.0954 - val_accuracy: 0.3850\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0939 - accuracy: 0.3757 - val_loss: 1.0883 - val_accuracy: 0.4280\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0907 - accuracy: 0.3798 - val_loss: 1.0818 - val_accuracy: 0.4350\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.4114 - val_loss: 1.0652 - val_accuracy: 0.4680\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0710 - accuracy: 0.4192 - val_loss: 1.0454 - val_accuracy: 0.4730\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0553 - accuracy: 0.4306 - val_loss: 1.0306 - val_accuracy: 0.4700\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0345 - accuracy: 0.4569 - val_loss: 1.0090 - val_accuracy: 0.4890\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0231 - accuracy: 0.4624 - val_loss: 0.9923 - val_accuracy: 0.4880\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.4598 - val_loss: 0.9738 - val_accuracy: 0.5015\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.4794 - val_loss: 0.9664 - val_accuracy: 0.4995\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9774 - accuracy: 0.4915 - val_loss: 0.9497 - val_accuracy: 0.5120\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9747 - accuracy: 0.4831 - val_loss: 0.9447 - val_accuracy: 0.5000\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9602 - accuracy: 0.5042 - val_loss: 0.9330 - val_accuracy: 0.5125\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.4980 - val_loss: 0.9262 - val_accuracy: 0.5215\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.5050 - val_loss: 0.9275 - val_accuracy: 0.5145\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9481 - accuracy: 0.4943 - val_loss: 0.9207 - val_accuracy: 0.5275\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9405 - accuracy: 0.5003 - val_loss: 0.9176 - val_accuracy: 0.5140\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.5070 - val_loss: 0.9095 - val_accuracy: 0.5215\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9420 - accuracy: 0.5038 - val_loss: 0.9075 - val_accuracy: 0.5105\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9307 - accuracy: 0.5108 - val_loss: 0.9061 - val_accuracy: 0.5305\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9302 - accuracy: 0.5079 - val_loss: 0.9063 - val_accuracy: 0.5195\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9202 - accuracy: 0.5196 - val_loss: 0.9003 - val_accuracy: 0.5200\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9256 - accuracy: 0.5186 - val_loss: 0.8965 - val_accuracy: 0.5285\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9282 - accuracy: 0.5134 - val_loss: 0.8938 - val_accuracy: 0.5205\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9257 - accuracy: 0.5091 - val_loss: 0.8924 - val_accuracy: 0.5285\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9138 - accuracy: 0.5137 - val_loss: 0.8907 - val_accuracy: 0.5365\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9132 - accuracy: 0.5276 - val_loss: 0.8866 - val_accuracy: 0.5375\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9088 - accuracy: 0.5209 - val_loss: 0.8881 - val_accuracy: 0.5275\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8956 - accuracy: 0.5304 - val_loss: 0.8833 - val_accuracy: 0.5410\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9080 - accuracy: 0.5203 - val_loss: 0.8750 - val_accuracy: 0.5445\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.5250 - val_loss: 0.8772 - val_accuracy: 0.5400\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8972 - accuracy: 0.5311 - val_loss: 0.8687 - val_accuracy: 0.5415\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8918 - accuracy: 0.5304 - val_loss: 0.8611 - val_accuracy: 0.5525\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.5348 - val_loss: 0.8563 - val_accuracy: 0.5510\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8898 - accuracy: 0.5275 - val_loss: 0.8484 - val_accuracy: 0.5450\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8730 - accuracy: 0.5453 - val_loss: 0.8480 - val_accuracy: 0.5595\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8665 - accuracy: 0.5500 - val_loss: 0.8383 - val_accuracy: 0.5495\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.5442 - val_loss: 0.8332 - val_accuracy: 0.5615\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8630 - accuracy: 0.5521 - val_loss: 0.8273 - val_accuracy: 0.5665\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8508 - accuracy: 0.5565 - val_loss: 0.8298 - val_accuracy: 0.5680\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8647 - accuracy: 0.5370 - val_loss: 0.8285 - val_accuracy: 0.5620\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8467 - accuracy: 0.5472 - val_loss: 0.8180 - val_accuracy: 0.5690\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8418 - accuracy: 0.5583 - val_loss: 0.8162 - val_accuracy: 0.5745\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8433 - accuracy: 0.5601 - val_loss: 0.8189 - val_accuracy: 0.5770\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8346 - accuracy: 0.5676 - val_loss: 0.8152 - val_accuracy: 0.5760\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8299 - accuracy: 0.5676 - val_loss: 0.8070 - val_accuracy: 0.5860\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.5675 - val_loss: 0.7984 - val_accuracy: 0.5830\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8317 - accuracy: 0.5738 - val_loss: 0.7916 - val_accuracy: 0.5965\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8174 - accuracy: 0.5894 - val_loss: 0.7917 - val_accuracy: 0.5955\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.5977 - val_loss: 0.7792 - val_accuracy: 0.6045\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7916 - accuracy: 0.6037 - val_loss: 0.7648 - val_accuracy: 0.6250\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7898 - accuracy: 0.6147 - val_loss: 0.7567 - val_accuracy: 0.6390\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7834 - accuracy: 0.6124 - val_loss: 0.7416 - val_accuracy: 0.6505\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7608 - accuracy: 0.6381 - val_loss: 0.7347 - val_accuracy: 0.6545\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.6640 - val_loss: 0.7291 - val_accuracy: 0.6630\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7460 - accuracy: 0.6558 - val_loss: 0.7144 - val_accuracy: 0.6610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7413 - accuracy: 0.6614 - val_loss: 0.7102 - val_accuracy: 0.6680\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.6652 - val_loss: 0.7067 - val_accuracy: 0.6660\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.6713 - val_loss: 0.7028 - val_accuracy: 0.6720\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.6581 - val_loss: 0.7023 - val_accuracy: 0.6710\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.6597 - val_loss: 0.7007 - val_accuracy: 0.6780\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.6712 - val_loss: 0.6972 - val_accuracy: 0.6780\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.6790 - val_loss: 0.6956 - val_accuracy: 0.6795\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.6713 - val_loss: 0.6958 - val_accuracy: 0.6740\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.6739 - val_loss: 0.6928 - val_accuracy: 0.6810\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.6716 - val_loss: 0.7018 - val_accuracy: 0.6755\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.6740 - val_loss: 0.6962 - val_accuracy: 0.6800\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.6844 - val_loss: 0.6933 - val_accuracy: 0.6770\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.6847 - val_loss: 0.6877 - val_accuracy: 0.6900\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.6758 - val_loss: 0.6925 - val_accuracy: 0.6800\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7108 - accuracy: 0.6763 - val_loss: 0.6932 - val_accuracy: 0.6770\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.6832 - val_loss: 0.6918 - val_accuracy: 0.6765\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.6784 - val_loss: 0.6910 - val_accuracy: 0.6820\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6898 - val_loss: 0.6845 - val_accuracy: 0.6900\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.6863 - val_loss: 0.6873 - val_accuracy: 0.6820\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.6806 - val_loss: 0.6892 - val_accuracy: 0.6805\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.6868 - val_loss: 0.6891 - val_accuracy: 0.6860\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6849 - val_loss: 0.6949 - val_accuracy: 0.6815\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6827 - val_loss: 0.6836 - val_accuracy: 0.6860\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.6724 - val_loss: 0.6908 - val_accuracy: 0.6820\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.6832 - val_loss: 0.6914 - val_accuracy: 0.6840\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.6748 - val_loss: 0.6831 - val_accuracy: 0.6925\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.6934 - val_loss: 0.6826 - val_accuracy: 0.6845\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.6815 - val_loss: 0.6812 - val_accuracy: 0.6920\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.6860 - val_loss: 0.6864 - val_accuracy: 0.6895\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.6847 - val_loss: 0.6924 - val_accuracy: 0.6800\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.6841 - val_loss: 0.6804 - val_accuracy: 0.6890\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6976 - val_loss: 0.6832 - val_accuracy: 0.6840\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6925 - val_loss: 0.6810 - val_accuracy: 0.6890\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.6887 - val_loss: 0.6855 - val_accuracy: 0.6870\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.6881 - val_loss: 0.6899 - val_accuracy: 0.6755\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.6748 - val_loss: 0.6821 - val_accuracy: 0.6895\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6794 - val_loss: 0.6815 - val_accuracy: 0.6895\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.6919 - val_loss: 0.6785 - val_accuracy: 0.6935\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6900 - val_loss: 0.6838 - val_accuracy: 0.6845\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.6764 - val_loss: 0.6839 - val_accuracy: 0.6835\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.6846 - val_loss: 0.6802 - val_accuracy: 0.6895\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6940 - val_loss: 0.6810 - val_accuracy: 0.6900\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6852 - val_loss: 0.6767 - val_accuracy: 0.6955\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6949 - val_loss: 0.6760 - val_accuracy: 0.6955\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.6946 - val_loss: 0.6769 - val_accuracy: 0.6915\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6956 - val_loss: 0.6750 - val_accuracy: 0.6965\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.6899 - val_loss: 0.6761 - val_accuracy: 0.6955\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.6887 - val_loss: 0.6750 - val_accuracy: 0.6920\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6936 - val_loss: 0.6760 - val_accuracy: 0.6900\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.7010 - val_loss: 0.6811 - val_accuracy: 0.6920\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.6941 - val_loss: 0.6727 - val_accuracy: 0.6955\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6959 - val_loss: 0.7108 - val_accuracy: 0.6665\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.6799 - val_loss: 0.6773 - val_accuracy: 0.7010\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6983 - val_loss: 0.6725 - val_accuracy: 0.6990\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6895 - val_loss: 0.6751 - val_accuracy: 0.6935\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6923 - val_loss: 0.6797 - val_accuracy: 0.6855\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6967 - val_loss: 0.6753 - val_accuracy: 0.6890\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.6885 - val_loss: 0.6711 - val_accuracy: 0.6920\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6903 - val_loss: 0.6715 - val_accuracy: 0.6985\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.7006 - val_loss: 0.6700 - val_accuracy: 0.6960\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6954 - val_loss: 0.6717 - val_accuracy: 0.6965\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.6935 - val_loss: 0.6715 - val_accuracy: 0.6960\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6868 - val_loss: 0.6737 - val_accuracy: 0.6960\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6873 - val_loss: 0.6673 - val_accuracy: 0.6980\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.7080 - val_loss: 0.6712 - val_accuracy: 0.6970\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6970 - val_loss: 0.6696 - val_accuracy: 0.6965\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.7024 - val_loss: 0.6959 - val_accuracy: 0.6855\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6832 - val_loss: 0.6679 - val_accuracy: 0.6925\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.6955 - val_loss: 0.6702 - val_accuracy: 0.7005\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.7016 - val_loss: 0.6851 - val_accuracy: 0.6915\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6964 - val_loss: 0.6665 - val_accuracy: 0.6975\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6984 - val_loss: 0.6708 - val_accuracy: 0.6935\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6959 - val_loss: 0.6750 - val_accuracy: 0.6925\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6997 - val_loss: 0.6694 - val_accuracy: 0.6955\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.7008 - val_loss: 0.6661 - val_accuracy: 0.6960\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.7097 - val_loss: 0.6678 - val_accuracy: 0.6945\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.7004 - val_loss: 0.6630 - val_accuracy: 0.6995\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.7047 - val_loss: 0.6656 - val_accuracy: 0.7020\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6939 - val_loss: 0.6661 - val_accuracy: 0.6980\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7013 - val_loss: 0.6659 - val_accuracy: 0.6995\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.7107 - val_loss: 0.6652 - val_accuracy: 0.7000\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.7002 - val_loss: 0.6658 - val_accuracy: 0.7055\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.7016 - val_loss: 0.6673 - val_accuracy: 0.6970\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6960 - val_loss: 0.6633 - val_accuracy: 0.7030\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.7021 - val_loss: 0.6663 - val_accuracy: 0.6955\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.7080 - val_loss: 0.6632 - val_accuracy: 0.7025\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.7101 - val_loss: 0.6603 - val_accuracy: 0.7060\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7054 - val_loss: 0.6650 - val_accuracy: 0.6995\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7113 - val_loss: 0.6685 - val_accuracy: 0.7020\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6988 - val_loss: 0.6646 - val_accuracy: 0.7035\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6933 - val_loss: 0.6692 - val_accuracy: 0.6985\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.7006 - val_loss: 0.6620 - val_accuracy: 0.6995\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.6932 - val_loss: 0.6649 - val_accuracy: 0.7015\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.7050 - val_loss: 0.6619 - val_accuracy: 0.7030\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6998 - val_loss: 0.6708 - val_accuracy: 0.7015\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.7019 - val_loss: 0.6674 - val_accuracy: 0.6970\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.7002 - val_loss: 0.6625 - val_accuracy: 0.7000\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.7064 - val_loss: 0.6628 - val_accuracy: 0.6995\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6989 - val_loss: 0.6579 - val_accuracy: 0.7065\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7054 - val_loss: 0.6629 - val_accuracy: 0.6965\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6963 - val_loss: 0.6627 - val_accuracy: 0.7020\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.7048 - val_loss: 0.6726 - val_accuracy: 0.6930\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.7048 - val_loss: 0.6593 - val_accuracy: 0.7025\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.7113 - val_loss: 0.6686 - val_accuracy: 0.7010\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.7073 - val_loss: 0.6595 - val_accuracy: 0.7055\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.7035 - val_loss: 0.6585 - val_accuracy: 0.7065\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6990 - val_loss: 0.6589 - val_accuracy: 0.7050\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6952 - val_loss: 0.6607 - val_accuracy: 0.7030\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.7064 - val_loss: 0.6603 - val_accuracy: 0.7005\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.7147 - val_loss: 0.6594 - val_accuracy: 0.7050\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.7069 - val_loss: 0.6563 - val_accuracy: 0.7025\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7092 - val_loss: 0.6560 - val_accuracy: 0.7070\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.7117 - val_loss: 0.6611 - val_accuracy: 0.7025\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6964 - val_loss: 0.6589 - val_accuracy: 0.7020\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.7149 - val_loss: 0.6594 - val_accuracy: 0.7010\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.7053 - val_loss: 0.6559 - val_accuracy: 0.7070\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.7084 - val_loss: 0.6569 - val_accuracy: 0.7075\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7020 - val_loss: 0.6589 - val_accuracy: 0.7045\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.7117 - val_loss: 0.6538 - val_accuracy: 0.7050\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.7086 - val_loss: 0.6630 - val_accuracy: 0.7065\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.7130 - val_loss: 0.6595 - val_accuracy: 0.6990\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7127 - val_loss: 0.6550 - val_accuracy: 0.7055\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7113 - val_loss: 0.6557 - val_accuracy: 0.7025\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.7052 - val_loss: 0.6537 - val_accuracy: 0.7085\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.7117 - val_loss: 0.6553 - val_accuracy: 0.7025\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6955 - val_loss: 0.6596 - val_accuracy: 0.6980\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7205 - val_loss: 0.6526 - val_accuracy: 0.7070\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.7017 - val_loss: 0.6528 - val_accuracy: 0.7100\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.7066 - val_loss: 0.6606 - val_accuracy: 0.7020\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.7075 - val_loss: 0.6531 - val_accuracy: 0.7070\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.7108 - val_loss: 0.6556 - val_accuracy: 0.7055\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.7137 - val_loss: 0.6545 - val_accuracy: 0.7000\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.7147 - val_loss: 0.6503 - val_accuracy: 0.7055\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.7055 - val_loss: 0.6631 - val_accuracy: 0.7025\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.7140 - val_loss: 0.6513 - val_accuracy: 0.7085\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7145 - val_loss: 0.6569 - val_accuracy: 0.7000\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7067 - val_loss: 0.6626 - val_accuracy: 0.6960\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7165 - val_loss: 0.6554 - val_accuracy: 0.7040\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.7109 - val_loss: 0.6538 - val_accuracy: 0.7060\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.7107 - val_loss: 0.6493 - val_accuracy: 0.7055\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.7072 - val_loss: 0.6543 - val_accuracy: 0.7045\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.7115 - val_loss: 0.6502 - val_accuracy: 0.7070\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.7164 - val_loss: 0.6525 - val_accuracy: 0.7050\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7168 - val_loss: 0.6563 - val_accuracy: 0.7005\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.7053 - val_loss: 0.6538 - val_accuracy: 0.7020\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7082 - val_loss: 0.6491 - val_accuracy: 0.7115\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7224 - val_loss: 0.6491 - val_accuracy: 0.7095\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7184 - val_loss: 0.6522 - val_accuracy: 0.7045\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7057 - val_loss: 0.6478 - val_accuracy: 0.7060\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.7179 - val_loss: 0.6510 - val_accuracy: 0.7055\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.7203 - val_loss: 0.6724 - val_accuracy: 0.6910\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7002 - val_loss: 0.6477 - val_accuracy: 0.7085\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7090 - val_loss: 0.6482 - val_accuracy: 0.7095\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7152 - val_loss: 0.6492 - val_accuracy: 0.7130\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.7163 - val_loss: 0.6495 - val_accuracy: 0.7080\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7122 - val_loss: 0.6512 - val_accuracy: 0.7045\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.7070 - val_loss: 0.6488 - val_accuracy: 0.7110\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7130 - val_loss: 0.6505 - val_accuracy: 0.7045\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7089 - val_loss: 0.6547 - val_accuracy: 0.7010\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.7084 - val_loss: 0.6502 - val_accuracy: 0.7110\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7165 - val_loss: 0.6508 - val_accuracy: 0.7090\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.7134 - val_loss: 0.6488 - val_accuracy: 0.7055\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.7175 - val_loss: 0.6486 - val_accuracy: 0.7100\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.7141 - val_loss: 0.6482 - val_accuracy: 0.7105\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7111 - val_loss: 0.6487 - val_accuracy: 0.7070\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7134 - val_loss: 0.6581 - val_accuracy: 0.7010\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7244 - val_loss: 0.6517 - val_accuracy: 0.7030\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.7260 - val_loss: 0.6488 - val_accuracy: 0.7075\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7120 - val_loss: 0.6605 - val_accuracy: 0.7020\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.7119 - val_loss: 0.6511 - val_accuracy: 0.7075\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7203 - val_loss: 0.6479 - val_accuracy: 0.7055\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7157 - val_loss: 0.6549 - val_accuracy: 0.7035\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.7115 - val_loss: 0.6536 - val_accuracy: 0.7045\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7143 - val_loss: 0.6508 - val_accuracy: 0.7085\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7115 - val_loss: 0.6572 - val_accuracy: 0.7015\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.7143 - val_loss: 0.6644 - val_accuracy: 0.6895\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7215 - val_loss: 0.6480 - val_accuracy: 0.7080\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7214 - val_loss: 0.6565 - val_accuracy: 0.7020\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7197 - val_loss: 0.6446 - val_accuracy: 0.7105\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7324 - val_loss: 0.6492 - val_accuracy: 0.7060\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7222 - val_loss: 0.6431 - val_accuracy: 0.7105\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7148 - val_loss: 0.6463 - val_accuracy: 0.7085\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7196 - val_loss: 0.6672 - val_accuracy: 0.7010\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7201 - val_loss: 0.6603 - val_accuracy: 0.6955\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7107 - val_loss: 0.6472 - val_accuracy: 0.7065\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7100 - val_loss: 0.6450 - val_accuracy: 0.7100\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.7231 - val_loss: 0.6579 - val_accuracy: 0.7000\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.7131 - val_loss: 0.6516 - val_accuracy: 0.7070\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.7152 - val_loss: 0.6456 - val_accuracy: 0.7100\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.7202 - val_loss: 0.6418 - val_accuracy: 0.7135\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7144 - val_loss: 0.6467 - val_accuracy: 0.7065\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.7203 - val_loss: 0.6481 - val_accuracy: 0.7095\n",
      "Epoch 1/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1010 - accuracy: 0.3335 - val_loss: 1.0986 - val_accuracy: 0.3355\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0968 - accuracy: 0.3635 - val_loss: 1.0962 - val_accuracy: 0.3515\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0935 - accuracy: 0.3822 - val_loss: 1.0915 - val_accuracy: 0.3670\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0886 - accuracy: 0.3788 - val_loss: 1.0821 - val_accuracy: 0.4115\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0819 - accuracy: 0.3966 - val_loss: 1.0691 - val_accuracy: 0.4305\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0708 - accuracy: 0.4067 - val_loss: 1.0525 - val_accuracy: 0.4365\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0532 - accuracy: 0.4424 - val_loss: 1.0340 - val_accuracy: 0.4540\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.4470 - val_loss: 1.0165 - val_accuracy: 0.4550\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.4479 - val_loss: 1.0009 - val_accuracy: 0.4535\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0030 - accuracy: 0.4602 - val_loss: 0.9925 - val_accuracy: 0.4490\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0008 - accuracy: 0.4662 - val_loss: 0.9733 - val_accuracy: 0.4740\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9878 - accuracy: 0.4860 - val_loss: 0.9630 - val_accuracy: 0.4705\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9788 - accuracy: 0.4768 - val_loss: 0.9529 - val_accuracy: 0.4790\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.4834 - val_loss: 0.9447 - val_accuracy: 0.4850\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9619 - accuracy: 0.4985 - val_loss: 0.9376 - val_accuracy: 0.4840\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9552 - accuracy: 0.4988 - val_loss: 0.9356 - val_accuracy: 0.4900\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.5085 - val_loss: 0.9315 - val_accuracy: 0.4965\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.5035 - val_loss: 0.9250 - val_accuracy: 0.5035\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9355 - accuracy: 0.5128 - val_loss: 0.9130 - val_accuracy: 0.5080\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9342 - accuracy: 0.5067 - val_loss: 0.9066 - val_accuracy: 0.5135\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9196 - accuracy: 0.5132 - val_loss: 0.9072 - val_accuracy: 0.5090\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.5148 - val_loss: 0.9010 - val_accuracy: 0.5155\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9143 - accuracy: 0.5202 - val_loss: 0.8917 - val_accuracy: 0.5215\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9019 - accuracy: 0.5282 - val_loss: 0.8809 - val_accuracy: 0.5340\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8948 - accuracy: 0.5300 - val_loss: 0.8774 - val_accuracy: 0.5335\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8946 - accuracy: 0.5224 - val_loss: 0.8679 - val_accuracy: 0.5470\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8801 - accuracy: 0.5386 - val_loss: 0.8604 - val_accuracy: 0.5555\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8874 - accuracy: 0.5308 - val_loss: 0.8563 - val_accuracy: 0.5555\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8690 - accuracy: 0.5361 - val_loss: 0.8459 - val_accuracy: 0.5620\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.5485 - val_loss: 0.8364 - val_accuracy: 0.5700\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8509 - accuracy: 0.5594 - val_loss: 0.8288 - val_accuracy: 0.5630\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8506 - accuracy: 0.5528 - val_loss: 0.8221 - val_accuracy: 0.5770\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8465 - accuracy: 0.5600 - val_loss: 0.8137 - val_accuracy: 0.5815\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8406 - accuracy: 0.5663 - val_loss: 0.8056 - val_accuracy: 0.5855\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8336 - accuracy: 0.5668 - val_loss: 0.7939 - val_accuracy: 0.5960\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8130 - accuracy: 0.5825 - val_loss: 0.7832 - val_accuracy: 0.6020\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8039 - accuracy: 0.5949 - val_loss: 0.7790 - val_accuracy: 0.6070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.5978 - val_loss: 0.7590 - val_accuracy: 0.6250\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.6155 - val_loss: 0.7523 - val_accuracy: 0.6215\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7666 - accuracy: 0.6253 - val_loss: 0.7388 - val_accuracy: 0.6380\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7395 - accuracy: 0.6371 - val_loss: 0.7252 - val_accuracy: 0.6435\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.6392 - val_loss: 0.7112 - val_accuracy: 0.6650\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7174 - accuracy: 0.6512 - val_loss: 0.7040 - val_accuracy: 0.6590\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7094 - accuracy: 0.6563 - val_loss: 0.7075 - val_accuracy: 0.6600\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.6597 - val_loss: 0.6869 - val_accuracy: 0.6720\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.6755 - val_loss: 0.6803 - val_accuracy: 0.6795\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6740 - val_loss: 0.6742 - val_accuracy: 0.6855\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.6747 - val_loss: 0.6713 - val_accuracy: 0.6895\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.6826 - val_loss: 0.6690 - val_accuracy: 0.6865\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6848 - val_loss: 0.6690 - val_accuracy: 0.6805\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6866 - val_loss: 0.6706 - val_accuracy: 0.6820\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6904 - val_loss: 0.6706 - val_accuracy: 0.6830\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.6882 - val_loss: 0.6632 - val_accuracy: 0.6900\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6905 - val_loss: 0.6647 - val_accuracy: 0.6970\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6882 - val_loss: 0.6625 - val_accuracy: 0.6875\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6916 - val_loss: 0.6551 - val_accuracy: 0.6935\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6837 - val_loss: 0.6617 - val_accuracy: 0.6905\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6908 - val_loss: 0.6597 - val_accuracy: 0.6885\n",
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7090 - val_loss: 0.6524 - val_accuracy: 0.6935\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.6999 - val_loss: 0.6550 - val_accuracy: 0.6910\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7038 - val_loss: 0.6513 - val_accuracy: 0.6895\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6978 - val_loss: 0.6501 - val_accuracy: 0.6955\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7117 - val_loss: 0.6504 - val_accuracy: 0.6995\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.7083 - val_loss: 0.6504 - val_accuracy: 0.6960\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7013 - val_loss: 0.6554 - val_accuracy: 0.6935\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.7036 - val_loss: 0.6513 - val_accuracy: 0.6930\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6917 - val_loss: 0.6472 - val_accuracy: 0.6980\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.7149 - val_loss: 0.6520 - val_accuracy: 0.6965\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.7090 - val_loss: 0.6494 - val_accuracy: 0.6995\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7081 - val_loss: 0.6472 - val_accuracy: 0.6975\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.7073 - val_loss: 0.6462 - val_accuracy: 0.6975\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7109 - val_loss: 0.6532 - val_accuracy: 0.6925\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.7092 - val_loss: 0.6500 - val_accuracy: 0.7020\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.7150 - val_loss: 0.6453 - val_accuracy: 0.6945\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7071 - val_loss: 0.6487 - val_accuracy: 0.6975\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7064 - val_loss: 0.6455 - val_accuracy: 0.6980\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.7009 - val_loss: 0.6472 - val_accuracy: 0.7005\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.7100 - val_loss: 0.6476 - val_accuracy: 0.6970\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.7090 - val_loss: 0.6508 - val_accuracy: 0.6970\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.7118 - val_loss: 0.6462 - val_accuracy: 0.6980\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.7093 - val_loss: 0.6469 - val_accuracy: 0.6975\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.7062 - val_loss: 0.6453 - val_accuracy: 0.6980\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.7127 - val_loss: 0.6437 - val_accuracy: 0.7010\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.7060 - val_loss: 0.6465 - val_accuracy: 0.6965\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7089 - val_loss: 0.6453 - val_accuracy: 0.7030\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6986 - val_loss: 0.6438 - val_accuracy: 0.7020\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.7052 - val_loss: 0.6446 - val_accuracy: 0.7000\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7155 - val_loss: 0.6423 - val_accuracy: 0.6995\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.7093 - val_loss: 0.6434 - val_accuracy: 0.6945\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.7121 - val_loss: 0.6416 - val_accuracy: 0.6980\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7022 - val_loss: 0.6399 - val_accuracy: 0.6990\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.7148 - val_loss: 0.6431 - val_accuracy: 0.7010\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.7168 - val_loss: 0.6421 - val_accuracy: 0.7015\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7159 - val_loss: 0.6402 - val_accuracy: 0.7000\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7064 - val_loss: 0.6434 - val_accuracy: 0.6955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7138 - val_loss: 0.6422 - val_accuracy: 0.6985\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.7088 - val_loss: 0.6400 - val_accuracy: 0.6995\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7119 - val_loss: 0.6404 - val_accuracy: 0.7010\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.7038 - val_loss: 0.6394 - val_accuracy: 0.6985\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.7147 - val_loss: 0.6407 - val_accuracy: 0.7010\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7120 - val_loss: 0.6384 - val_accuracy: 0.6990\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7057 - val_loss: 0.6401 - val_accuracy: 0.6980\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.7125 - val_loss: 0.6409 - val_accuracy: 0.6985\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7249 - val_loss: 0.6398 - val_accuracy: 0.7010\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.7147 - val_loss: 0.6415 - val_accuracy: 0.7005\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.7157 - val_loss: 0.6389 - val_accuracy: 0.6995\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7212 - val_loss: 0.6386 - val_accuracy: 0.6990\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7229 - val_loss: 0.6387 - val_accuracy: 0.7020\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7154 - val_loss: 0.6367 - val_accuracy: 0.7010\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7115 - val_loss: 0.6399 - val_accuracy: 0.6960\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7183 - val_loss: 0.6360 - val_accuracy: 0.6980\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.7094 - val_loss: 0.6364 - val_accuracy: 0.7000\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7225 - val_loss: 0.6400 - val_accuracy: 0.7040\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7236 - val_loss: 0.6379 - val_accuracy: 0.6985\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7259 - val_loss: 0.6342 - val_accuracy: 0.6995\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.7205 - val_loss: 0.6358 - val_accuracy: 0.6985\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.7213 - val_loss: 0.6358 - val_accuracy: 0.6975\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.7184 - val_loss: 0.6382 - val_accuracy: 0.6975\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7200 - val_loss: 0.6392 - val_accuracy: 0.6955\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7166 - val_loss: 0.6380 - val_accuracy: 0.6985\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7234 - val_loss: 0.6336 - val_accuracy: 0.6970\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.7225 - val_loss: 0.6335 - val_accuracy: 0.6950\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7229 - val_loss: 0.6330 - val_accuracy: 0.6955\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7210 - val_loss: 0.6319 - val_accuracy: 0.6950\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.7287 - val_loss: 0.6317 - val_accuracy: 0.6975\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7280 - val_loss: 0.6325 - val_accuracy: 0.6955\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.7279 - val_loss: 0.6317 - val_accuracy: 0.6980\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7298 - val_loss: 0.6327 - val_accuracy: 0.6975\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7243 - val_loss: 0.6447 - val_accuracy: 0.6925\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7251 - val_loss: 0.6305 - val_accuracy: 0.6955\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7262 - val_loss: 0.6313 - val_accuracy: 0.6920\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7208 - val_loss: 0.6337 - val_accuracy: 0.6925\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7233 - val_loss: 0.6355 - val_accuracy: 0.6910\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7301 - val_loss: 0.6318 - val_accuracy: 0.6940\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.7270 - val_loss: 0.6324 - val_accuracy: 0.7065\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7251 - val_loss: 0.6313 - val_accuracy: 0.6940\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7235 - val_loss: 0.6315 - val_accuracy: 0.6970\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7293 - val_loss: 0.6308 - val_accuracy: 0.6965\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7353 - val_loss: 0.6295 - val_accuracy: 0.7015\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.7245 - val_loss: 0.6376 - val_accuracy: 0.6905\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7250 - val_loss: 0.6336 - val_accuracy: 0.6920\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7317 - val_loss: 0.6281 - val_accuracy: 0.7005\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7299 - val_loss: 0.6296 - val_accuracy: 0.7060\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7185 - val_loss: 0.6276 - val_accuracy: 0.6995\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7281 - val_loss: 0.6291 - val_accuracy: 0.6980\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7216 - val_loss: 0.6284 - val_accuracy: 0.6960\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.7281 - val_loss: 0.6302 - val_accuracy: 0.6970\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7297 - val_loss: 0.6263 - val_accuracy: 0.7035\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7261 - val_loss: 0.6270 - val_accuracy: 0.7005\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7379 - val_loss: 0.6271 - val_accuracy: 0.7050\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7241 - val_loss: 0.6273 - val_accuracy: 0.6995\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7327 - val_loss: 0.6275 - val_accuracy: 0.7020\n",
      "Epoch 153/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7244 - val_loss: 0.6268 - val_accuracy: 0.7060\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7355 - val_loss: 0.6264 - val_accuracy: 0.7060\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7378 - val_loss: 0.6250 - val_accuracy: 0.7065\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7373 - val_loss: 0.6271 - val_accuracy: 0.7020\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7384 - val_loss: 0.6344 - val_accuracy: 0.6975\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7363 - val_loss: 0.6280 - val_accuracy: 0.6980\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7365 - val_loss: 0.6228 - val_accuracy: 0.7080\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7365 - val_loss: 0.6235 - val_accuracy: 0.7015\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7262 - val_loss: 0.6272 - val_accuracy: 0.7035\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7374 - val_loss: 0.6249 - val_accuracy: 0.7080\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7330 - val_loss: 0.6231 - val_accuracy: 0.7085\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7371 - val_loss: 0.6277 - val_accuracy: 0.7095\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7260 - val_loss: 0.6261 - val_accuracy: 0.6995\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7398 - val_loss: 0.6252 - val_accuracy: 0.7055\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7294 - val_loss: 0.6259 - val_accuracy: 0.7025\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7334 - val_loss: 0.6244 - val_accuracy: 0.7100\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7258 - val_loss: 0.6239 - val_accuracy: 0.7050\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7445 - val_loss: 0.6226 - val_accuracy: 0.7075\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7358 - val_loss: 0.6217 - val_accuracy: 0.7085\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7315 - val_loss: 0.6227 - val_accuracy: 0.7035\n",
      "Epoch 173/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7368 - val_loss: 0.6227 - val_accuracy: 0.7050\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7353 - val_loss: 0.6310 - val_accuracy: 0.7020\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7287 - val_loss: 0.6218 - val_accuracy: 0.7100\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7430 - val_loss: 0.6261 - val_accuracy: 0.7050\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7386 - val_loss: 0.6247 - val_accuracy: 0.7060\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7448 - val_loss: 0.6195 - val_accuracy: 0.7085\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7451 - val_loss: 0.6198 - val_accuracy: 0.7065\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7496 - val_loss: 0.6195 - val_accuracy: 0.7075\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7339 - val_loss: 0.6218 - val_accuracy: 0.7035\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7382 - val_loss: 0.6204 - val_accuracy: 0.7060\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7396 - val_loss: 0.6191 - val_accuracy: 0.7070\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7431 - val_loss: 0.6280 - val_accuracy: 0.7050\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.7299 - val_loss: 0.6195 - val_accuracy: 0.7060\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7425 - val_loss: 0.6205 - val_accuracy: 0.7090\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7378 - val_loss: 0.6243 - val_accuracy: 0.7060\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7380 - val_loss: 0.6200 - val_accuracy: 0.7075\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7328 - val_loss: 0.6222 - val_accuracy: 0.7080\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7460 - val_loss: 0.6178 - val_accuracy: 0.7090\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7536 - val_loss: 0.6188 - val_accuracy: 0.7095\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7434 - val_loss: 0.6205 - val_accuracy: 0.7080\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7418 - val_loss: 0.6173 - val_accuracy: 0.7135\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7374 - val_loss: 0.6195 - val_accuracy: 0.7110\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7426 - val_loss: 0.6222 - val_accuracy: 0.7055\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.7414 - val_loss: 0.6228 - val_accuracy: 0.7080\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7416 - val_loss: 0.6179 - val_accuracy: 0.7170\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.7472 - val_loss: 0.6250 - val_accuracy: 0.7075\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7416 - val_loss: 0.6165 - val_accuracy: 0.7125\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7459 - val_loss: 0.6176 - val_accuracy: 0.7110\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7435 - val_loss: 0.6189 - val_accuracy: 0.7105\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7501 - val_loss: 0.6160 - val_accuracy: 0.7125\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7460 - val_loss: 0.6196 - val_accuracy: 0.7125\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7478 - val_loss: 0.6187 - val_accuracy: 0.7175\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7461 - val_loss: 0.6174 - val_accuracy: 0.7155\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7439 - val_loss: 0.6126 - val_accuracy: 0.7190\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7557 - val_loss: 0.6132 - val_accuracy: 0.7145\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7491 - val_loss: 0.6136 - val_accuracy: 0.7165\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7516 - val_loss: 0.6161 - val_accuracy: 0.7175\n",
      "Epoch 210/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7373 - val_loss: 0.6126 - val_accuracy: 0.7190\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7382 - val_loss: 0.6160 - val_accuracy: 0.7180\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7526 - val_loss: 0.6134 - val_accuracy: 0.7175\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7408 - val_loss: 0.6158 - val_accuracy: 0.7160\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7518 - val_loss: 0.6148 - val_accuracy: 0.7175\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7493 - val_loss: 0.6126 - val_accuracy: 0.7215\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7510 - val_loss: 0.6127 - val_accuracy: 0.7200\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7483 - val_loss: 0.6152 - val_accuracy: 0.7205\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7452 - val_loss: 0.6158 - val_accuracy: 0.7200\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7488 - val_loss: 0.6150 - val_accuracy: 0.7245\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7491 - val_loss: 0.6141 - val_accuracy: 0.7195\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7491 - val_loss: 0.6161 - val_accuracy: 0.7145\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7490 - val_loss: 0.6118 - val_accuracy: 0.7210\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7493 - val_loss: 0.6153 - val_accuracy: 0.7190\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7446 - val_loss: 0.6127 - val_accuracy: 0.7230\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7463 - val_loss: 0.6125 - val_accuracy: 0.7200\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7492 - val_loss: 0.6122 - val_accuracy: 0.7205\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7569 - val_loss: 0.6139 - val_accuracy: 0.7190\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7547 - val_loss: 0.6111 - val_accuracy: 0.7195\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7460 - val_loss: 0.6109 - val_accuracy: 0.7190\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7542 - val_loss: 0.6113 - val_accuracy: 0.7180\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7492 - val_loss: 0.6143 - val_accuracy: 0.7190\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7552 - val_loss: 0.6100 - val_accuracy: 0.7200\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7531 - val_loss: 0.6110 - val_accuracy: 0.7210\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7547 - val_loss: 0.6108 - val_accuracy: 0.7235\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7527 - val_loss: 0.6095 - val_accuracy: 0.7270\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7595 - val_loss: 0.6154 - val_accuracy: 0.7190\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7432 - val_loss: 0.6154 - val_accuracy: 0.7210\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7505 - val_loss: 0.6084 - val_accuracy: 0.7205\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7469 - val_loss: 0.6193 - val_accuracy: 0.7185\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7542 - val_loss: 0.6157 - val_accuracy: 0.7210\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7577 - val_loss: 0.6163 - val_accuracy: 0.7150\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7543 - val_loss: 0.6122 - val_accuracy: 0.7175\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7496 - val_loss: 0.6105 - val_accuracy: 0.7270\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7530 - val_loss: 0.6101 - val_accuracy: 0.7230\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7576 - val_loss: 0.6102 - val_accuracy: 0.7205\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7550 - val_loss: 0.6094 - val_accuracy: 0.7195\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7555 - val_loss: 0.6181 - val_accuracy: 0.7215\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7612 - val_loss: 0.6109 - val_accuracy: 0.7235\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7619 - val_loss: 0.6105 - val_accuracy: 0.7200\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7567 - val_loss: 0.6099 - val_accuracy: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ab6422c10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "model1 = compile_model( regularizers.l2,  0.1)\n",
    "model2 = compile_model( regularizers.l2,  0.001)\n",
    "\n",
    "model1.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)\n",
    "model2.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(20,5), sharey=True)\n",
    "colors = [\"#D81B60\", \"#1E88E5\", \"#FFC107\", \"#004D40\"]\n",
    "\n",
    "filters, biases = model1.layers[0].get_weights()\n",
    "for i in range(4):\n",
    "    axes[0].plot(filters[:,:,i], color = colors[i],label = \"{} filter\".format(i+1), lw =2.5)\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"Strong regularization\")\n",
    "filters, biases = model2.layers[0].get_weights()\n",
    "for i in range(4):\n",
    "    axes[1].plot(filters[:,:,i], color = colors[i], label = f\"{i+1} filter\", lw =2.5)\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Weak regularization\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for strong regularization is 0.71, while for weak regularization is 0.72\n"
     ]
    }
   ],
   "source": [
    "results1 = model1.evaluate(x_test, y_test, verbose = 0)\n",
    "results2 = model2.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "print(f\"Validation loss for strong regularization is {results1[1]:1.2}, while for weak regularization is {results2[1]:1.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily see how strong regularization give weights of almost zero value, while pattern recognition is not visible. Results are also similar in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 51, 4)             44        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 597\n",
      "Trainable params: 597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reg = regularizers.l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=4, kernel_size = 10,\n",
    "                kernel_regularizer = reg,\n",
    "                bias_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
