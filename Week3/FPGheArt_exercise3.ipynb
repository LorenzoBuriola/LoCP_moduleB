{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import initializers, regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "str0 = \"ts_L60_Z12_A500_DX50_bias5_N10000\"\n",
    "\n",
    "fnamex = \"DATA/x_\"+str0+\".csv\"\n",
    "fnamey = \"DATA/y_\"+str0+\".csv\"\n",
    "\n",
    "x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "N = len(x)\n",
    "print(N)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_std =  scaler.fit_transform(x.T).T\n",
    "\n",
    "plt.plot(x_std[0], label = '0')\n",
    "plt.plot(x_std[1], label = '1')\n",
    "plt.plot(x_std[2], label = '2')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "N_categ = 3\n",
    "y = np.zeros((N,N_categ))\n",
    "\n",
    "for n in range(N):\n",
    "    y[n][categ[n]] = 1.\n",
    "    \n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 8000 2000 60\n"
     ]
    }
   ],
   "source": [
    "perc_train = 0.8\n",
    "N_train = int(N*perc_train)\n",
    "N_val = N-N_train\n",
    "\n",
    "x_train = x_std[:N_train]\n",
    "y_train = y[:N_train]\n",
    "x_val = x_std[N_train:]\n",
    "y_val = y[N_train:]\n",
    "\n",
    "\n",
    "L = len(x[0])\n",
    "print(N, N_train, N_val, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],L,1) #1 - channel (RGB:3)\n",
    "                                                # L = sample size\n",
    "x_val = x_val.reshape(x_val.shape[0],L,1)\n",
    "\n",
    "input_shape = (L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "reg = regularizers.l2(0.01) #Lasso\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "#kernel_size = 11... similar to 12 as before\n",
    "model.add(Conv1D( filters = 5, kernel_size = 11, kernel_regularizer = reg, \n",
    "                 kernel_initializer = ini, \n",
    "                 activation = \"relu\", \n",
    "                 input_shape = input_shape                \n",
    "                ))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(filters = 5, kernel_size = 7, \n",
    "                 activation = \"relu\", \n",
    "                ))\n",
    "model.add(MaxPooling1D(2)) #optional\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, \n",
    "              optimizer = \"adam\", \n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "# model.save_weights(\"Original_Weights_CNN1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Working!\n",
    "The NN has as input larger and larger numbers. We shall manipulate the data at the beginning for example reshuffling them as they have average 0 and remove their standard deviation (set it to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = 250, epochs = 250, \n",
    "                 validation_data = (x_val, y_val), \n",
    "                verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(categ[N_train:],np.argmax(model.predict(x_val), axis=1),  normalize = 'true')\n",
    "\n",
    "\n",
    "#Better visualization of confusion matrices\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize = (15, 8))\n",
    "ax1.matshow(c_matrix, cmap = plt.cm.YlGn, alpha = 0.5)\n",
    "ax1.set_xticks(np.arange(3))\n",
    "ax1.set_yticks(np.arange(3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax1.text(x=j, y=i, s=round(c_matrix[i, j],2), ha=\"center\", va=\"center\")\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.set_xlabel('predicted label')\n",
    "ax1.set_ylabel('true label')\n",
    "ax1.set_title('CNN')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Discrimination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = np.linspace(50,500,10)\n",
    "res = []\n",
    "\n",
    "for A in As[-3:]:\n",
    "    str0 = f\"ts_L60_Z12_A{A}_DX50_bias5_N10000\"\n",
    "    fnamex = \"DATA/x_\" + str0 + \".csv\"\n",
    "    fnamey = \"DATA/y_\" + str0 + \".csv\"\n",
    "    \n",
    "    x = np.asarray(pd.read_csv(fnamex, header = None))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_std =  scaler.fit_transform(x.T).T\n",
    "    categ  = np.asarray(pd.read_csv(fnamey, header = None), dtype = int)\n",
    "    N_categ = 3\n",
    "    y = np.zeros((N,N_categ))\n",
    "\n",
    "    for n in range(N):\n",
    "        y[n][categ[n]] = 1.\n",
    "\n",
    "    perc_train = 0.8\n",
    "    N_train = int(N*perc_train)\n",
    "    N_val = N-N_train\n",
    "\n",
    "    x_train = x_std[:N_train]\n",
    "    y_train = y[:N_train]\n",
    "    x_val = x_std[N_train:]\n",
    "    y_val = y[N_train:]\n",
    "\n",
    "\n",
    "    L = len(x[0])\n",
    "    x_train = x_train.reshape(x_train.shape[0],L,1) #1 - channel (RGB:3)\n",
    "                                                   # L = sample size\n",
    "    x_val = x_val.reshape(x_val.shape[0],L,1)\n",
    "\n",
    "    input_shape = (L,1)\n",
    "    \n",
    "#     model.load_weights(\"Original_Weights_CNN1.h5\")\n",
    "    hist = model.fit(x_train, y_train, batch_size = 250, epochs = 50, \n",
    "                 validation_data = (x_val, y_val), \n",
    "                verbose = 2, shuffle = True)\n",
    "    res.append(pd.DataFrame(hist))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POINT 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "x_ts_comp_N10000.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8273455c18dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_ts_comp_N10000.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcateg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_ts_comp_N10000.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python38/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python38/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python38/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: x_ts_comp_N10000.csv not found."
     ]
    }
   ],
   "source": [
    "x = np.loadtxt(\"DATA/x_ts_comp_N10000.csv\", delimiter =\",\")\n",
    "categ_y = np.loadtxt(\"DATA/y_ts_comp_N10000.csv\", delimiter =\",\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x =  scaler.fit_transform(x.T).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(categ_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(x[0])\n",
    "input_shape = (len(x[0]),1)\n",
    "N_categ = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2)\n",
    "x_train = x_train.reshape(x_train.shape[0],L,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],L,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 50, 4)             48        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg = regularizers.l1_l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=4, kernel_size = 11,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_32 (Conv1D)           (None, 56, 3)             18        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_28 (Averag (None, 11, 3)             0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                340       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 611\n",
      "Trainable params: 611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l1_l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=3, kernel_size = 5,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 38, 13)            312       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_25 (Averag (None, 7, 13)             0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3)                 276       \n",
      "=================================================================\n",
      "Total params: 588\n",
      "Trainable params: 588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers, regularizers\n",
    "reg = regularizers.l1_l2(0.001)\n",
    "np.random.seed(12345)\n",
    "\n",
    "ini = initializers.RandomNormal(mean = 0, stddev = 0.05)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=13, kernel_size = 23,\n",
    "                kernel_regularizer = reg,\n",
    "                kernel_initializer=ini,\n",
    "                activation = \"relu\",\n",
    "                input_shape = input_shape\n",
    "                ))\n",
    "model.add(AveragePooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(N_categ, activation=\"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum= 0.9, nesterov=True, decay = 1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 1.1022 - accuracy: 0.3405 - val_loss: 1.0980 - val_accuracy: 0.3465\n",
      "Epoch 2/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0965 - accuracy: 0.3554 - val_loss: 1.0940 - val_accuracy: 0.3585\n",
      "Epoch 3/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0919 - accuracy: 0.3745 - val_loss: 1.0901 - val_accuracy: 0.3605\n",
      "Epoch 4/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0857 - accuracy: 0.3887 - val_loss: 1.0840 - val_accuracy: 0.3790\n",
      "Epoch 5/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0786 - accuracy: 0.3985 - val_loss: 1.0750 - val_accuracy: 0.4025\n",
      "Epoch 6/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0730 - accuracy: 0.4056 - val_loss: 1.0618 - val_accuracy: 0.4145\n",
      "Epoch 7/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0567 - accuracy: 0.4200 - val_loss: 1.0479 - val_accuracy: 0.4195\n",
      "Epoch 8/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0397 - accuracy: 0.4329 - val_loss: 1.0357 - val_accuracy: 0.4285\n",
      "Epoch 9/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0345 - accuracy: 0.4504 - val_loss: 1.0229 - val_accuracy: 0.4430\n",
      "Epoch 10/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0238 - accuracy: 0.4532 - val_loss: 1.0098 - val_accuracy: 0.4570\n",
      "Epoch 11/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0130 - accuracy: 0.4540 - val_loss: 0.9980 - val_accuracy: 0.4680\n",
      "Epoch 12/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9998 - accuracy: 0.4711 - val_loss: 0.9861 - val_accuracy: 0.4705\n",
      "Epoch 13/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9884 - accuracy: 0.4700 - val_loss: 0.9750 - val_accuracy: 0.4860\n",
      "Epoch 14/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9831 - accuracy: 0.4780 - val_loss: 0.9628 - val_accuracy: 0.4960\n",
      "Epoch 15/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9693 - accuracy: 0.4749 - val_loss: 0.9507 - val_accuracy: 0.5020\n",
      "Epoch 16/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9579 - accuracy: 0.4960 - val_loss: 0.9400 - val_accuracy: 0.5055\n",
      "Epoch 17/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9445 - accuracy: 0.5020 - val_loss: 0.9269 - val_accuracy: 0.5065\n",
      "Epoch 18/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9396 - accuracy: 0.5082 - val_loss: 0.9144 - val_accuracy: 0.5090\n",
      "Epoch 19/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9229 - accuracy: 0.5076 - val_loss: 0.9070 - val_accuracy: 0.5245\n",
      "Epoch 20/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9217 - accuracy: 0.5094 - val_loss: 0.8963 - val_accuracy: 0.5155\n",
      "Epoch 21/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9138 - accuracy: 0.5179 - val_loss: 0.8900 - val_accuracy: 0.5185\n",
      "Epoch 22/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9003 - accuracy: 0.5179 - val_loss: 0.8811 - val_accuracy: 0.5320\n",
      "Epoch 23/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8891 - accuracy: 0.5290 - val_loss: 0.8798 - val_accuracy: 0.5370\n",
      "Epoch 24/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8921 - accuracy: 0.5437 - val_loss: 0.8715 - val_accuracy: 0.5375\n",
      "Epoch 25/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8739 - accuracy: 0.5428 - val_loss: 0.8668 - val_accuracy: 0.5400\n",
      "Epoch 26/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8632 - accuracy: 0.5438 - val_loss: 0.8625 - val_accuracy: 0.5420\n",
      "Epoch 27/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8705 - accuracy: 0.5330 - val_loss: 0.8598 - val_accuracy: 0.5435\n",
      "Epoch 28/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8575 - accuracy: 0.5389 - val_loss: 0.8562 - val_accuracy: 0.5530\n",
      "Epoch 29/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8711 - accuracy: 0.5448 - val_loss: 0.8546 - val_accuracy: 0.5470\n",
      "Epoch 30/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8627 - accuracy: 0.5384 - val_loss: 0.8468 - val_accuracy: 0.5530\n",
      "Epoch 31/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8592 - accuracy: 0.5473 - val_loss: 0.8462 - val_accuracy: 0.5550\n",
      "Epoch 32/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8528 - accuracy: 0.5442 - val_loss: 0.8374 - val_accuracy: 0.5665\n",
      "Epoch 33/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8321 - accuracy: 0.5624 - val_loss: 0.8322 - val_accuracy: 0.5660\n",
      "Epoch 34/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8318 - accuracy: 0.5728 - val_loss: 0.8271 - val_accuracy: 0.5695\n",
      "Epoch 35/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8300 - accuracy: 0.5582 - val_loss: 0.8171 - val_accuracy: 0.5795\n",
      "Epoch 36/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8139 - accuracy: 0.5800 - val_loss: 0.8099 - val_accuracy: 0.5870\n",
      "Epoch 37/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.5917 - val_loss: 0.7990 - val_accuracy: 0.5970\n",
      "Epoch 38/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8104 - accuracy: 0.5802 - val_loss: 0.7948 - val_accuracy: 0.5975\n",
      "Epoch 39/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.8016 - accuracy: 0.5969 - val_loss: 0.7839 - val_accuracy: 0.6130\n",
      "Epoch 40/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7854 - accuracy: 0.6068 - val_loss: 0.7718 - val_accuracy: 0.6250\n",
      "Epoch 41/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7843 - accuracy: 0.6106 - val_loss: 0.7617 - val_accuracy: 0.6360\n",
      "Epoch 42/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7808 - accuracy: 0.6233 - val_loss: 0.7553 - val_accuracy: 0.6370\n",
      "Epoch 43/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.6321 - val_loss: 0.7443 - val_accuracy: 0.6490\n",
      "Epoch 44/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7594 - accuracy: 0.6414 - val_loss: 0.7373 - val_accuracy: 0.6515\n",
      "Epoch 45/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7557 - accuracy: 0.6430 - val_loss: 0.7283 - val_accuracy: 0.6565\n",
      "Epoch 46/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.6502 - val_loss: 0.7238 - val_accuracy: 0.6580\n",
      "Epoch 47/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.6669 - val_loss: 0.7197 - val_accuracy: 0.6670\n",
      "Epoch 48/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.6624 - val_loss: 0.7145 - val_accuracy: 0.6660\n",
      "Epoch 49/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7455 - accuracy: 0.6579 - val_loss: 0.7107 - val_accuracy: 0.6710\n",
      "Epoch 50/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.6710 - val_loss: 0.7063 - val_accuracy: 0.6735\n",
      "Epoch 51/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.6637 - val_loss: 0.7045 - val_accuracy: 0.6755\n",
      "Epoch 52/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.6594 - val_loss: 0.7046 - val_accuracy: 0.6805\n",
      "Epoch 53/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7280 - accuracy: 0.6753 - val_loss: 0.7008 - val_accuracy: 0.6820\n",
      "Epoch 54/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7319 - accuracy: 0.6686 - val_loss: 0.6988 - val_accuracy: 0.6820\n",
      "Epoch 55/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.6822 - val_loss: 0.6935 - val_accuracy: 0.6825\n",
      "Epoch 56/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.6804 - val_loss: 0.6933 - val_accuracy: 0.6795\n",
      "Epoch 57/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7315 - accuracy: 0.6665 - val_loss: 0.6950 - val_accuracy: 0.6925\n",
      "Epoch 58/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.6807 - val_loss: 0.6920 - val_accuracy: 0.6855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7203 - accuracy: 0.6720 - val_loss: 0.6888 - val_accuracy: 0.6870\n",
      "Epoch 60/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.6810 - val_loss: 0.6886 - val_accuracy: 0.6925\n",
      "Epoch 61/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.6693 - val_loss: 0.6881 - val_accuracy: 0.6865\n",
      "Epoch 62/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7102 - accuracy: 0.6623 - val_loss: 0.6873 - val_accuracy: 0.6875\n",
      "Epoch 63/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.6755 - val_loss: 0.6851 - val_accuracy: 0.6915\n",
      "Epoch 64/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.6812 - val_loss: 0.6839 - val_accuracy: 0.6880\n",
      "Epoch 65/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7129 - accuracy: 0.6733 - val_loss: 0.6838 - val_accuracy: 0.6885\n",
      "Epoch 66/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7031 - accuracy: 0.6842 - val_loss: 0.6837 - val_accuracy: 0.6865\n",
      "Epoch 67/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.6846 - val_loss: 0.6816 - val_accuracy: 0.7010\n",
      "Epoch 68/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.6769 - val_loss: 0.6797 - val_accuracy: 0.6920\n",
      "Epoch 69/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7068 - accuracy: 0.6851 - val_loss: 0.6809 - val_accuracy: 0.6885\n",
      "Epoch 70/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.6757 - val_loss: 0.6792 - val_accuracy: 0.6865\n",
      "Epoch 71/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7034 - accuracy: 0.6791 - val_loss: 0.6803 - val_accuracy: 0.6925\n",
      "Epoch 72/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7070 - accuracy: 0.6811 - val_loss: 0.6767 - val_accuracy: 0.6890\n",
      "Epoch 73/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7103 - accuracy: 0.6830 - val_loss: 0.6790 - val_accuracy: 0.7040\n",
      "Epoch 74/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.6885 - val_loss: 0.6775 - val_accuracy: 0.7035\n",
      "Epoch 75/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.6846 - val_loss: 0.6752 - val_accuracy: 0.6965\n",
      "Epoch 76/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.6817 - val_loss: 0.6743 - val_accuracy: 0.6980\n",
      "Epoch 77/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7014 - accuracy: 0.6905 - val_loss: 0.6791 - val_accuracy: 0.6865\n",
      "Epoch 78/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.6752 - val_loss: 0.6733 - val_accuracy: 0.6935\n",
      "Epoch 79/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.6837 - val_loss: 0.6716 - val_accuracy: 0.7015\n",
      "Epoch 80/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.6889 - val_loss: 0.6704 - val_accuracy: 0.6920\n",
      "Epoch 81/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.6926 - val_loss: 0.6696 - val_accuracy: 0.7005\n",
      "Epoch 82/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.6897 - val_loss: 0.6695 - val_accuracy: 0.6935\n",
      "Epoch 83/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.6951 - val_loss: 0.6700 - val_accuracy: 0.7025\n",
      "Epoch 84/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.6871 - val_loss: 0.6717 - val_accuracy: 0.6975\n",
      "Epoch 85/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.6853 - val_loss: 0.6713 - val_accuracy: 0.7015\n",
      "Epoch 86/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.6923 - val_loss: 0.6691 - val_accuracy: 0.7000\n",
      "Epoch 87/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.6849 - val_loss: 0.6688 - val_accuracy: 0.7010\n",
      "Epoch 88/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.6841 - val_loss: 0.6699 - val_accuracy: 0.7005\n",
      "Epoch 89/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.7005 - val_loss: 0.6675 - val_accuracy: 0.6975\n",
      "Epoch 90/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.6956 - val_loss: 0.6659 - val_accuracy: 0.6965\n",
      "Epoch 91/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.6921 - val_loss: 0.6661 - val_accuracy: 0.7000\n",
      "Epoch 92/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6964 - accuracy: 0.6822 - val_loss: 0.6655 - val_accuracy: 0.6990\n",
      "Epoch 93/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.7027 - val_loss: 0.6648 - val_accuracy: 0.6990\n",
      "Epoch 94/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.7079 - val_loss: 0.6632 - val_accuracy: 0.6970\n",
      "Epoch 95/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6936 - val_loss: 0.6629 - val_accuracy: 0.7020\n",
      "Epoch 96/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.6867 - val_loss: 0.6636 - val_accuracy: 0.7050\n",
      "Epoch 97/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6765 - accuracy: 0.6956 - val_loss: 0.6660 - val_accuracy: 0.7060\n",
      "Epoch 98/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.6829 - val_loss: 0.6624 - val_accuracy: 0.7095\n",
      "Epoch 99/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.6989 - val_loss: 0.6623 - val_accuracy: 0.7020\n",
      "Epoch 100/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.6957 - val_loss: 0.6626 - val_accuracy: 0.7035\n",
      "Epoch 101/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.6855 - val_loss: 0.6610 - val_accuracy: 0.7030\n",
      "Epoch 102/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.6887 - val_loss: 0.6603 - val_accuracy: 0.7095\n",
      "Epoch 103/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.6994 - val_loss: 0.6620 - val_accuracy: 0.7045\n",
      "Epoch 104/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6999 - val_loss: 0.6592 - val_accuracy: 0.7080\n",
      "Epoch 105/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.6860 - val_loss: 0.6636 - val_accuracy: 0.7035\n",
      "Epoch 106/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.6922 - val_loss: 0.6595 - val_accuracy: 0.7090\n",
      "Epoch 107/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.6885 - val_loss: 0.6584 - val_accuracy: 0.7105\n",
      "Epoch 108/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6761 - accuracy: 0.7000 - val_loss: 0.6575 - val_accuracy: 0.7060\n",
      "Epoch 109/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.6898 - val_loss: 0.6575 - val_accuracy: 0.7120\n",
      "Epoch 110/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.6845 - val_loss: 0.6575 - val_accuracy: 0.7105\n",
      "Epoch 111/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.6941 - val_loss: 0.6616 - val_accuracy: 0.7050\n",
      "Epoch 112/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.6910 - val_loss: 0.6567 - val_accuracy: 0.7040\n",
      "Epoch 113/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.6992 - val_loss: 0.6569 - val_accuracy: 0.7080\n",
      "Epoch 114/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7026 - val_loss: 0.6580 - val_accuracy: 0.7040\n",
      "Epoch 115/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6739 - accuracy: 0.6988 - val_loss: 0.6563 - val_accuracy: 0.7095\n",
      "Epoch 116/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.6887 - val_loss: 0.6559 - val_accuracy: 0.7105\n",
      "Epoch 117/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6781 - accuracy: 0.6994 - val_loss: 0.6549 - val_accuracy: 0.7125\n",
      "Epoch 118/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.7082 - val_loss: 0.6554 - val_accuracy: 0.7095\n",
      "Epoch 119/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.7000 - val_loss: 0.6581 - val_accuracy: 0.7050\n",
      "Epoch 120/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.6965 - val_loss: 0.6586 - val_accuracy: 0.7085\n",
      "Epoch 121/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.6914 - val_loss: 0.6552 - val_accuracy: 0.7070\n",
      "Epoch 122/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.6885 - val_loss: 0.6564 - val_accuracy: 0.7105\n",
      "Epoch 123/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6658 - accuracy: 0.6996 - val_loss: 0.6540 - val_accuracy: 0.7115\n",
      "Epoch 124/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.6995 - val_loss: 0.6540 - val_accuracy: 0.7110\n",
      "Epoch 125/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.6972 - val_loss: 0.6532 - val_accuracy: 0.7125\n",
      "Epoch 126/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.6939 - val_loss: 0.6523 - val_accuracy: 0.7095\n",
      "Epoch 127/250\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6683 - accuracy: 0.7037 - val_loss: 0.6525 - val_accuracy: 0.7100\n",
      "Epoch 128/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.7054 - val_loss: 0.6518 - val_accuracy: 0.7130\n",
      "Epoch 129/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.7012 - val_loss: 0.6558 - val_accuracy: 0.7100\n",
      "Epoch 130/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.6914 - val_loss: 0.6512 - val_accuracy: 0.7140\n",
      "Epoch 131/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7063 - val_loss: 0.6501 - val_accuracy: 0.7120\n",
      "Epoch 132/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6960 - val_loss: 0.6508 - val_accuracy: 0.7100\n",
      "Epoch 133/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.6969 - val_loss: 0.6505 - val_accuracy: 0.7105\n",
      "Epoch 134/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7009 - val_loss: 0.6516 - val_accuracy: 0.7140\n",
      "Epoch 135/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.7013 - val_loss: 0.6518 - val_accuracy: 0.7095\n",
      "Epoch 136/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6817 - accuracy: 0.6923 - val_loss: 0.6493 - val_accuracy: 0.7090\n",
      "Epoch 137/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.6952 - val_loss: 0.6484 - val_accuracy: 0.7130\n",
      "Epoch 138/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.6885 - val_loss: 0.6482 - val_accuracy: 0.7110\n",
      "Epoch 139/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7048 - val_loss: 0.6507 - val_accuracy: 0.7115\n",
      "Epoch 140/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.7019 - val_loss: 0.6496 - val_accuracy: 0.7090\n",
      "Epoch 141/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7021 - val_loss: 0.6502 - val_accuracy: 0.7125\n",
      "Epoch 142/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6984 - val_loss: 0.6491 - val_accuracy: 0.7095\n",
      "Epoch 143/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7020 - val_loss: 0.6502 - val_accuracy: 0.7110\n",
      "Epoch 144/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.6949 - val_loss: 0.6483 - val_accuracy: 0.7135\n",
      "Epoch 145/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.7147 - val_loss: 0.6483 - val_accuracy: 0.7080\n",
      "Epoch 146/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7035 - val_loss: 0.6481 - val_accuracy: 0.7060\n",
      "Epoch 147/250\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6652 - accuracy: 0.7081 - val_loss: 0.6481 - val_accuracy: 0.7110\n",
      "Epoch 148/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.6814 - val_loss: 0.6472 - val_accuracy: 0.7115\n",
      "Epoch 149/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.7062 - val_loss: 0.6497 - val_accuracy: 0.7105\n",
      "Epoch 150/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.7058 - val_loss: 0.6454 - val_accuracy: 0.7140\n",
      "Epoch 151/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7000 - val_loss: 0.6480 - val_accuracy: 0.7125\n",
      "Epoch 152/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.7099 - val_loss: 0.6478 - val_accuracy: 0.7095\n",
      "Epoch 153/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7040 - val_loss: 0.6452 - val_accuracy: 0.7120\n",
      "Epoch 154/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.6954 - val_loss: 0.6470 - val_accuracy: 0.7110\n",
      "Epoch 155/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.7006 - val_loss: 0.6526 - val_accuracy: 0.7115\n",
      "Epoch 156/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.6949 - val_loss: 0.6477 - val_accuracy: 0.7110\n",
      "Epoch 157/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.6965 - val_loss: 0.6466 - val_accuracy: 0.7125\n",
      "Epoch 158/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6981 - val_loss: 0.6484 - val_accuracy: 0.7125\n",
      "Epoch 159/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.6955 - val_loss: 0.6455 - val_accuracy: 0.7120\n",
      "Epoch 160/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.7030 - val_loss: 0.6435 - val_accuracy: 0.7120\n",
      "Epoch 161/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6654 - accuracy: 0.7061 - val_loss: 0.6457 - val_accuracy: 0.7100\n",
      "Epoch 162/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.6967 - val_loss: 0.6440 - val_accuracy: 0.7135\n",
      "Epoch 163/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.7000 - val_loss: 0.6468 - val_accuracy: 0.7105\n",
      "Epoch 164/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.7036 - val_loss: 0.6466 - val_accuracy: 0.7100\n",
      "Epoch 165/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.6996 - val_loss: 0.6459 - val_accuracy: 0.7130\n",
      "Epoch 166/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.7016 - val_loss: 0.6467 - val_accuracy: 0.7095\n",
      "Epoch 167/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.7035 - val_loss: 0.6433 - val_accuracy: 0.7150\n",
      "Epoch 168/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7004 - val_loss: 0.6424 - val_accuracy: 0.7170\n",
      "Epoch 169/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.7058 - val_loss: 0.6450 - val_accuracy: 0.7110\n",
      "Epoch 170/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7022 - val_loss: 0.6434 - val_accuracy: 0.7120\n",
      "Epoch 171/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.7084 - val_loss: 0.6419 - val_accuracy: 0.7140\n",
      "Epoch 172/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.7013 - val_loss: 0.6458 - val_accuracy: 0.7090\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.7005 - val_loss: 0.6417 - val_accuracy: 0.7065\n",
      "Epoch 174/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7090 - val_loss: 0.6407 - val_accuracy: 0.7130\n",
      "Epoch 175/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.7094 - val_loss: 0.6409 - val_accuracy: 0.7130\n",
      "Epoch 176/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7030 - val_loss: 0.6416 - val_accuracy: 0.7110\n",
      "Epoch 177/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6618 - accuracy: 0.7043 - val_loss: 0.6438 - val_accuracy: 0.7150\n",
      "Epoch 178/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.7042 - val_loss: 0.6467 - val_accuracy: 0.7120\n",
      "Epoch 179/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.7030 - val_loss: 0.6406 - val_accuracy: 0.7100\n",
      "Epoch 180/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7049 - val_loss: 0.6397 - val_accuracy: 0.7125\n",
      "Epoch 181/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.7137 - val_loss: 0.6429 - val_accuracy: 0.7060\n",
      "Epoch 182/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6999 - val_loss: 0.6397 - val_accuracy: 0.7155\n",
      "Epoch 183/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.7056 - val_loss: 0.6389 - val_accuracy: 0.7095\n",
      "Epoch 184/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.7054 - val_loss: 0.6461 - val_accuracy: 0.7100\n",
      "Epoch 185/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7066 - val_loss: 0.6441 - val_accuracy: 0.7045\n",
      "Epoch 186/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7138 - val_loss: 0.6423 - val_accuracy: 0.7105\n",
      "Epoch 187/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7086 - val_loss: 0.6390 - val_accuracy: 0.7125\n",
      "Epoch 188/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7098 - val_loss: 0.6405 - val_accuracy: 0.7115\n",
      "Epoch 189/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.7006 - val_loss: 0.6381 - val_accuracy: 0.7160\n",
      "Epoch 190/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.7100 - val_loss: 0.6427 - val_accuracy: 0.7085\n",
      "Epoch 191/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7114 - val_loss: 0.6391 - val_accuracy: 0.7125\n",
      "Epoch 192/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.7105 - val_loss: 0.6402 - val_accuracy: 0.7125\n",
      "Epoch 193/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7055 - val_loss: 0.6395 - val_accuracy: 0.7130\n",
      "Epoch 194/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.7138 - val_loss: 0.6389 - val_accuracy: 0.7120\n",
      "Epoch 195/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.7089 - val_loss: 0.6390 - val_accuracy: 0.7130\n",
      "Epoch 196/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7063 - val_loss: 0.6396 - val_accuracy: 0.7115\n",
      "Epoch 197/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.7124 - val_loss: 0.6381 - val_accuracy: 0.7080\n",
      "Epoch 198/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.7025 - val_loss: 0.6378 - val_accuracy: 0.7180\n",
      "Epoch 199/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7024 - val_loss: 0.6361 - val_accuracy: 0.7155\n",
      "Epoch 200/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.7082 - val_loss: 0.6384 - val_accuracy: 0.7125\n",
      "Epoch 201/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.7134 - val_loss: 0.6374 - val_accuracy: 0.7170\n",
      "Epoch 202/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.6970 - val_loss: 0.6354 - val_accuracy: 0.7175\n",
      "Epoch 203/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7135 - val_loss: 0.6386 - val_accuracy: 0.7120\n",
      "Epoch 204/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7028 - val_loss: 0.6369 - val_accuracy: 0.7125\n",
      "Epoch 205/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7038 - val_loss: 0.6397 - val_accuracy: 0.7145\n",
      "Epoch 206/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.7077 - val_loss: 0.6375 - val_accuracy: 0.7130\n",
      "Epoch 207/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.7132 - val_loss: 0.6359 - val_accuracy: 0.7125\n",
      "Epoch 208/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.7092 - val_loss: 0.6353 - val_accuracy: 0.7155\n",
      "Epoch 209/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7150 - val_loss: 0.6370 - val_accuracy: 0.7125\n",
      "Epoch 210/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.7099 - val_loss: 0.6372 - val_accuracy: 0.7120\n",
      "Epoch 211/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.7174 - val_loss: 0.6359 - val_accuracy: 0.7135\n",
      "Epoch 212/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.7085 - val_loss: 0.6385 - val_accuracy: 0.7135\n",
      "Epoch 213/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.7120 - val_loss: 0.6389 - val_accuracy: 0.7110\n",
      "Epoch 214/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.6999 - val_loss: 0.6348 - val_accuracy: 0.7165\n",
      "Epoch 215/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.7087 - val_loss: 0.6419 - val_accuracy: 0.7050\n",
      "Epoch 216/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7020 - val_loss: 0.6350 - val_accuracy: 0.7125\n",
      "Epoch 217/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.6938 - val_loss: 0.6390 - val_accuracy: 0.7115\n",
      "Epoch 218/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.7114 - val_loss: 0.6342 - val_accuracy: 0.7090\n",
      "Epoch 219/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.7099 - val_loss: 0.6380 - val_accuracy: 0.7095\n",
      "Epoch 220/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.7190 - val_loss: 0.6369 - val_accuracy: 0.7130\n",
      "Epoch 221/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.7082 - val_loss: 0.6373 - val_accuracy: 0.7115\n",
      "Epoch 222/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7096 - val_loss: 0.6341 - val_accuracy: 0.7170\n",
      "Epoch 223/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.7064 - val_loss: 0.6337 - val_accuracy: 0.7155\n",
      "Epoch 224/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.7151 - val_loss: 0.6331 - val_accuracy: 0.7155\n",
      "Epoch 225/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.7098 - val_loss: 0.6329 - val_accuracy: 0.7120\n",
      "Epoch 226/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.7024 - val_loss: 0.6316 - val_accuracy: 0.7160\n",
      "Epoch 227/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.7086 - val_loss: 0.6306 - val_accuracy: 0.7155\n",
      "Epoch 228/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.7178 - val_loss: 0.6319 - val_accuracy: 0.7165\n",
      "Epoch 229/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.7065 - val_loss: 0.6350 - val_accuracy: 0.7145\n",
      "Epoch 230/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.7143 - val_loss: 0.6309 - val_accuracy: 0.7175\n",
      "Epoch 231/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.7116 - val_loss: 0.6300 - val_accuracy: 0.7100\n",
      "Epoch 232/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.7131 - val_loss: 0.6288 - val_accuracy: 0.7175\n",
      "Epoch 233/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.7130 - val_loss: 0.6309 - val_accuracy: 0.7185\n",
      "Epoch 234/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.7184 - val_loss: 0.6316 - val_accuracy: 0.7120\n",
      "Epoch 235/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.7098 - val_loss: 0.6288 - val_accuracy: 0.7190\n",
      "Epoch 236/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.7039 - val_loss: 0.6319 - val_accuracy: 0.7170\n",
      "Epoch 237/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.7056 - val_loss: 0.6284 - val_accuracy: 0.7190\n",
      "Epoch 238/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.7094 - val_loss: 0.6298 - val_accuracy: 0.7205\n",
      "Epoch 239/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.7158 - val_loss: 0.6274 - val_accuracy: 0.7185\n",
      "Epoch 240/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.7143 - val_loss: 0.6293 - val_accuracy: 0.7195\n",
      "Epoch 241/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.7026 - val_loss: 0.6290 - val_accuracy: 0.7130\n",
      "Epoch 242/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6461 - accuracy: 0.7086 - val_loss: 0.6302 - val_accuracy: 0.7170\n",
      "Epoch 243/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.7203 - val_loss: 0.6276 - val_accuracy: 0.7155\n",
      "Epoch 244/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.7052 - val_loss: 0.6284 - val_accuracy: 0.7165\n",
      "Epoch 245/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.7146 - val_loss: 0.6260 - val_accuracy: 0.7175\n",
      "Epoch 246/250\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.7159 - val_loss: 0.6283 - val_accuracy: 0.7175\n",
      "Epoch 247/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7166 - val_loss: 0.6275 - val_accuracy: 0.7220\n",
      "Epoch 248/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.7052 - val_loss: 0.6284 - val_accuracy: 0.7160\n",
      "Epoch 249/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.7049 - val_loss: 0.6267 - val_accuracy: 0.7210\n",
      "Epoch 250/250\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7097 - val_loss: 0.6246 - val_accuracy: 0.7175\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "epochs = 250\n",
    "\n",
    "fit = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_data = (x_test, y_test), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
